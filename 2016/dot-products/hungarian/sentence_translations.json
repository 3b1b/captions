[
 {
  "input": "Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "[\"Oda az örömhöz\", Beethoven, a zongora végére.] Hagyományosan a ponttöredékeket a lineáris algebra kurzusokon nagyon korán, jellemzően rögtön az elején bevezetik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "Így talán furcsának tűnhet, hogy a sorozatban ilyen messzire visszatoltam őket.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "Ezt azért tettem, mert van egy szabványos módja a téma bevezetésének, amihez nem kell más, mint a vektorok alapfokú ismerete, de a ponttermékeknek a matematikában betöltött szerepének teljesebb megértése csak a lineáris transzformációk fényében érhető el igazán.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "Előtte azonban hadd térjek ki röviden a ponttermék bevezetésének szokásos módjára, amely feltételezem, hogy számos néző számára legalább részben áttekinthető.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "Numerikusan, ha két azonos dimenziójú vektorunk van, két azonos hosszúságú számlista, akkor a pontproduktum kiszámítása azt jelenti, hogy az összes koordinátát összepárosítjuk, ezeket a párokat összeszorozzuk, és az eredményt összeadjuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "Tehát az 1, 2 vektor pontozva a 3, 4-gyel az 1-szer 3 plusz 2-szer 4 lenne.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "A 6, 2, 8, 3 vektor 1, 8, 5, 3 ponttal pontozva 6-szor 1 plusz 2-szer 8 plusz 8-szor 5 plusz 3-szor 3.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "Szerencsére ennek a számításnak van egy nagyon szép geometriai értelmezése.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "Ha két vektor, v és w közötti pontszorzatra gondolunk, képzeljük el, hogy w-t az origón és a v csúcsán áthaladó egyenesre vetítjük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "Ha ennek a vetületnek a hosszát megszorozzuk v hosszával, akkor megkapjuk a v pont szorzatot v pont w.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "Kivéve, ha w vetülete a v-vel ellentétes irányba mutat, akkor a pontproduktum valójában negatív lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "Ha tehát két vektor általában ugyanabba az irányba mutat, akkor a pontszorzatuk pozitív.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "Ha merőlegesek egymásra, vagyis az egyiknek a másikra vetített vetülete a nullvektor, akkor a pontproduktumuk nulla.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "Ha pedig általában ellentétes irányba mutatnak, akkor a pontproduktumuk negatív.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "Nos, ez az értelmezés furcsán aszimmetrikus.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "A két vektort nagyon eltérően kezeli.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "Amikor először tanultam ezt, meglepődtem, hogy a sorrend nem számít.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "Ehelyett vetíthetjük v-t w-ra, megszorozhatjuk a vetített v hosszát w hosszával, és ugyanazt az eredményt kapjuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "Úgy értem, nem érzed, hogy ez egy teljesen más folyamat?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "Itt a megérzés, hogy miért nem számít a sorrend.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "Ha v és w történetesen azonos hosszúságúak lennének, akkor kihasználhatnánk némi szimmetriát.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "Mivel w vetítése v-re, majd e vetítés hosszának megszorzása v hosszával, teljes tükörképe annak, hogy v-t vetítjük w-re, majd e vetítés hosszát megszorozzuk w hosszával.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "Ha most az egyiket, mondjuk v-t, valamilyen konstanssal, például 2-vel méretezzük, hogy ne legyen egyenlő hosszúságú, a szimmetria megszakad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "De gondoljuk végig, hogyan értelmezzük az új vektor, 2-szer v és w közötti pontszorzatot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "Ha úgy gondolunk w-re, mintha v-re vetítenénk, akkor a 2v pont w pont szorzata pontosan kétszerese lesz a v pont w pont szorzatának.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "Ez azért van, mert amikor v-et 2-vel méretezzük, az nem változtatja meg a w vetületének hosszát, hanem megduplázza a vektor hosszát, amelyre vetítjük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "De másrészt, mondjuk, hogy arra gondoltál, hogy v kivetül w-re.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "Nos, ebben az esetben a vetület hossza az, ami méretezve lesz, amikor v-t megszorozzuk 2-vel, de a vektor hossza, amire vetítünk, állandó marad.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "Tehát az összhatás továbbra is csak a pontproduktum megduplázása.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "Tehát bár a szimmetria ebben az esetben megtört, a skálázás hatása a pontszorzat értékére mindkét értelmezésben ugyanaz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "Van még egy másik nagy kérdés, ami összezavart, amikor először tanultam ezt a dolgot.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "Mi a csudának van köze ennek a koordináták összevetéséből, a párok szorzásából és összeadásából álló numerikus folyamatnak a vetítéshez?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "Nos, ahhoz, hogy kielégítő választ adhassunk, és hogy a pontproduktum jelentőségének teljes mértékben megfeleljünk, fel kell tárnunk valamit, ami egy kicsit mélyebb, és amit gyakran dualitásnak neveznek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "Mielőtt azonban erre rátérnénk, egy kis időt kell szánnom a több dimenzióból egy dimenzióba történő lineáris transzformációkra, ami nem más, mint a számsor.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "Ezek olyan függvények, amelyek egy 2D-s vektort vesznek be, és valamilyen számot adnak ki, de a lineáris transzformációk természetesen sokkal korlátozottabbak, mint a 2D-s bemenettel és 1D-s kimenettel rendelkező szokásos függvények.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "Ahogy a magasabb dimenziókban történő transzformációk esetében is, mint amilyenekről a 3. fejezetben beszéltem, van néhány formális tulajdonság, ami ezeket a függvényeket lineárissá teszi, de ezeket itt szándékosan figyelmen kívül hagyom, hogy ne térítsem el a célunktól, és ehelyett egy bizonyos vizuális tulajdonságra összpontosítok, ami egyenértékű az összes formális dologgal.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "Ha veszünk egy egyenletes távolságban lévő pontokból álló vonalat, és alkalmazunk egy transzformációt, akkor a lineáris transzformáció egyenletes távolságban tartja a pontokat, amint azok a kimeneti térben, azaz a számsoron landolnak.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "Ellenkező esetben, ha a pontok sora egyenetlenül oszlik el, akkor a transzformáció nem lineáris.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "Az eddig látott esetekhez hasonlóan az egyik ilyen lineáris transzformációt teljesen meghatározza az, hogy hova viszi az i-hat és j-hat, de ezúttal minden egyes alapvektor csak egy számra érkezik, így amikor egy mátrix oszlopaként rögzítjük, hogy hova érkeznek, minden egyes oszlop csak egyetlen számot tartalmaz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "Ez egy 1x2-es mátrix.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "Nézzünk egy példát arra, hogy mit jelent az egyik ilyen transzformáció alkalmazása egy vektorra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "Tegyük fel, hogy van egy lineáris transzformáció, amely az i-hatot 1-re, a j-hatot pedig negatív 2-re változtatja.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "Ha követni akarjuk, hogy egy mondjuk 4, 3 koordinátájú vektor hova kerül, gondoljunk arra, hogy ez a vektor 4-szer i-hat plusz 3-szor j-hat.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "A linearitás következménye, hogy a transzformáció után a vektor 4-szerese lesz annak a helynek, ahol az i-kalap landol, azaz 1-nek, plusz 3-szorosa annak a helynek, ahol a j-kalap landol, azaz negatív 2-nek, ami ebben az esetben azt jelenti, hogy a negatív 2-re landol.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "Ha ezt a számítást tisztán numerikusan végezzük, akkor ez mátrixvektor-szorzás.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "Ez a numerikus művelet, egy 1x2-es mátrix és egy vektor szorzása olyan, mintha két vektor szorzatát vennénk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "Nem úgy néz ki ez az 1x2-es mátrix, mint egy vektor, amit az oldalára döntöttünk?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "Valójában most azt mondhatnánk, hogy van egy szép asszociáció az 1x2 mátrixok és a 2D vektorok között, amit úgy határozunk meg, hogy egy vektor numerikus ábrázolását oldalra billentve megkapjuk a hozzá tartozó mátrixot, vagy a mátrixot visszafordítva megkapjuk a hozzá tartozó vektort.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "Mivel most csak numerikus kifejezéseket vizsgálunk, a vektorok és az 1x2-es mátrixok között ide-oda járkálás butaságnak tűnhet.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "De ez valami olyasmit sugall, ami geometriai szempontból igazán félelmetes.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "Van valamiféle kapcsolat a vektorokat számokká alakító lineáris transzformációk és maguk a vektorok között.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "Hadd mutassak egy példát, amely tisztázza a jelentőségét, és amely történetesen választ ad a korábban említett ponttétel-rejtélyre is.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "Tegye félre, amit eddig tanult, és képzelje el, hogy még nem tudja, hogy a pontszorzat a vetülethez kapcsolódik.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "Itt most fogok egy másolatot készíteni a számsorból, és valahogy átlósan elhelyezem a térben, úgy, hogy a 0-ás szám az origónál legyen.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "Most gondoljunk arra a kétdimenziós egységvektorra, amelynek csúcsa ott van, ahol a számon az 1-es szám van.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "Szeretnék egy nevet adni a fickónak, U-hat.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "Ez a kis fickó fontos szerepet játszik abban, ami történni fog, úgyhogy tartsd őt a fejedben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "Ha 2d vektorokat vetítünk egyenesen erre az átlós számegyenesre, akkor tulajdonképpen épp most definiáltunk egy függvényt, amely 2d vektorokat számokká alakít.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "Ráadásul ez a függvény valójában lineáris, mivel átmegy a vizuális tesztünkön, miszerint az egyenletes távolságban lévő pontokból álló bármelyik sor egyenletes távolságban marad, ha a számsorra kerül.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "Csak hogy tisztázzuk, annak ellenére, hogy a számsort 2d térbe ágyaztam be, a függvény kimenetei számok, nem pedig 2d vektorok.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "Olyan függvényt kell kitalálnod, amely két koordinátát vesz fel, és egyetlen koordinátát ad ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "De ez az u-hat vektor egy kétdimenziós vektor, amely a bemeneti térben él.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "Csak úgy helyezkedik el, hogy átfedésben van a számsor beágyazásával.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "Ezzel a vetítéssel épp most definiáltunk egy lineáris transzformációt 2d vektorokból számokká, tehát találni fogunk valamilyen 1x2-es mátrixot, amely leírja ezt a transzformációt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "Ahhoz, hogy megtaláljuk ezt az 1x2-es mátrixot, közelítsünk rá erre az átlós számsorra, és gondoljuk végig, hol landol az i-hat és a j-hat, mivel ezek a leszállóhelyek lesznek a mátrix oszlopai.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "Ez a rész szuper király.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "Egy igazán elegáns szimmetriával érvelhetünk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "Mivel i-hat és u-hat egyaránt egységvektor, az i-hat vetítése az u-haton áthaladó egyenesre teljesen szimmetrikusnak tűnik az u-hat x-tengelyre vetítésével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "Amikor tehát azt kérdezzük, hogy az i-kalap milyen számra érkezik, amikor kivetítjük, a válasz ugyanaz lesz, mint amire az u-kalap érkezik, amikor az x-tengelyre vetítjük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "De az u-hat x-tengelyre vetítése csak annyit jelent, hogy az u-hat x-koordinátáját vesszük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "Tehát a szimmetria miatt az a szám, ahol az i-kalap az átlós számegyenesre vetítve landol, az u-kalap x-koordinátája lesz.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Hát nem király?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "Az érvelés majdnem azonos a j-hat esetében.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "Gondolj bele egy pillanatra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "Ugyanezen okok miatt az u-kalap y-koordinátája adja meg azt a számot, ahol a j-kalap a számegyenesre vetítve landol.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "Állj meg és gondolkodj el ezen egy pillanatra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "Szerintem ez nagyon király.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "Tehát a vetítési transzformációt leíró 1x2-es mátrix bejegyzései az u-hat koordinátái lesznek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "És ennek a vetületi transzformációnak a kiszámítása tetszőleges térbeli vektorokra, amihez a mátrixot meg kell szorozni ezekkel a vektorokkal, számításilag azonos az u-hat ponttöbbszörözéssel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "Ezért az egységvektorral való pontszorzatot úgy lehet értelmezni, hogy egy vektort rávetítünk ennek az egységvektornak a tartományára, és a hosszát vesszük.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "Mi a helyzet a nem egységvektorokkal?",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "Tegyük fel például, hogy vesszük az u-hat egységvektort, de felskálázzuk 3-mal.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "Számszerűen minden egyes összetevőjét megszorozzuk 3-mal.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "Tehát ha megnézzük az ehhez a vektorhoz tartozó mátrixot, akkor az i-hat és j-hat háromszor olyan értékre kerül, mint ahol korábban volt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "Mivel mindez lineáris, ez általánosabban azt jelenti, hogy az új mátrix úgy értelmezhető, hogy bármelyik vektort rávetítjük a számegyenes másolatára, és ahol az landol, ott megszorozzuk 3-mal.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "Ezért a pontszorzat egy nem egységnyi vektorral úgy értelmezhető, hogy először rávetítjük a vektorra, majd a vetület hosszát felskálázzuk a vektor hosszával.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "Gondolkodjon el egy pillanatra azon, hogy mi történt itt.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "Volt egy lineáris transzformációnk a 2D térből a számegyenesre, amelyet nem definiáltunk numerikus vektorok vagy numerikus pontprodukciók segítségével, hanem egyszerűen a térnek a számegyenes egy átlós másolatára való vetítésével.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "De mivel a transzformáció lineáris, szükségszerűen valamilyen 1x2-es mátrix írta le.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "És mivel egy 1x2-es mátrixot megszorozni egy 2D-s vektorral ugyanaz, mint a mátrixot az oldalára fordítani és ponttermelést végezni, ez a transzformáció elkerülhetetlenül valamilyen 2D-s vektorhoz kapcsolódott.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "A tanulság az, hogy bármikor, amikor van egy ilyen lineáris transzformáció, amelynek kimeneti tere a számegyenes, függetlenül attól, hogy hogyan definiálták, mindig lesz egy egyedi vektor, amely megfelel ennek a transzformációnak, abban az értelemben, hogy a transzformáció alkalmazása ugyanaz, mint a vektorral való ponttétel.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "Számomra ez teljesen gyönyörű.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "Ez egy példa a matematikában a dualitásnak nevezett dologra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "A dualitás sokféle módon és formában jelenik meg a matematikában, és nagyon nehéz definiálni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "Lazán fogalmazva olyan helyzetekre utal, amikor természetes, de meglepő megfelelés van kétféle matematikai dolog között.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "A lineáris algebrai esetben, amelyet az imént tanultál, azt mondanád, hogy egy vektor duálisa az a lineáris transzformáció, amelyet kódol, és egy bizonyos térből egy dimenzióba történő lineáris transzformáció duálisa egy bizonyos vektor abban a térben.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "Összefoglalva tehát, a felszínen a pontszorzat egy nagyon hasznos geometriai eszköz a vetületek megértéséhez és annak teszteléséhez, hogy a vektorok hajlamosak-e ugyanabba az irányba mutatni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "És ez talán a legfontosabb dolog, amit a ponttermékről érdemes megjegyezni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "Mélyebb szinten azonban két vektor összeillesztésével az egyiket a transzformációk világába fordíthatjuk.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "Számszerűsítve ezt is butaságnak tűnhet hangsúlyozni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "Ez csak két számítás, amelyek történetesen hasonlóan néznek ki.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "De azért tartom ezt olyan fontosnak, mert az egész matematika során, amikor egy vektorral foglalkozunk, ha egyszer igazán megismerjük a személyiségét, néha rájövünk, hogy könnyebb úgy értelmezni, hogy nem egy nyíl a térben, hanem egy lineáris transzformáció fizikai megtestesülése.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "Mintha a vektor valójában csak egy fogalmi rövidítés lenne egy bizonyos transzformációra, mivel könnyebb számunkra a térben lévő nyilakra gondolni, mint az egész teret a számsorra áthelyezni.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.97
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "A következő videóban ennek a kettősségnek egy másik nagyon jó példáját láthatod majd működés közben, amikor a kereszttételről beszélek.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 822.61,
  "end": 829.19
 }
]