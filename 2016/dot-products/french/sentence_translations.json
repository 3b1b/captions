[
 {
  "translatedText": "[&quot;Ode to Joy&quot;, de Beethoven, joue jusqu'au bout du piano.] Traditionnellement, les produits scalaires sont quelque chose qui est introduit très tôt dans un cours d'algèbre linéaire, généralement dès le début.",
  "input": "[\"Ode to Joy\", by Beethoven, plays to the end of the piano.] Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "time_range": [
   16.58,
   26.3
  ]
 },
 {
  "translatedText": "Cela peut donc paraître étrange que je les ai repoussés aussi loin dans la série.",
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "time_range": [
   26.64,
   29.58
  ]
 },
 {
  "translatedText": "J'ai fait cela parce qu'il existe une manière standard d'introduire le sujet, qui ne nécessite rien de plus qu'une compréhension de base des vecteurs, mais une compréhension plus complète du rôle que jouent les produits scalaires en mathématiques ne peut être réellement trouvée qu'à la lumière des transformations linéaires.",
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "time_range": [
   29.58,
   42.44
  ]
 },
 {
  "translatedText": "Avant cela, cependant, permettez-moi d'aborder brièvement la manière standard dont les produits scalaires sont introduits, qui, je suppose, est au moins partiellement révisée pour un certain nombre de téléspectateurs.",
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "time_range": [
   43.48,
   50.62
  ]
 },
 {
  "translatedText": "Numériquement, si vous avez deux vecteurs de même dimension, deux listes de nombres de mêmes longueurs, prendre leur produit scalaire signifie associer toutes les coordonnées, multiplier ces paires entre elles et additionner le résultat.",
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "time_range": [
   51.44,
   64.98
  ]
 },
 {
  "translatedText": "Ainsi le vecteur 1, 2 pointé par 3, 4 serait 1 fois 3 plus 2 fois 4.",
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "time_range": [
   66.86,
   73.18
  ]
 },
 {
  "translatedText": "Le vecteur 6, 2, 8, 3 parsemé de 1, 8, 5, 3 serait 6 fois 1 plus 2 fois 8 plus 8 fois 5 plus 3 fois 3.",
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "time_range": [
   74.58,
   83.72
  ]
 },
 {
  "translatedText": "Heureusement, ce calcul a une très belle interprétation géométrique.",
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "time_range": [
   84.74,
   88.66
  ]
 },
 {
  "translatedText": "Pour réfléchir au produit scalaire entre deux vecteurs v et w, imaginez projeter w sur la ligne qui passe par l’origine et la pointe de v.",
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "time_range": [
   89.34,
   97.98
  ]
 },
 {
  "translatedText": "En multipliant la longueur de cette projection par la longueur de v, vous obtenez le produit scalaire v dot w.",
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "time_range": [
   98.78,
   104.46
  ]
 },
 {
  "translatedText": "Sauf lorsque cette projection de w pointe dans la direction opposée à celle de v, ce produit scalaire sera en réalité négatif.",
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "time_range": [
   106.42,
   112.16
  ]
 },
 {
  "translatedText": "Ainsi, lorsque deux vecteurs pointent généralement dans la même direction, leur produit scalaire est positif.",
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "time_range": [
   113.72,
   117.86
  ]
 },
 {
  "translatedText": "Lorsqu'ils sont perpendiculaires, c'est-à-dire que la projection de l'un sur l'autre est le vecteur zéro, leur produit scalaire est nul.",
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "time_range": [
   119.24,
   125.56
  ]
 },
 {
  "translatedText": "Et s’ils pointent généralement dans la direction opposée, leur produit scalaire est négatif.",
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "time_range": [
   125.98,
   129.6
  ]
 },
 {
  "translatedText": "Or, cette interprétation est étrangement asymétrique.",
  "input": "Now, this interpretation is weirdly asymmetric.",
  "time_range": [
   131.62,
   134.56
  ]
 },
 {
  "translatedText": "Il traite les deux vecteurs de manière très différente.",
  "input": "It treats the two vectors very differently.",
  "time_range": [
   134.8,
   136.5
  ]
 },
 {
  "translatedText": "Alors, quand j'ai appris cela pour la première fois, j'ai été surpris de constater que l'ordre n'avait pas d'importance.",
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "time_range": [
   136.88,
   140.0
  ]
 },
 {
  "translatedText": "Vous pouvez plutôt projeter v sur w, multiplier la longueur du v projeté par la longueur de w et obtenir le même résultat.",
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "time_range": [
   140.96,
   148.22
  ]
 },
 {
  "translatedText": "Je veux dire, cela ne semble-t-il pas être un processus vraiment différent ?",
  "input": "I mean, doesn't that feel like a really different process?",
  "time_range": [
   150.4,
   152.84
  ]
 },
 {
  "translatedText": "Voici l’intuition expliquant pourquoi l’ordre n’a pas d’importance.",
  "input": "Here's the intuition for why order doesn't matter.",
  "time_range": [
   155.32,
   157.76
  ]
 },
 {
  "translatedText": "Si v et w avaient la même longueur, nous pourrions exploiter une certaine symétrie.",
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "time_range": [
   158.44,
   162.18
  ]
 },
 {
  "translatedText": "Puisque projeter w sur v, puis multiplier la longueur de cette projection par la longueur de v, est une image miroir complète de la projection de v sur w, puis multiplier la longueur de cette projection par la longueur de w.",
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "time_range": [
   163.08,
   175.24
  ]
 },
 {
  "translatedText": "Maintenant, si vous mettez à l'échelle l'un d'eux, disons v, par une constante telle que 2, de sorte qu'ils n'aient pas la même longueur, la symétrie est rompue.",
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "time_range": [
   177.28,
   184.36
  ]
 },
 {
  "translatedText": "Mais réfléchissons à la manière d'interpréter le produit scalaire entre ce nouveau vecteur, 2 fois v, et w.",
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "time_range": [
   185.02,
   190.04
  ]
 },
 {
  "translatedText": "Si vous pensez que w est projeté sur v, alors le produit scalaire 2v dot w sera exactement le double du produit scalaire v dot w.",
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "time_range": [
   190.88,
   199.72
  ]
 },
 {
  "translatedText": "En effet, lorsque vous mettez v à l'échelle par 2, cela ne change pas la longueur de la projection de w, mais cela double la longueur du vecteur sur lequel vous projetez.",
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "time_range": [
   200.46,
   209.52
  ]
 },
 {
  "translatedText": "Mais d’un autre côté, disons que vous pensiez à ce que v soit projeté sur w.",
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "time_range": [
   210.46,
   214.2
  ]
 },
 {
  "translatedText": "Eh bien, dans ce cas, la longueur de la projection est ce qui est mis à l'échelle lorsque nous multiplions v par 2, mais la longueur du vecteur sur lequel vous projetez reste constante.",
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "time_range": [
   214.9,
   223.0
  ]
 },
 {
  "translatedText": "L’effet global consiste donc simplement à doubler le produit scalaire.",
  "input": "So the overall effect is still to just double the dot product.",
  "time_range": [
   223.0,
   226.66
  ]
 },
 {
  "translatedText": "Ainsi, même si la symétrie est rompue dans ce cas, l’effet de cette mise à l’échelle sur la valeur du produit scalaire est le même dans les deux interprétations.",
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "time_range": [
   227.28,
   234.86
  ]
 },
 {
  "translatedText": "Il y a aussi une autre grande question qui m'a dérouté lorsque j'ai appris ce genre de choses pour la première fois.",
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "time_range": [
   236.64,
   240.34
  ]
 },
 {
  "translatedText": "Pourquoi diable ce processus numérique consistant à faire correspondre les coordonnées, à multiplier les paires et à les additionner a-t-il quelque chose à voir avec la projection ?",
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "time_range": [
   240.84,
   248.74
  ]
 },
 {
  "translatedText": "Eh bien, pour donner une réponse satisfaisante, et aussi pour rendre pleinement justice à l’importance du produit scalaire, nous devons découvrir ici quelque chose d’un peu plus profond, qui est souvent appelé dualité.",
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "time_range": [
   250.64,
   261.4
  ]
 },
 {
  "translatedText": "Mais avant d’entrer dans le vif du sujet, je dois passer un peu de temps à parler des transformations linéaires de plusieurs dimensions à une seule dimension, qui n’est que la droite numérique.",
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "time_range": [
   262.14,
   270.04
  ]
 },
 {
  "translatedText": "Ce sont des fonctions qui prennent en compte un vecteur 2D et crachent un certain nombre, mais les transformations linéaires sont bien sûr beaucoup plus restreintes que votre fonction ordinaire avec une entrée 2D et une sortie 1D.",
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "time_range": [
   272.42,
   282.3
  ]
 },
 {
  "translatedText": "Comme pour les transformations dans des dimensions supérieures, comme celles dont j'ai parlé au chapitre 3, il existe certaines propriétés formelles qui rendent ces fonctions linéaires, mais je vais délibérément les ignorer ici afin de ne pas détourner l'attention de notre objectif final, et à la place concentrez-vous sur une certaine propriété visuelle qui est équivalente à tous les éléments formels.",
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "time_range": [
   283.02,
   298.26
  ]
 },
 {
  "translatedText": "Si vous prenez une ligne de points régulièrement espacés et appliquez une transformation, une transformation linéaire maintiendra ces points uniformément espacés une fois qu'ils atterriront dans l'espace de sortie, qui est la droite numérique.",
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "time_range": [
   299.04,
   311.28
  ]
 },
 {
  "translatedText": "Sinon, s’il y a une ligne de points inégalement espacés, alors votre transformation n’est pas linéaire.",
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "time_range": [
   312.42,
   317.14
  ]
 },
 {
  "translatedText": "Comme dans les cas que nous avons vus précédemment, l'une de ces transformations linéaires est entièrement déterminée par l'endroit où elle prend i-hat et j-hat, mais cette fois, chacun de ces vecteurs de base atterrit simplement sur un nombre, donc lorsque nous enregistrons où ils atterrissent comme les colonnes d'une matrice, chacune de ces colonnes n'a qu'un seul numéro.",
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "time_range": [
   319.22,
   336.82
  ]
 },
 {
  "translatedText": "Il s'agit d'une matrice 1x2.",
  "input": "This is a 1x2 matrix.",
  "time_range": [
   338.46,
   339.84
  ]
 },
 {
  "translatedText": "Passons en revue un exemple de ce que signifie appliquer l'une de ces transformations à un vecteur.",
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "time_range": [
   341.86,
   345.66
  ]
 },
 {
  "translatedText": "Disons que vous avez une transformation linéaire qui amène i-hat à 1 et j-hat à moins 2.",
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "time_range": [
   346.38,
   351.68
  ]
 },
 {
  "translatedText": "Pour savoir où aboutit un vecteur avec des coordonnées, disons 4, 3, pensez à diviser ce vecteur en 4 fois i-hat plus 3 fois j-hat.",
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "time_range": [
   352.42,
   361.02
  ]
 },
 {
  "translatedText": "Une conséquence de la linéarité est qu'après la transformation, le vecteur sera 4 fois l'endroit où i-hat atterrit, 1, plus 3 fois l'endroit où j-hat atterrit, moins 2, ce qui dans ce cas implique qu'il atterrit sur négatif 2.",
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "time_range": [
   361.84,
   375.78
  ]
 },
 {
  "translatedText": "Lorsque vous effectuez ce calcul purement numériquement, il s’agit d’une multiplication vectorielle matricielle.",
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "time_range": [
   378.02,
   382.36
  ]
 },
 {
  "translatedText": "Maintenant, cette opération numérique consistant à multiplier une matrice 1x2 par un vecteur revient à prendre le produit scalaire de deux vecteurs.",
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "time_range": [
   385.7,
   392.86
  ]
 },
 {
  "translatedText": "Cette matrice 1x2 ne ressemble-t-elle pas simplement à un vecteur que nous avons incliné sur le côté ?",
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "time_range": [
   393.46,
   396.8
  ]
 },
 {
  "translatedText": "En fait, on pourrait dire dès maintenant qu'il existe une belle association entre les matrices 1x2 et les vecteurs 2D, définie en inclinant la représentation numérique d'un vecteur sur son côté pour obtenir la matrice associée, ou en inclinant la matrice vers le haut pour obtenir le vecteur associé. .",
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "time_range": [
   397.96,
   412.58
  ]
 },
 {
  "translatedText": "Puisque nous examinons uniquement les expressions numériques pour le moment, faire des allers-retours entre les vecteurs et les matrices 1x2 peut sembler idiot.",
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "time_range": [
   413.56,
   420.86
  ]
 },
 {
  "translatedText": "Mais cela suggère quelque chose de vraiment génial du point de vue géométrique.",
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "time_range": [
   421.46,
   425.12
  ]
 },
 {
  "translatedText": "Il existe une sorte de lien entre les transformations linéaires qui transforment les vecteurs en nombres et les vecteurs eux-mêmes.",
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "time_range": [
   425.38,
   431.72
  ]
 },
 {
  "translatedText": "Permettez-moi de montrer un exemple qui clarifie la signification et qui, par hasard, répond également à l'énigme du produit scalaire évoquée plus tôt.",
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "time_range": [
   434.78,
   441.38
  ]
 },
 {
  "translatedText": "Désapprenez ce que vous avez appris et imaginez que vous ne savez pas déjà que le produit scalaire est lié à la projection.",
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "time_range": [
   442.14,
   447.18
  ]
 },
 {
  "translatedText": "Ce que je vais faire ici, c'est prendre une copie de la droite numérique et la placer d'une manière ou d'une autre en diagonale dans l'espace, avec le chiffre 0 à l'origine.",
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "time_range": [
   448.86,
   456.06
  ]
 },
 {
  "translatedText": "Pensez maintenant au vecteur unitaire bidimensionnel dont la pointe se trouve là où se trouve le chiffre 1 sur le nombre.",
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "time_range": [
   456.9,
   461.92
  ]
 },
 {
  "translatedText": "Je veux donner un nom à ce type, u-hat.",
  "input": "I want to give that guy a name, u-hat.",
  "time_range": [
   462.4,
   464.56
  ]
 },
 {
  "translatedText": "Ce petit bonhomme joue un rôle important dans ce qui est sur le point de se produire, alors gardez-le à l'esprit.",
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "time_range": [
   465.62,
   470.02
  ]
 },
 {
  "translatedText": "Si nous projetons des vecteurs 2D directement sur cette droite numérique diagonale, nous venons en fait de définir une fonction qui transforme les vecteurs 2D en nombres.",
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "time_range": [
   470.74,
   478.96
  ]
 },
 {
  "translatedText": "De plus, cette fonction est en réalité linéaire, puisqu'elle réussit notre test visuel selon lequel toute ligne de points régulièrement espacés reste également espacée une fois qu'elle atterrit sur la droite numérique.",
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "time_range": [
   479.66,
   488.96
  ]
 },
 {
  "translatedText": "Juste pour être clair, même si j'ai intégré la droite numérique dans un espace 2D comme celui-ci, les sorties de la fonction sont des nombres, pas des vecteurs 2D.",
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "time_range": [
   491.64,
   499.28
  ]
 },
 {
  "translatedText": "Vous devriez penser à une fonction qui prend deux coordonnées et génère une seule coordonnée.",
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "time_range": [
   499.96,
   503.68
  ]
 },
 {
  "translatedText": "Mais ce vecteur u-hat est un vecteur bidimensionnel, vivant dans l’espace d’entrée.",
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "time_range": [
   505.06,
   509.02
  ]
 },
 {
  "translatedText": "Il est simplement situé de telle manière qu'il chevauche l'intégration de la droite numérique.",
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "time_range": [
   509.44,
   513.22
  ]
 },
 {
  "translatedText": "Avec cette projection, nous venons de définir une transformation linéaire de vecteurs 2D en nombres, nous allons donc pouvoir trouver une sorte de matrice 1x2 qui décrit cette transformation.",
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "time_range": [
   514.6,
   524.6
  ]
 },
 {
  "translatedText": "Pour trouver cette matrice 1x2, zoomons sur cette configuration de droite numérique diagonale et réfléchissons à l'endroit où i-hat et j-hat atterrissent chacun, puisque ces points d'atterrissage seront les colonnes de la matrice.",
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "time_range": [
   525.54,
   536.46
  ]
 },
 {
  "translatedText": "Cette partie est super cool.",
  "input": "This part's super cool.",
  "time_range": [
   538.48,
   539.44
  ]
 },
 {
  "translatedText": "Nous pouvons raisonner avec une symétrie vraiment élégante.",
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "time_range": [
   539.7,
   542.42
  ]
 },
 {
  "translatedText": "Puisque i-hat et u-hat sont tous deux des vecteurs unitaires, la projection de i-hat sur la ligne passant par u-hat semble totalement symétrique à la projection de u-hat sur l'axe des x.",
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "time_range": [
   543.02,
   553.16
  ]
 },
 {
  "translatedText": "Ainsi, lorsque nous demandons sur quel nombre le chapeau atterrit lorsqu'il est projeté, la réponse sera la même que quel que soit le nombre sur lequel le chapeau atterrit lorsqu'il est projeté sur l'axe des x.",
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "time_range": [
   553.84,
   562.32
  ]
 },
 {
  "translatedText": "Mais projeter u-hat sur l’axe des x signifie simplement prendre la coordonnée x de u-hat.",
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "time_range": [
   562.92,
   568.6
  ]
 },
 {
  "translatedText": "Donc, par symétrie, le nombre où i-hat atterrit lorsqu'il est projeté sur cette droite numérique diagonale sera la coordonnée x de u-hat.",
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "time_range": [
   569.02,
   576.62
  ]
 },
 {
  "translatedText": "N'est-ce pas cool ?",
  "input": "Isn't that cool?",
  "time_range": [
   577.16,
   577.66
  ]
 },
 {
  "translatedText": "Le raisonnement est presque identique pour l’affaire j-hat.",
  "input": "The reasoning is almost identical for the j-hat case.",
  "time_range": [
   579.2,
   581.8
  ]
 },
 {
  "translatedText": "Pensez-y un instant.",
  "input": "Think about it for a moment.",
  "time_range": [
   582.18,
   583.26
  ]
 },
 {
  "translatedText": "Pour les mêmes raisons, la coordonnée y de u-hat nous donne le nombre où j-hat atterrit lorsqu'il est projeté sur la copie de la droite numérique.",
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "time_range": [
   589.12,
   596.6
  ]
 },
 {
  "translatedText": "Faites une pause et réfléchissez-y un instant.",
  "input": "Pause and ponder that for a moment.",
  "time_range": [
   597.58,
   598.72
  ]
 },
 {
  "translatedText": "Je pense juste que c'est vraiment cool.",
  "input": "I just think that's really cool.",
  "time_range": [
   598.78,
   600.2
  ]
 },
 {
  "translatedText": "Ainsi, les entrées de la matrice 1x2 décrivant la transformation de projection seront les coordonnées de u-hat.",
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "time_range": [
   600.92,
   607.26
  ]
 },
 {
  "translatedText": "Et calculer cette transformation de projection pour des vecteurs arbitraires dans l'espace, qui nécessite de multiplier cette matrice par ces vecteurs, est informatiquement identique à la prise d'un produit scalaire avec u-hat.",
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "time_range": [
   608.04,
   618.88
  ]
 },
 {
  "translatedText": "C'est pourquoi prendre le produit scalaire avec un vecteur unitaire peut être interprété comme projeter un vecteur sur l'étendue de ce vecteur unitaire et prendre la longueur.",
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "time_range": [
   621.46,
   630.59
  ]
 },
 {
  "translatedText": "Alors qu’en est-il des vecteurs non unitaires ?",
  "input": "So what about non-unit vectors?",
  "time_range": [
   634.03,
   635.79
  ]
 },
 {
  "translatedText": "Par exemple, disons que nous prenons ce vecteur unitaire u-hat, mais que nous l'agrandissons d'un facteur 3.",
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "time_range": [
   636.31,
   640.63
  ]
 },
 {
  "translatedText": "Numériquement, chacune de ses composantes est multipliée par 3.",
  "input": "Numerically, each of its components gets multiplied by 3.",
  "time_range": [
   641.35,
   644.39
  ]
 },
 {
  "translatedText": "Donc, en regardant la matrice associée à ce vecteur, cela amène i-hat et j-hat à trois fois les valeurs auxquelles ils avaient atterri auparavant.",
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "time_range": [
   644.81,
   652.39
  ]
 },
 {
  "translatedText": "Puisque tout cela est linéaire, cela implique plus généralement que la nouvelle matrice peut être interprétée comme projetant n'importe quel vecteur sur la copie de la droite numérique et multipliant là où il atterrit par 3.",
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "time_range": [
   655.23,
   664.65
  ]
 },
 {
  "translatedText": "C'est pourquoi le produit scalaire avec un vecteur non unitaire peut être interprété comme se projetant d'abord sur ce vecteur, puis augmentant la longueur de cette projection de la longueur du vecteur.",
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "time_range": [
   665.47,
   674.95
  ]
 },
 {
  "translatedText": "Prenez un moment pour réfléchir à ce qui s'est passé ici.",
  "input": "Take a moment to think about what happened here.",
  "time_range": [
   677.59,
   679.55
  ]
 },
 {
  "translatedText": "Nous avons eu une transformation linéaire de l'espace 2D vers la droite numérique, qui n'a pas été définie en termes de vecteurs numériques ou de produits scalaires numériques, elle a simplement été définie en projetant l'espace sur une copie diagonale de la droite numérique.",
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "time_range": [
   679.89,
   690.89
  ]
 },
 {
  "translatedText": "Mais comme la transformation est linéaire, elle a nécessairement été décrite par une matrice 1x2.",
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "time_range": [
   691.67,
   696.83
  ]
 },
 {
  "translatedText": "Et comme multiplier une matrice 1x2 par un vecteur 2D revient à retourner cette matrice et à prendre un produit scalaire, cette transformation était inévitablement liée à un vecteur 2D.",
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "time_range": [
   697.33,
   707.91
  ]
 },
 {
  "translatedText": "La leçon ici est que chaque fois que vous avez une de ces transformations linéaires dont l'espace de sortie est la droite numérique, peu importe comment elle a été définie, il y aura un vecteur unique v correspondant à cette transformation, dans le sens où appliquer la transformation est la même chose que de prendre un produit scalaire avec ce vecteur.",
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "time_range": [
   709.41,
   726.35
  ]
 },
 {
  "translatedText": "Pour moi, c'est tout à fait magnifique.",
  "input": "To me, this is utterly beautiful.",
  "time_range": [
   729.93,
   732.03
  ]
 },
 {
  "translatedText": "C'est un exemple de quelque chose en mathématiques appelé dualité.",
  "input": "It's an example of something in math called duality.",
  "time_range": [
   732.73,
   735.39
  ]
 },
 {
  "translatedText": "La dualité apparaît de différentes manières et sous différentes formes en mathématiques, et elle est très difficile à définir.",
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "time_range": [
   736.27,
   741.93
  ]
 },
 {
  "translatedText": "En gros, cela fait référence à des situations dans lesquelles il existe une correspondance naturelle mais surprenante entre deux types de choses mathématiques.",
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "time_range": [
   742.67,
   750.23
  ]
 },
 {
  "translatedText": "Pour le cas d'algèbre linéaire que vous venez d'apprendre, vous diriez que le dual d'un vecteur est la transformation linéaire qu'il code, et que le dual d'une transformation linéaire d'un espace vers une dimension est un certain vecteur dans cet espace.",
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "time_range": [
   751.01,
   764.65
  ]
 },
 {
  "translatedText": "Donc, pour résumer, en surface, le produit scalaire est un outil géométrique très utile pour comprendre les projections et pour tester si les vecteurs ont tendance ou non à pointer dans la même direction.",
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "time_range": [
   766.73,
   776.31
  ]
 },
 {
  "translatedText": "Et c’est probablement la chose la plus importante à retenir à propos du produit scalaire.",
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "time_range": [
   776.97,
   780.79
  ]
 },
 {
  "translatedText": "Mais à un niveau plus profond, relier deux vecteurs est une manière de traduire l’un d’eux dans le monde des transformations.",
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "time_range": [
   781.27,
   787.73
  ]
 },
 {
  "translatedText": "Encore une fois, numériquement, cela peut sembler un point idiot à souligner.",
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "time_range": [
   788.67,
   791.55
  ]
 },
 {
  "translatedText": "Ce ne sont que deux calculs qui se ressemblent.",
  "input": "It's just two computations that happen to look similar.",
  "time_range": [
   791.67,
   794.49
  ]
 },
 {
  "translatedText": "Mais la raison pour laquelle je trouve cela si important est que, en mathématiques, lorsque vous avez affaire à un vecteur, une fois que vous connaissez vraiment sa personnalité, vous réalisez parfois qu'il est plus facile de le comprendre non pas comme une flèche dans l'espace, mais comme une flèche dans l'espace. incarnation physique d'une transformation linéaire.",
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "time_range": [
   794.49,
   810.09
  ]
 },
 {
  "translatedText": "C'est comme si le vecteur n'était en réalité qu'un raccourci conceptuel pour une certaine transformation, puisqu'il nous est plus facile de penser à des flèches dans l'espace plutôt que de déplacer tout cet espace vers la droite numérique.",
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "time_range": [
   810.73,
   820.97
  ]
 },
 {
  "translatedText": "Dans la vidéo suivante, vous verrez un autre exemple vraiment sympa de cette dualité en action, alors que je parle du produit croisé.",
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "time_range": [
   822.61,
   829.19
  ]
 }
]