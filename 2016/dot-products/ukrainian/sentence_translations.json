[
 {
  "input": "Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "[Музика] Традиційно скалярний добуток вводиться в курс лінійної алгебри дуже рано, як правило, на початку.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "Тому може здатися дивним, що я відсунув їх так далеко в серії.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "Я зробив це тому, що існує стандартний спосіб ознайомлення з темою, який вимагає лише базового розуміння векторів, але більш повне розуміння ролі, яку скалярний добуток відіграє в математиці, можна знайти лише в світлі лінійних перетворень.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "Однак перед цим дозвольте мені коротко розповісти про стандартний спосіб введення точкових добутків, який, я припускаю, є принаймні частковим оглядом для кількох глядачів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "Чисельно, якщо у вас є два вектори однакової розмірності, два списки чисел однакової довжини, їх скалярний добуток означає поєднання всіх координат, множення цих пар разом і додавання результату.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "Отже, вектор 1, 2, позначений крапками 3, 4, буде 1 помножити на 3 плюс 2 помножити на 4.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "Вектор 6, 2, 8, 3, позначений 1, 8, 5, 3, буде 6 помножити на 1 плюс 2 помножити на 8 плюс 8 помножити на 5 плюс 3 помножити на 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "На щастя, це обчислення має справді гарну геометричну інтерпретацію.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "Щоб подумати про скалярний добуток між двома векторами, v і w, уявіть проектування w на пряму, яка проходить через початок і вершину v.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "Помноживши довжину цієї проекції на довжину v, ви отримаєте скалярний добуток v на точку w.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "За винятком випадків, коли ця проекція w вказує в протилежному напрямку від v, цей скалярний добуток насправді буде від’ємним.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "Отже, коли два вектори зазвичай спрямовані в одному напрямку, їх скалярний добуток додатний.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "Коли вони перпендикулярні, тобто проекція одного на інший є нульовим вектором, їх скалярний добуток дорівнює нулю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "І якщо вони вказують у протилежному напрямку, їх скалярний добуток буде від’ємним.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "Тепер ця інтерпретація дивно асиметрична.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "Він розглядає два вектори дуже по-різному.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "Тож коли я вперше про це дізнався, я був здивований, що порядок не має значення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "Натомість ви можете спроектувати v на w, помножити довжину спроектованої v на довжину w і отримати той самий результат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "Я маю на увазі, хіба це не виглядає як зовсім інший процес?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "Ось інтуїція, чому порядок не має значення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "Якби v і w мали однакову довжину, ми могли б застосувати певну симетрію.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "Оскільки проектування w на v і множення довжини цієї проекції на довжину v є повним дзеркальним відображенням проектування v на w і множення довжини цієї проекції на довжину w.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "Тепер, якщо ви масштабуєте одну з них, скажімо, v, на якусь константу, наприклад 2, щоб вони не мали однакову довжину, симетрія порушується.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "Але давайте подумаємо, як інтерпретувати скалярний добуток між цим новим вектором, 2 помноженим на v, і w.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "Якщо ви думаєте, що w проектується на v, тоді скалярний добуток 2v dot w точно вдвічі перевищує скалярний добуток v dot w.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "Це тому, що коли ви масштабуєте v на 2, це не змінює довжину проекції w, але подвоює довжину вектора, на який ви проектуєте.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "Але з іншого боку, скажімо, ви думали про проектування v на w.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "Ну, у такому випадку довжина проекції – це те, що масштабується, коли ми множимо v на 2, але довжина вектора, на який ви проектуєте, залишається постійною.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "Таким чином, загальний ефект все ще полягає в подвоєнні скалярного добутку.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "Таким чином, незважаючи на те, що в цьому випадку симетрія порушена, ефект, який це масштабування має на значення скалярного добутку, є однаковим в обох інтерпретаціях.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "Є ще одне важливе питання, яке мене збентежило, коли я вперше дізнався про це.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "Чому цей числовий процес зіставлення координат, множення пар і їх додавання має щось спільне з проекцією?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "Що ж, щоб дати задовільну відповідь, а також щоб повністю віддати належне значенню скалярного добутку, нам потрібно розкопати дещо глибше, що тут відбувається, що часто називають подвійністю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "Але перш ніж приступити до цього, мені потрібно витратити трохи часу на розмову про лінійні перетворення від кількох вимірів до одного виміру, який є просто числовим рядком.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "Це функції, які приймають 2d-вектор і видають певне число, але лінійні перетворення, звичайно, набагато обмеженіші, ніж ваша звичайна функція з 2d-введенням і 1d-виходом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "Як і у випадку з перетвореннями у вищих вимірах, подібних до тих, про які я говорив у розділі 3, існують деякі формальні властивості, які роблять ці функції лінійними, але я навмисно ігноруватиму їх тут, щоб не відволікати від нашої кінцевої мети, а натомість зосередитися на певній візуальній властивості, яка еквівалентна всім формальним речам.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "Якщо ви візьмете рядок із рівномірно розташованими крапками та застосуєте перетворення, лінійне перетворення збереже ці крапки рівномірними, коли вони потраплять у вихідний простір, який є числовим рядком.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "Інакше, якщо є якась лінія точок, розташованих нерівномірно, то ваше перетворення не є лінійним.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "Як і у випадках, які ми бачили раніше, одне з цих лінійних перетворень повністю визначається тим, куди воно бере i-hat та j-hat, але цього разу кожен із цих базисних векторів просто потрапляє на число, тому коли ми записуємо, де вони розташовані як стовпці матриці, кожен із цих стовпців має лише одне число.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "Це матриця 1x2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "Давайте на прикладі розглянемо, що означає застосувати одне з цих перетворень до вектора.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "Скажімо, у вас є лінійне перетворення, яке переводить i-hat до 1, а j-hat до мінус 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "Щоб визначити, де закінчується вектор із координатами, скажімо, 4, 3, подумайте про розбиття цього вектора на 4 помножені на i-hat плюс 3 на j-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "Наслідком лінійності є те, що після перетворення вектор буде в 4 рази більше місця, де приземляється i-hat, 1, плюс у 3 рази більше місця, де приземляється j-hat, мінус 2, що в цьому випадку означає, що він приземляється на від’ємному 2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "Коли ви виконуєте це обчислення чисто чисельно, це множення матриці на вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "Ця чисельна операція множення матриці 1x2 на вектор схожа на скалярний добуток двох векторів.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "Хіба ця матриця 1x2 не схожа на вектор, який ми перекинули на бік?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "Насправді ми можемо сказати прямо зараз, що між матрицями 1x2 і 2D-векторами існує хороший зв’язок, який визначається нахилом числового представлення вектора на бік, щоб отримати пов’язану матрицю, або нахилом матриці назад, щоб отримати пов’язаний вектор.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "Оскільки зараз ми просто розглядаємо числові вирази, перехід між векторами та матрицями 1x2 може здатися безглуздим.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "Але це говорить про те, що є справді чудовим з геометричної точки зору.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "Існує певний зв’язок між лінійними перетвореннями, які перетворюють вектори в числа, і самими векторами.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "Дозвольте мені показати приклад, який пояснює значення, і який, випадково, також відповідає на головоломку скалярного добутку з попереднього.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "Відмовтеся від того, що ви навчилися, і уявіть, що ви ще не знаєте, що скалярний добуток пов’язаний з проекцією.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "Що я збираюся зробити тут, так це взяти копію числової прямої та розташувати її якось по діагоналі в просторі, з числом 0 у початку координат.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "Тепер подумайте про двовимірний одиничний вектор, кінчик якого знаходиться там, де цифра 1 на числовій прямій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "Я хочу дати цьому хлопцю ім'я, U-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "Цей маленький хлопець відіграє важливу роль у тому, що має статися, тож пам’ятайте про нього.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "Якщо ми спроектуємо 2D-вектори прямо на цю діагональну числову пряму, фактично ми щойно визначили функцію, яка перетворює 2D-вектори в числа.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "Більше того, ця функція фактично є лінійною, оскільки вона проходить наш візуальний тест на те, що будь-яка лінія рівномірно розташованих крапок залишається рівномірною, коли потрапляє на числову пряму.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "Щоб було зрозуміло, незважаючи на те, що я вставив числову пряму в двовимірний простір таким чином, виходом функції є числа, а не двовимірні вектори.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "Ви повинні подумати про функцію, яка приймає дві координати та виводить одну координату.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "Але цей векторний капелюх є двовимірним вектором, що живе у вхідному просторі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "Він просто розташований таким чином, що накладається на вкладення числової прямої.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "За допомогою цієї проекції ми щойно визначили лінійне перетворення від 2D-векторів до чисел, тому ми зможемо знайти якусь матрицю 1x2, яка описує це перетворення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "Щоб знайти цю матрицю 1x2, давайте збільшимо масштаб цієї діагональної числової прямої та подумаємо про те, куди потрапляють I-hat і J-hat, оскільки ці точки посадки будуть стовпцями матриці.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "Ця частина супер крута.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "Ми можемо міркувати через це за допомогою справді елегантної симетрії.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "Оскільки I-hat і U-hat є одиничними векторами, проектування I-hat на пряму, що проходить через U-hat, виглядає абсолютно симетричним до проектування U-hat на вісь x.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "Отже, коли ми запитуємо, на яке число потрапляє капелюх «І», коли його проектують, відповідь буде такою ж, як і на будь-яке, на яке потрапляє «капелюх», коли він проектується на вісь х.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "Але проектування U-капелюха на вісь x означає лише взяття координати x U-капелюха.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "Відповідно до симетрії, число, куди потрапляє I-hat, коли його проектують на цю діагональну числову пряму, буде координатою x U-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "Хіба це не круто?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "Аргументація майже ідентична для справи J-hat.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "Подумайте про це на мить.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "З усіх тих самих причин y-координата U-капелюха дає нам число, куди потрапляє J-капелюх, коли його проектують на копію числової лінії.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "Зупиніться і подумайте про це на мить.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "Я просто думаю, що це дійсно круто.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "Отже, елементи матриці 1x2, що описують перетворення проекції, будуть координатами U-капелюха.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "І обчислення цього проекційного перетворення для довільних векторів у просторі, яке вимагає множення цієї матриці на ці вектори, обчислювально ідентично отриманню скалярного добутку з U-капелюхом.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "Ось чому скалярний добуток на одиничний вектор можна інтерпретувати як проектування вектора на розмах цього одиничного вектора та взяття довжини.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "А як щодо неодиничних векторів?",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "Наприклад, скажімо, ми візьмемо цей U-образний вектор, але збільшимо його в 3 рази.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "Чисельно кожен із його компонентів множиться на 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "Таким чином, дивлячись на матрицю, пов’язану з цим вектором, вона приймає значення I-hat і J-hat в три рази більше, ніж вони були раніше.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "Оскільки все це лінійно, це означає, що нову матрицю можна інтерпретувати як проектування будь-якого вектора на копію числової прямої та множення там, де він потрапляє, на 3.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "Ось чому скалярний добуток із неодиничним вектором можна інтерпретувати як спочатку проектування на цей вектор, а потім збільшення довжини цієї проекції на довжину вектора.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "Подумайте на хвилинку про те, що тут сталося.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "Ми мали лінійне перетворення з двовимірного простору на числову пряму, яка не була визначена в термінах числових векторів чи числових скалярних добутків, вона була просто визначена шляхом проектування простору на діагональну копію числової прямої.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "Але оскільки перетворення є лінійним, воно обов’язково описується якоюсь матрицею 1x2.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "І оскільки помножити матрицю 1x2 на 2D-вектор — це те саме, що повернути цю матрицю на бік і взяти скалярний добуток, це перетворення неминуче пов’язане з деяким 2D-вектором.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "Урок тут полягає в тому, що кожного разу, коли у вас є одне з цих лінійних перетворень, вихідним простором якого є числова лінія, незалежно від того, як вона була визначена, буде якийсь унікальний вектор v, який відповідає цьому перетворенню, у тому сенсі, що застосування перетворення є те саме, що взяти скалярний добуток із цим вектором.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "Для мене це надзвичайно красиво.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "Це приклад того, що в математиці називається подвійністю.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "Подвійність проявляється у багатьох різних способах і формах у математиці, і її насправді дуже складно визначити.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "Грубо кажучи, це стосується ситуацій, коли у вас є природна, але дивовижна відповідність між двома типами математичних речей.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "Для випадку лінійної алгебри, про який ви щойно дізналися, ви б сказали, що подвійність вектора — це лінійне перетворення, яке він кодує, а подвійність лінійного перетворення з деякого простору в один вимір — це певний вектор у цьому просторі.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "Отже, підсумовуючи, на перший погляд скалярний добуток є дуже корисним геометричним інструментом для розуміння проекцій і для перевірки того, чи мають вектори тенденцію вказувати в одному напрямку.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "І це, мабуть, найважливіше, що вам потрібно пам’ятати про скалярний добуток.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "Але на глибшому рівні поєднання двох векторів — це спосіб перевести один із них у світ трансформацій.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "Знову ж таки, чисельно це може здатися безглуздим моментом, на якому слід наголошувати.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "Це занадто обчислювально.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "Але причина, чому я вважаю це таким важливим, полягає в тому, що в математиці, коли ви маєте справу з вектором, як тільки ви дійсно дізнаєтесь про його характер, іноді ви розумієте, що легше зрозуміти його не як стрілу в просторі, а як фізичне втілення лінійного перетворення.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "Схоже, що вектор — це просто концептуальне скорочення певного перетворення, оскільки нам легше думати про стрілки в просторі, а не переміщувати весь цей простір.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.15
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "У наступному відео ви побачите ще один дуже класний приклад цієї подвійності в дії, коли я говорю про перехресний добуток.",
  "model": "google_nmt",
  "n_reviews": 0,
  "start": 820.15,
  "end": 829.19
 }
]