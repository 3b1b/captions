[
 {
  "input": "Traditionally, dot products are something that's introduced really early on in a linear algebra course, typically right at the start.",
  "translatedText": "[&quot;Oda a la alegría&quot;, de Beethoven, se toca hasta el final del piano.] Tradicionalmente, los productos escalares son algo que se introduce muy temprano en un curso de álgebra lineal, normalmente desde el principio.",
  "from_community_srt": "Calvin: Sabes, no creo que la matemática sea una ciencia, creo que es una religión. Hobbes: ¿Una religión? Hobbes: ¿Una religión? Calvin: Sí. Todas estas ecuaciones son como milagros. Tomas dos números y luego cuando los sumas ¡mágicamente se vuelven un número NUEVO! Nadie puede decir cómo ocurre. Simplemente los crees o no. Tradicionalmente, el producto punto es algo que es introducido en las primeras partes de un curso de álgebra lineal usualmente en el comienzo.",
  "n_reviews": 0,
  "start": 16.58,
  "end": 26.3
 },
 {
  "input": "So it might seem strange that I've pushed them back this far in the series.",
  "translatedText": "Así que puede parecer extraño que los haya hecho retroceder hasta este punto en la serie.",
  "from_community_srt": "Así que puede parecer extraño que lo haya pospuesto tanto en la serie.",
  "n_reviews": 0,
  "start": 26.64,
  "end": 29.58
 },
 {
  "input": "I did this because there's a standard way to introduce the topic, which requires nothing more than a basic understanding of vectors, but a fuller understanding of the role that dot products play in math can only really be found under the light of linear transformations.",
  "translatedText": "Hice esto porque hay una forma estándar de presentar el tema, que no requiere más que una comprensión básica de los vectores, pero una comprensión más completa del papel que desempeñan los productos escalares en matemáticas solo se puede encontrar a la luz de las transformaciones lineales.",
  "from_community_srt": "Lo hice porque hay una manera estándar de introducir el tema la cual sólo requiere un conocimiento básico de los vectores, pero una comprensión más completa del papel que juego el producto punto en las matemáticas, sólo se puede obtener bajo la óptica de las transformaciones lineales.",
  "n_reviews": 0,
  "start": 29.58,
  "end": 42.44
 },
 {
  "input": "Before that, though, let me just briefly cover the standard way that dot products are introduced, which I'm assuming is at least partially review for a number of viewers.",
  "translatedText": "Antes de eso, sin embargo, permítanme cubrir brevemente la forma estándar en que se presentan los productos punto, que supongo que es al menos parcialmente una revisión para varios espectadores.",
  "from_community_srt": "Antes de esto, sin embargo, déjenme cubrir rápidamente la forma estándar como es introducido el producto punto, la cual asumo es por lo menos parcialmente un resúmen para muchos de ustedes.",
  "n_reviews": 0,
  "start": 43.48,
  "end": 50.62
 },
 {
  "input": "Numerically, if you have two vectors of the same dimension, two lists of numbers with the same lengths, taking their dot product means pairing up all of the coordinates, multiplying those pairs together, and adding the result.",
  "translatedText": "Numéricamente, si tienes dos vectores de la misma dimensión, dos listas de números con las mismas longitudes, tomar su producto escalar significa emparejar todas las coordenadas, multiplicar esos pares y sumar el resultado.",
  "from_community_srt": "Numéricamente, si tienen dos vectores de la misma dimensión; dos listas de números con la misma longitud, realizar su pruducto punto, quiere decir, emparejar todas las coordenadas, multiplicar esos pares, y sumar los resultados.",
  "n_reviews": 0,
  "start": 51.44,
  "end": 64.98
 },
 {
  "input": "So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4.",
  "translatedText": "Entonces, el vector 1, 2 punteado con 3, 4 sería 1 por 3 más 2 por 4.",
  "from_community_srt": "Así que el producto punto del vector [1,2] con el vector [3,4], sería 1 por 3,",
  "n_reviews": 0,
  "start": 66.86,
  "end": 73.18
 },
 {
  "input": "The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be 6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3.",
  "translatedText": "El vector 6, 2, 8, 3 punteado con 1, 8, 5, 3 sería 6 por 1 más 2 por 8 más 8 por 5 más 3 por 3.",
  "from_community_srt": "más 2 por 4. El vector [6,2,8,3] por el vector [1,8,5,3] sería: 6 por 1, más 2 por 8, más 8 por 5,",
  "n_reviews": 0,
  "start": 74.58,
  "end": 83.72
 },
 {
  "input": "Luckily, this computation has a really nice geometric interpretation.",
  "translatedText": "Afortunadamente, este cálculo tiene una interpretación geométrica realmente agradable.",
  "from_community_srt": "más 3 por 3. Afortunadamente este cómputo tiene una interpretación geométrica muy interesante.",
  "n_reviews": 0,
  "start": 84.74,
  "end": 88.66
 },
 {
  "input": "To think about the dot product between two vectors, v and w, imagine projecting w onto the line that passes through the origin and the tip of v.",
  "translatedText": "Para pensar en el producto escalar entre dos vectores, v y w, imagina proyectar w sobre la línea que pasa por el origen y la punta de v.",
  "from_community_srt": "Al pensar en el producto punto entre dos vectores, \"v\" y\"w\", Imaginen que proyectan \"w\" sobre la línea que pasa por el origen y la punta \"v\".",
  "n_reviews": 0,
  "start": 89.34,
  "end": 97.98
 },
 {
  "input": "Multiplying the length of this projection by the length of v, you have the dot product v dot w.",
  "translatedText": "Multiplicando la longitud de esta proyección por la longitud de v, se obtiene el producto escalar v punto w.",
  "from_community_srt": "Al multiplicar la longitud de esta proyección por la longitud de \"v\" obtienen el producto punto de \"v\" por \"w\".",
  "n_reviews": 0,
  "start": 98.78,
  "end": 104.46
 },
 {
  "input": "Except when this projection of w is pointing in the opposite direction from v, that dot product will actually be negative.",
  "translatedText": "Excepto cuando esta proyección de w apunta en la dirección opuesta a v, ese producto escalar en realidad será negativo.",
  "from_community_srt": "Excepto que cuando esta proyección de \"w\" apunte en la dirección opuesta a \"v\", ese producto punto en realidad sería negativo.",
  "n_reviews": 0,
  "start": 106.42,
  "end": 112.16
 },
 {
  "input": "So when two vectors are generally pointing in the same direction, their dot product is positive.",
  "translatedText": "Entonces, cuando dos vectores generalmente apuntan en la misma dirección, su producto escalar es positivo.",
  "from_community_srt": "Entonces, cuando dos vectores están más o menos apuntando en la misma dirección, su producto punto es positivo,",
  "n_reviews": 0,
  "start": 113.72,
  "end": 117.86
 },
 {
  "input": "When they're perpendicular, meaning the projection of one onto the other is the zero vector, their dot product is zero.",
  "translatedText": "Cuando son perpendiculares, es decir, la proyección de uno sobre el otro es el vector cero, su producto escalar es cero.",
  "from_community_srt": "cuando son perpendiculares, es decir, la proyección de uno sobre el otro es el vector cero,",
  "n_reviews": 0,
  "start": 119.24,
  "end": 125.56
 },
 {
  "input": "And if they point in generally the opposite direction, their dot product is negative.",
  "translatedText": "Y si apuntan generalmente en la dirección opuesta, su producto escalar es negativo.",
  "from_community_srt": "su producto punto es cero, y si apuntan más o menos en direcciones opuestas su producto punto es negativo.",
  "n_reviews": 0,
  "start": 125.98,
  "end": 129.6
 },
 {
  "input": "Now, this interpretation is weirdly asymmetric.",
  "translatedText": "Ahora bien, esta interpretación es extrañamente asimétrica.",
  "from_community_srt": "Esta interpretación es extrañamente asimétrica, trata a cada vector de manera muy diferente,",
  "n_reviews": 0,
  "start": 131.62,
  "end": 134.56
 },
 {
  "input": "It treats the two vectors very differently.",
  "translatedText": "Trata a los dos vectores de manera muy diferente.",
  "n_reviews": 0,
  "start": 134.8,
  "end": 136.5
 },
 {
  "input": "So when I first learned this, I was surprised that order doesn't matter.",
  "translatedText": "Entonces, cuando supe esto por primera vez, me sorprendió que el orden no importara.",
  "from_community_srt": "así que cuando vi esto por primera vez, me sorprendió que el orden no importara.",
  "n_reviews": 0,
  "start": 136.88,
  "end": 140.0
 },
 {
  "input": "You could instead project v onto w, multiply the length of the projected v by the length of w, and get the same result.",
  "translatedText": "En su lugar, podría proyectar v sobre w, multiplicar la longitud de la v proyectada por la longitud de w y obtener el mismo resultado.",
  "from_community_srt": "Pudieran más bien proyectar \"v\" sobre \"w\"; multiplicar la longitud de la proyección de \"v\" por la longitud de \"w\"",
  "n_reviews": 0,
  "start": 140.96,
  "end": 148.22
 },
 {
  "input": "I mean, doesn't that feel like a really different process?",
  "translatedText": "Quiero decir, ¿no parece un proceso realmente diferente?",
  "from_community_srt": "y obtener el mismo resultado.",
  "n_reviews": 0,
  "start": 150.4,
  "end": 152.84
 },
 {
  "input": "Here's the intuition for why order doesn't matter.",
  "translatedText": "Aquí está la intuición de por qué el orden no importa.",
  "from_community_srt": "¿Acaso no se siente como un proceso muy diferente? Ésta es la intuición de por qué el orden no importa:",
  "n_reviews": 0,
  "start": 155.32,
  "end": 157.76
 },
 {
  "input": "If v and w happened to have the same length, we could leverage some symmetry.",
  "translatedText": "Si v y w tuvieran la misma longitud, podríamos aprovechar cierta simetría.",
  "from_community_srt": "Si \"v\" y \"w\" sucede que tienen la misma longitud, podemos argumentar cierta simetría.",
  "n_reviews": 0,
  "start": 158.44,
  "end": 162.18
 },
 {
  "input": "Since projecting w onto v, then multiplying the length of that projection by the length of v, is a complete mirror image of projecting v onto w, then multiplying the length of that projection by the length of w.",
  "translatedText": "Dado que proyectar w sobre v, luego multiplicar la longitud de esa proyección por la longitud de v, es una imagen especular completa de proyectar v sobre w, luego multiplicar la longitud de esa proyección por la longitud de w.",
  "from_community_srt": "Dado que proyectar \"w\" sobre \"v\" y luego multiplicar la longitud de dicha proyección por la longitud de \"v\", es el reflejo de proyectar \"v\" sobre \"w\" y multiplicar la longitud de esa proyección por la longitud de \"w\"",
  "n_reviews": 0,
  "start": 163.08,
  "end": 175.24
 },
 {
  "input": "Now, if you scale one of them, say v, by some constant like 2, so that they don't have equal length, the symmetry is broken.",
  "translatedText": "Ahora, si escalas uno de ellos, digamos v, por alguna constante como 2, de modo que no tengan la misma longitud, la simetría se rompe.",
  "from_community_srt": "Ahora, si \"escalan\" a uno de ellos, digamos  a \"v\", por una constante como 2, de tal manera de que no tengan la misma logitud, la simetría se rompe.",
  "n_reviews": 0,
  "start": 177.28,
  "end": 184.36
 },
 {
  "input": "But let's think through how to interpret the dot product between this new vector, 2 times v, and w.",
  "translatedText": "Pero pensemos en cómo interpretar el producto escalar entre este nuevo vector, 2 por v, y w.",
  "from_community_srt": "Pero pensemos cómo interpretar el producto punto entre este nuevo vector,",
  "n_reviews": 0,
  "start": 185.02,
  "end": 190.04
 },
 {
  "input": "If you think of w as getting projected onto v, then the dot product 2v dot w will be exactly twice the dot product v dot w.",
  "translatedText": "Si piensa que w se proyecta sobre v, entonces el producto escalar 2v punto w será exactamente el doble del producto escalar v punto w.",
  "from_community_srt": "\"2v\", y \"w\". Si piensan que \"w\" se proyecta sobre \"v\" entonces el producto punto, \"2v\" por \"w\" sería exactamente el doble del producto \"v\" por \"w\".",
  "n_reviews": 0,
  "start": 190.88,
  "end": 199.72
 },
 {
  "input": "This is because when you scale v by 2, it doesn't change the length of the projection of w, but it doubles the length of the vector that you're projecting onto.",
  "translatedText": "Esto se debe a que cuando escalas v en 2, no cambia la longitud de la proyección de w, pero duplica la longitud del vector sobre el que estás proyectando.",
  "from_community_srt": "Esto es porque cuando \"escalan\" a \"v\" por 2 no cambian la longitud de la proyección de \"w\" pero se duplica la longitud del vector sobre el cual proyectan.",
  "n_reviews": 0,
  "start": 200.46,
  "end": 209.52
 },
 {
  "input": "But on the other hand, let's say you were thinking about v getting projected onto w.",
  "translatedText": "Pero, por otro lado, digamos que estás pensando en proyectar v sobre w.",
  "from_community_srt": "Pero por otro lado, digamos que piensan que \"v\" se proyecta sobre \"w\".",
  "n_reviews": 0,
  "start": 210.46,
  "end": 214.2
 },
 {
  "input": "Well, in that case, the length of the projection is the thing that gets scaled when we multiply v by 2, but the length of the vector that you're projecting onto stays constant.",
  "translatedText": "Bueno, en ese caso, la longitud de la proyección es lo que se escala cuando multiplicamos v por 2, pero la longitud del vector sobre el que estás proyectando se mantiene constante.",
  "from_community_srt": "Pues en ese caso, la longitud de la proyección es lo que es \"escalado\" cuando multiplicamos a \"v\" por 2. Pero la longitud del vector sorbe el cual proyectan se mantiene constante.",
  "n_reviews": 0,
  "start": 214.9,
  "end": 223.0
 },
 {
  "input": "So the overall effect is still to just double the dot product.",
  "translatedText": "Entonces, el efecto general sigue siendo simplemente duplicar el producto escalar.",
  "from_community_srt": "Entonces el efecto total sigue siendo el de duplicar el producto punto.",
  "n_reviews": 0,
  "start": 223.0,
  "end": 226.66
 },
 {
  "input": "So even though symmetry is broken in this case, the effect that this scaling has on the value of the dot product is the same under both interpretations.",
  "translatedText": "Entonces, aunque en este caso se rompe la simetría, el efecto que tiene esta escala sobre el valor del producto escalar es el mismo en ambas interpretaciones.",
  "from_community_srt": "Entonces, aún cuando la simetría se rompe en este caso, el efecto que tiene este \"escalamiento\" en el valor del producto punto,",
  "n_reviews": 0,
  "start": 227.28,
  "end": 234.86
 },
 {
  "input": "There's also one other big question that confused me when I first learned this stuff.",
  "translatedText": "También hay otra gran pregunta que me confundió cuando aprendí esto por primera vez.",
  "from_community_srt": "es el mismo en las dos interpretaciones.",
  "n_reviews": 0,
  "start": 236.64,
  "end": 240.34
 },
 {
  "input": "Why on earth does this numerical process of matching coordinates, multiplying pairs, and adding them together have anything to do with projection?",
  "translatedText": "¿Por qué diablos este proceso numérico de hacer coincidir coordenadas, multiplicar pares y sumarlos tiene algo que ver con la proyección?",
  "from_community_srt": "También hay otra pregunta importante que me confundió cuando vi esto por primera vez: ¿Por qué rayos este proceso numérico de emparejar coordenadas, multiplicar los pares y sumarlos, tiene algo que ver con proyecciones?",
  "n_reviews": 0,
  "start": 240.84,
  "end": 248.74
 },
 {
  "input": "Well, to give a satisfactory answer, and also to do full justice to the significance of the dot product, we need to unearth something a little bit deeper going on here, which often goes by the name duality.",
  "translatedText": "Bueno, para dar una respuesta satisfactoria, y también para hacer plena justicia a la importancia del producto escalar, necesitamos descubrir algo un poco más profundo que está sucediendo aquí, que a menudo recibe el nombre de dualidad.",
  "from_community_srt": "Bueno, para dar una respuesta satisfactoria, y también para hacerle justicia a la significatividad del producto punto, tenemos que desenterrar algo que está ocurriendo que es un poco más profundo, que usualmente se le da el nombre de dualidad.",
  "n_reviews": 0,
  "start": 250.64,
  "end": 261.4
 },
 {
  "input": "But before getting into that, I need to spend some time talking about linear transformations from multiple dimensions to one dimension, which is just the number line.",
  "translatedText": "Pero antes de entrar en eso, necesito dedicar algo de tiempo a hablar sobre transformaciones lineales de múltiples dimensiones a una dimensión, que es solo la recta numérica.",
  "from_community_srt": "Pero antes de entrar en eso, necesito dedicar un tiempo a hablar de transformaciones lineales que van de varias dimensiones a una dimensión que es simplemente la recta real.",
  "n_reviews": 0,
  "start": 262.14,
  "end": 270.04
 },
 {
  "input": "These are functions that take in a 2D vector and spit out some number, but linear transformations are of course much more restricted than your run-of-the-mill function with a 2D input and a 1D output.",
  "translatedText": "Estas son funciones que toman un vector 2D y escupen algún número, pero las transformaciones lineales son, por supuesto, mucho más restringidas que la función común y corriente con una entrada 2D y una salida 1D.",
  "from_community_srt": "Estas son funciones que reciben un vector 2-D y arrojan un número. Pero las transformaciones lineales son, por supuesto, mucho más restrictivas que una transformación cualquiera con dos dimensiones de entrada y una de salida.",
  "n_reviews": 0,
  "start": 272.42,
  "end": 282.3
 },
 {
  "input": "As with transformations in higher dimensions, like the ones I talked about in chapter 3, there are some formal properties that make these functions linear, but I'm going to purposefully ignore those here so as to not distract from our end goal, and instead focus on a certain visual property that's equivalent to all the formal stuff.",
  "translatedText": "Al igual que con las transformaciones en dimensiones superiores, como las que hablé en el capítulo 3, hay algunas propiedades formales que hacen que estas funciones sean lineales, pero voy a ignorarlas aquí a propósito para no distraernos de nuestro objetivo final, y en su lugar centrarse en una determinada propiedad visual que sea equivalente a todo el material formal.",
  "from_community_srt": "Así como las transformaciones en dimensiones mayores, como las que mencioné en el capítulo 3, hay unas propiedades formales que hacen a estas transformaciones lineales. pero voy a ignorarlas intencionalmente aquí para no distraernos de nuestra meta final, y más bien me enfocaré en una propiedad visual específica que es equivalente a todas las cosas formales.",
  "n_reviews": 0,
  "start": 283.02,
  "end": 298.26
 },
 {
  "input": "If you take a line of evenly spaced dots and apply a transformation, a linear transformation will keep those dots evenly spaced once they land in the output space, which is the number line.",
  "translatedText": "Si toma una línea de puntos espaciados uniformemente y aplica una transformación, una transformación lineal mantendrá esos puntos espaciados uniformemente una vez que lleguen al espacio de salida, que es la recta numérica.",
  "from_community_srt": "Si toman una línea de puntos equidistantes y les aplican una transformación, una transformación LINEAL  mantendrá a esos puntos equidistantes, una vez aterricen en el espacio de salida,",
  "n_reviews": 0,
  "start": 299.04,
  "end": 311.28
 },
 {
  "input": "Otherwise, if there's some line of dots that gets unevenly spaced, then your transformation is not linear.",
  "translatedText": "De lo contrario, si hay alguna línea de puntos que se espacia de manera desigual, entonces su transformación no es lineal.",
  "from_community_srt": "que es la recta real. De otra manera, si hay alguna línea de puntos que no se mantiene equidistante entonces su transformación no es lineal.",
  "n_reviews": 0,
  "start": 312.42,
  "end": 317.14
 },
 {
  "input": "As with the cases we've seen before, one of these linear transformations is completely determined by where it takes i-hat and j-hat, but this time each one of those basis vectors just lands on a number, so when we record where they land as the columns of a matrix, each of those columns just has a single number.",
  "translatedText": "Como en los casos que hemos visto antes, una de estas transformaciones lineales está completamente determinada por dónde toma i-hat y j-hat, pero esta vez cada uno de esos vectores base simplemente aterriza en un número, así que cuando registramos dónde aterrizan como las columnas de una matriz, cada una de esas columnas solo tiene un número.",
  "from_community_srt": "Como en los casos que hemos visto antes, cualquiera de estas transformaciones lineales está completamente definida por donde lleva a \"i\"y \"j\" pero esta vez, cada uno de los vectores bases simplemente cae en un número. Así que cuando registramos donde cayeron como las columnas de una matriz cada una de esas columnas sólo tiene un sólo número",
  "n_reviews": 0,
  "start": 319.22,
  "end": 336.82
 },
 {
  "input": "This is a 1x2 matrix.",
  "translatedText": "Esta es una matriz de 1x2.",
  "n_reviews": 0,
  "start": 338.46,
  "end": 339.84
 },
 {
  "input": "Let's walk through an example of what it means to apply one of these transformations to a vector.",
  "translatedText": "Veamos un ejemplo de lo que significa aplicar una de estas transformaciones a un vector.",
  "from_community_srt": "Esto es una matriz de 1x2. Veamos un ejemplo de qué quiere decir aplicar una de estas transformaciones a un vector.",
  "n_reviews": 0,
  "start": 341.86,
  "end": 345.66
 },
 {
  "input": "Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2.",
  "translatedText": "Digamos que tienes una transformación lineal que lleva i-hat a 1 y j-hat a menos 2.",
  "from_community_srt": "Digamos que tenemos una transformación lineal que lleva \"i\" a 1 y \"j\"a (-2.) Para ver dónde termina un vector con coordenadas,",
  "n_reviews": 0,
  "start": 346.38,
  "end": 351.68
 },
 {
  "input": "To follow where a vector with coordinates, say, 4, 3 ends up, think of breaking up this vector as 4 times i-hat plus 3 times j-hat.",
  "translatedText": "Para seguir dónde termina un vector con coordenadas, digamos, 4, 3, piense en dividir este vector como 4 veces i-hat más 3 veces j-hat.",
  "from_community_srt": "digamos, [4,3], piensen en escribir este vector como 4 por \"i\" más 3 por \"j\".",
  "n_reviews": 0,
  "start": 352.42,
  "end": 361.02
 },
 {
  "input": "A consequence of linearity is that after the transformation, the vector will be 4 times the place where i-hat lands, 1, plus 3 times the place where j-hat lands, negative 2, which in this case implies that it lands on negative 2.",
  "translatedText": "Una consecuencia de la linealidad es que después de la transformación, el vector será 4 veces el lugar donde aterriza i-hat, 1, más 3 veces el lugar donde aterriza j-hat, menos 2, lo que en este caso implica que aterriza en negativo 2.",
  "from_community_srt": "Una consecuencia de linealidad, es que después de la transformación el vector será: 4 por el lugar donde caiga \"i\", en este caso 1, más 3 por el lugar donde caiga \"j\", -2. Lo cual en este caso implica que cae en -2.",
  "n_reviews": 0,
  "start": 361.84,
  "end": 375.78
 },
 {
  "input": "When you do this calculation purely numerically, it's matrix vector multiplication.",
  "translatedText": "Cuando haces este cálculo puramente numérico, es una multiplicación de vectores matriciales.",
  "from_community_srt": "Cuando realizan este cálculo numéricamente,",
  "n_reviews": 0,
  "start": 378.02,
  "end": 382.36
 },
 {
  "input": "Now, this numerical operation of multiplying a 1x2 matrix by a vector feels just like taking the dot product of two vectors.",
  "translatedText": "Ahora bien, esta operación numérica de multiplicar una matriz de 1x2 por un vector es como tomar el producto escalar de dos vectores.",
  "from_community_srt": "hacen un producto matriz vector. Esta operación numérica de multiplicar una matriz de 1x2 por un vector, se siente como calcular el producto punto de dos vectores.",
  "n_reviews": 0,
  "start": 385.7,
  "end": 392.86
 },
 {
  "input": "Doesn't that 1x2 matrix just look like a vector that we tipped on its side?",
  "translatedText": "¿No parece esa matriz de 1x2 simplemente un vector que inclinamos de lado?",
  "n_reviews": 0,
  "start": 393.46,
  "end": 396.8
 },
 {
  "input": "In fact, we could say right now that there's a nice association between 1x2 matrices and 2D vectors, defined by tilting the numerical representation of a vector on its side to get the associated matrix, or to tip the matrix back up to get the associated vector.",
  "translatedText": "De hecho, podríamos decir ahora mismo que existe una buena asociación entre matrices 1x2 y vectores 2D, definida inclinando la representación numérica de un vector de lado para obtener la matriz asociada, o inclinando la matriz hacia arriba para obtener el vector asociado. .",
  "from_community_srt": "¿Acaso esa matriz de 1x2 no se ve como un vector visto de lado? De hecho podemos decir ahora que hay una interesante relación entre matrices de 1x2 y vectores 2-D, definida inclinando la representación numérica de un vector sobre su lado para obtener la matriz asociada, o volteando la matriz de vuelta hacia arriba para obtener el vector asociado.",
  "n_reviews": 0,
  "start": 397.96,
  "end": 412.58
 },
 {
  "input": "Since we're just looking at numerical expressions right now, going back and forth between vectors and 1x2 matrices might feel like a silly thing to do.",
  "translatedText": "Dado que ahora solo estamos viendo expresiones numéricas, ir y venir entre vectores y matrices de 1x2 puede parecer una tontería.",
  "from_community_srt": "Dado que sólo estamos viendo expresiones numéricas en este momento, ir de un lado al otro entre vectores y matrices de 1x2 puede parecer una cosa tonta que hacer.",
  "n_reviews": 0,
  "start": 413.56,
  "end": 420.86
 },
 {
  "input": "But this suggests something that's truly awesome from the geometric view.",
  "translatedText": "Pero esto sugiere algo que es realmente asombroso desde el punto de vista geométrico.",
  "n_reviews": 0,
  "start": 421.46,
  "end": 425.12
 },
 {
  "input": "There's some kind of connection between linear transformations that take vectors to numbers and vectors themselves.",
  "translatedText": "Existe algún tipo de conexión entre las transformaciones lineales que convierten los vectores en números y los propios vectores.",
  "from_community_srt": "Pero sugiere algo que es verdaderamente impresionante en la perspectiva geométrica: Hay algún tipo de conexión entre las transformaciones lineales que llevan vectores a números",
  "n_reviews": 0,
  "start": 425.38,
  "end": 431.72
 },
 {
  "input": "Let me show an example that clarifies the significance, and which just so happens to also answer the dot product puzzle from earlier.",
  "translatedText": "Permítanme mostrarles un ejemplo que aclara el significado y que resulta que también responde al enigma del producto escalar de antes.",
  "from_community_srt": "y los vectores en sí mismos. Déjenme mostrarles un ejemplo que aclare la significatividad y que además sucede que responde el problema del producto punto que mencioné antes.",
  "n_reviews": 0,
  "start": 434.78,
  "end": 441.38
 },
 {
  "input": "Unlearn what you have learned, and imagine that you don't already know that the dot product relates to projection.",
  "translatedText": "Desaprende lo que has aprendido e imagina que aún no sabes que el producto escalar se relaciona con la proyección.",
  "from_community_srt": "Desaprendan lo que aprendieron e imaginen que no saben que el producto punto se relaciona con proyectar.",
  "n_reviews": 0,
  "start": 442.14,
  "end": 447.18
 },
 {
  "input": "What I'm going to do here is take a copy of the number line and place it diagonally in space somehow, with the number 0 sitting at the origin.",
  "translatedText": "Lo que voy a hacer aquí es tomar una copia de la recta numérica y colocarla diagonalmente en el espacio de alguna manera, con el número 0 en el origen.",
  "from_community_srt": "Lo que voy a hacer aquí es tomar una copia de la recta real y colocarla diagonalmente en el espacio de alguna manera, con el número cero centrado en el origen.",
  "n_reviews": 0,
  "start": 448.86,
  "end": 456.06
 },
 {
  "input": "Now think of the two-dimensional unit vector whose tip sits where the number 1 on the number is.",
  "translatedText": "Ahora piense en el vector unitario bidimensional cuya punta se encuentra donde está el número 1 del número.",
  "from_community_srt": "Ahora piensen en el vector unitario bidimensional, cuya punta se encuentra en el número 1 de la recta real.",
  "n_reviews": 0,
  "start": 456.9,
  "end": 461.92
 },
 {
  "input": "I want to give that guy a name, u-hat.",
  "translatedText": "Quiero darle un nombre a ese tipo, u-sombrero.",
  "from_community_srt": "Le quiero dar un nombre a este sujeto:",
  "n_reviews": 0,
  "start": 462.4,
  "end": 464.56
 },
 {
  "input": "This little guy plays an important role in what's about to happen, so just keep him in the back of your mind.",
  "translatedText": "Este pequeño juega un papel importante en lo que está por suceder, así que mantenlo en el fondo de tu mente.",
  "from_community_srt": "\"u\". Este pequeño sujeto juega un papel importante en lo que está por suceder, así que guárdenlo en sus mentes.",
  "n_reviews": 0,
  "start": 465.62,
  "end": 470.02
 },
 {
  "input": "If we project 2d vectors straight onto this diagonal number line, in effect, we've just defined a function that takes 2d vectors to numbers.",
  "translatedText": "Si proyectamos vectores 2d directamente sobre esta recta numérica diagonal, en efecto, acabamos de definir una función que convierte vectores 2d en números.",
  "from_community_srt": "si proyectamos vectores 2-D sobre esta recta real diaonal, en efecto, hemos definido una función que lleva vectores 2-D a números.",
  "n_reviews": 0,
  "start": 470.74,
  "end": 478.96
 },
 {
  "input": "What's more, this function is actually linear, since it passes our visual test that any line of evenly spaced dots remains evenly spaced once it lands on the number line.",
  "translatedText": "Es más, esta función es en realidad lineal, ya que pasa nuestra prueba visual de que cualquier línea de puntos espaciados uniformemente permanece igualmente espaciada una vez que llega a la recta numérica.",
  "from_community_srt": "Es más, esta función es además lineal dado que pasa nuestra prueba visual de que cualquier línea de puntos equidistantes se mantiene equidistante una vez aterrice en la recta real.",
  "n_reviews": 0,
  "start": 479.66,
  "end": 488.96
 },
 {
  "input": "Just to be clear, even though I've embedded the number line in 2d space like this, the outputs of the function are numbers, not 2d vectors.",
  "translatedText": "Para que quede claro, aunque he incrustado la recta numérica en un espacio 2D como este, las salidas de la función son números, no vectores 2D.",
  "from_community_srt": "Sólo para aclarar, aún cuando he integrado la recta real al espacio 2-D así, la salida de la función son números, no vectores 2-D.",
  "n_reviews": 0,
  "start": 491.64,
  "end": 499.28
 },
 {
  "input": "You should think of a function that takes in two coordinates and outputs a single coordinate.",
  "translatedText": "Deberías pensar en una función que tome dos coordenadas y genere una sola coordenada.",
  "from_community_srt": "Deberían pensar en una función que toma dos coordenadas y arroja una sola coordenada.",
  "n_reviews": 0,
  "start": 499.96,
  "end": 503.68
 },
 {
  "input": "But that vector u-hat is a two-dimensional vector, living in the input space.",
  "translatedText": "Pero ese vector u-hat es un vector bidimensional que vive en el espacio de entrada.",
  "from_community_srt": "Pero ese vector \"u\" SÍ es un vector bidimensional que vive en el espacio de entrada.",
  "n_reviews": 0,
  "start": 505.06,
  "end": 509.02
 },
 {
  "input": "It's just situated in such a way that overlaps with the embedding of the number line.",
  "translatedText": "Simplemente está situado de tal manera que se superpone con la incrustación de la recta numérica.",
  "from_community_srt": "Sólo que está situado de tal manera que se superpone con la recta real que se definió.",
  "n_reviews": 0,
  "start": 509.44,
  "end": 513.22
 },
 {
  "input": "With this projection, we just defined a linear transformation from 2d vectors to numbers, so we're going to be able to find some kind of 1x2 matrix that describes that transformation.",
  "translatedText": "Con esta proyección, acabamos de definir una transformación lineal de vectores 2d a números, por lo que podremos encontrar algún tipo de matriz de 1x2 que describa esa transformación.",
  "from_community_srt": "Con esta proyección, hemos definido una transformación lineal que va de vectores 2-D a números, así que seremos capaces de encontrar alguna matriz de 1x2 que describa a esa transformación.",
  "n_reviews": 0,
  "start": 514.6,
  "end": 524.6
 },
 {
  "input": "To find that 1x2 matrix, let's zoom in on this diagonal number line setup and think about where i-hat and j-hat each land, since those landing spots are going to be the columns of the matrix.",
  "translatedText": "Para encontrar esa matriz de 1x2, acerquémonos a esta configuración de línea numérica diagonal y pensemos en dónde aterrizan i-hat y j-hat, ya que esos puntos de aterrizaje serán las columnas de la matriz.",
  "from_community_srt": "Para encontrar esa matriz de 1x2 hagamos zoom a esta disposición con la recta real que hemos hecho y pensemos en dónde caen \"i\" y \"j\". dado que los sitios donde caigan serán las columnas de la matriz.",
  "n_reviews": 0,
  "start": 525.54,
  "end": 536.46
 },
 {
  "input": "This part's super cool.",
  "translatedText": "Esta parte es genial.",
  "from_community_srt": "Esta parte es súper fina,",
  "n_reviews": 0,
  "start": 538.48,
  "end": 539.44
 },
 {
  "input": "We can reason through it with a really elegant piece of symmetry.",
  "translatedText": "Podemos razonarlo con una pieza de simetría realmente elegante.",
  "n_reviews": 0,
  "start": 539.7,
  "end": 542.42
 },
 {
  "input": "Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis.",
  "translatedText": "Dado que i-hat y u-hat son vectores unitarios, proyectar i-hat sobre la línea que pasa por u-hat parece totalmente simétrico a proyectar u-hat sobre el eje x.",
  "from_community_srt": "podemos razonarla con un argumento de simetría muy elegante: Dado que \"i\" y \"j\" son ambos vectores unitarios, proyectar \"i\" sobre la línea que pasa por \"u\" es completamente simétrico a proyectar \"u\" sobre el eje \"x\".",
  "n_reviews": 0,
  "start": 543.02,
  "end": 553.16
 },
 {
  "input": "So when we ask what number does i-hat land on when it gets projected, the answer is going to be the same as whatever u-hat lands on when it's projected onto the x-axis.",
  "translatedText": "Entonces, cuando preguntamos en qué número aterriza i-hat cuando se proyecta, la respuesta será la misma que cualquier número en el que aterriza u-hat cuando se proyecta sobre el eje x.",
  "from_community_srt": "Así que cuando preguntamos en que número cae  \"i\" cuando es proyectado la respuesta será la misma que dónde caiga \"u\" cuando es proyectado sobre el eje \"x\"",
  "n_reviews": 0,
  "start": 553.84,
  "end": 562.32
 },
 {
  "input": "But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat.",
  "translatedText": "Pero proyectar u-hat sobre el eje x solo significa tomar la coordenada x de u-hat.",
  "from_community_srt": "pero proyectar \"u\" sobre el eje \"x\" es simplemente tomar la coordenada \"x\" de \"u\".",
  "n_reviews": 0,
  "start": 562.92,
  "end": 568.6
 },
 {
  "input": "So by symmetry, the number where i-hat lands when it's projected onto that diagonal number line is going to be the x-coordinate of u-hat.",
  "translatedText": "Entonces, por simetría, el número donde aterriza i-hat cuando se proyecta sobre esa recta numérica diagonal será la coordenada x de u-hat.",
  "from_community_srt": "Así, por simetría, el número donde caiga \"i\" cuando es proyectado sobre esa recta real diagonal será la coordenada \"x\"de \"u\"",
  "n_reviews": 0,
  "start": 569.02,
  "end": 576.62
 },
 {
  "input": "Isn't that cool?",
  "translatedText": "¿No es genial?",
  "n_reviews": 0,
  "start": 577.16,
  "end": 577.66
 },
 {
  "input": "The reasoning is almost identical for the j-hat case.",
  "translatedText": "El razonamiento es casi idéntico para el caso j-hat.",
  "from_community_srt": "¿No es eso fino? El razonamiento es casi idéntica para el caso de \"j\" Piénsenlo por un momento.",
  "n_reviews": 0,
  "start": 579.2,
  "end": 581.8
 },
 {
  "input": "Think about it for a moment.",
  "translatedText": "Piensa un momento en ello.",
  "n_reviews": 0,
  "start": 582.18,
  "end": 583.26
 },
 {
  "input": "For all the same reasons, the y-coordinate of u-hat gives us the number where j-hat lands when it's projected onto the number line copy.",
  "translatedText": "Por las mismas razones, la coordenada y de u-hat nos da el número donde aterriza j-hat cuando se proyecta en la copia de la recta numérica.",
  "from_community_srt": "Por las mismas razones, la coordenada \"y\" de \"u\" nos da el número donde cae \"j\" cuando es proyectado sobre la copia de la recta real.",
  "n_reviews": 0,
  "start": 589.12,
  "end": 596.6
 },
 {
  "input": "Pause and ponder that for a moment.",
  "translatedText": "Haga una pausa y reflexione sobre eso por un momento.",
  "from_community_srt": "Pausen y reflexionen sobre eso un momento;",
  "n_reviews": 0,
  "start": 597.58,
  "end": 598.72
 },
 {
  "input": "I just think that's really cool.",
  "translatedText": "Creo que eso es realmente genial.",
  "from_community_srt": "simplemente creo que es algo muy genial.",
  "n_reviews": 0,
  "start": 598.78,
  "end": 600.2
 },
 {
  "input": "So the entries of the 1x2 matrix describing the projection transformation are going to be the coordinates of u-hat.",
  "translatedText": "Entonces, las entradas de la matriz 1x2 que describe la transformación de proyección serán las coordenadas de u-hat.",
  "from_community_srt": "Entonces los coefcientes de la matriz de 1x2 describiendo la transformación de proyección serán las coordenadasde \"u\".",
  "n_reviews": 0,
  "start": 600.92,
  "end": 607.26
 },
 {
  "input": "And computing this projection transformation for arbitrary vectors in space, which requires multiplying that matrix by those vectors, is computationally identical to taking a dot product with u-hat.",
  "translatedText": "Y calcular esta transformación de proyección para vectores arbitrarios en el espacio, que requiere multiplicar esa matriz por esos vectores, es computacionalmente idéntico a tomar un producto escalar con u-hat.",
  "from_community_srt": "Y computar esta transformación de proyección para vectores arbitrarios en el espacio, lo cual requiere multiplicar esa matriz por esos vectores, es computacionalmente idéntico a tomar el producto punto con \"u\".",
  "n_reviews": 0,
  "start": 608.04,
  "end": 618.88
 },
 {
  "input": "This is why taking the dot product with a unit vector can be interpreted as projecting a vector onto the span of that unit vector and taking the length.",
  "translatedText": "Es por eso que tomar el producto escalar con un vector unitario puede interpretarse como proyectar un vector en el tramo de ese vector unitario y tomar la longitud.",
  "from_community_srt": "Esto es el por qué hacer el producto punto por un vector unitario, puede ser interpretado como proyectar ese vector al espacio generado por el vector unitario y tomar la longitud de esa proyección.",
  "n_reviews": 0,
  "start": 621.46,
  "end": 630.59
 },
 {
  "input": "So what about non-unit vectors?",
  "translatedText": "Entonces, ¿qué pasa con los vectores no unitarios?",
  "from_community_srt": "¿Y qué pasa con los vectores que no son unitarios? Por ejemplo,",
  "n_reviews": 0,
  "start": 634.03,
  "end": 635.79
 },
 {
  "input": "For example, let's say we take that unit vector u-hat, but we scale it up by a factor of 3.",
  "translatedText": "Por ejemplo, digamos que tomamos ese vector unitario u-hat, pero lo ampliamos en un factor de 3.",
  "from_community_srt": "digamos que tomamos ese vector unitario \"u\", pero lo \"escalamos\" por un factor de 3.",
  "n_reviews": 0,
  "start": 636.31,
  "end": 640.63
 },
 {
  "input": "Numerically, each of its components gets multiplied by 3.",
  "translatedText": "Numéricamente, cada uno de sus componentes se multiplica por 3.",
  "from_community_srt": "Numéricamente,",
  "n_reviews": 0,
  "start": 641.35,
  "end": 644.39
 },
 {
  "input": "So looking at the matrix associated with that vector, it takes i-hat and j-hat to three times the values where they landed before.",
  "translatedText": "Entonces, al observar la matriz asociada con ese vector, i-hat y j-hat alcanzan tres veces los valores donde aterrizaron antes.",
  "from_community_srt": "cada uno de sus componentes es multiplicado por 3, así que observando a la matriz asociada con ese vector, lleva a \"i\" y a \"j\" a los valores donde cayeron antes multiplicados por 3.",
  "n_reviews": 0,
  "start": 644.81,
  "end": 652.39
 },
 {
  "input": "Since this is all linear, it implies more generally that the new matrix can be interpreted as projecting any vector onto the number line copy and multiplying where it lands by 3.",
  "translatedText": "Dado que todo esto es lineal, implica de manera más general que la nueva matriz puede interpretarse como proyectar cualquier vector en la copia de la recta numérica y multiplicar donde aterriza por 3.",
  "from_community_srt": "Dado que todo esto es lineal, implica de manera más general, que la nueva matriz puede ser interpretada como que proyecta cualquier vector a la copia de la recta real y luego multiplica donde caiga por 3.",
  "n_reviews": 0,
  "start": 655.23,
  "end": 664.65
 },
 {
  "input": "This is why the dot product with a non-unit vector can be interpreted as first projecting onto that vector, then scaling up the length of that projection by the length of the vector.",
  "translatedText": "Esta es la razón por la que el producto escalar con un vector no unitario se puede interpretar como una proyección primero sobre ese vector y luego un aumento de la longitud de esa proyección según la longitud del vector.",
  "from_community_srt": "Esto es el por qué el producto punto por un vector no unitario puede ser interpretado como primero proyectar sobre ese vector y luego escalar la longitud de esa proyección por la longitud del vector.",
  "n_reviews": 0,
  "start": 665.47,
  "end": 674.95
 },
 {
  "input": "Take a moment to think about what happened here.",
  "translatedText": "Tómate un momento para pensar en lo que pasó aquí.",
  "from_community_srt": "Tómense un momento para pensar en lo que acaba de suceder.",
  "n_reviews": 0,
  "start": 677.59,
  "end": 679.55
 },
 {
  "input": "We had a linear transformation from 2D space to the number line, which was not defined in terms of numerical vectors or numerical dot products, it was just defined by projecting space onto a diagonal copy of the number line.",
  "translatedText": "Tuvimos una transformación lineal del espacio 2D a la recta numérica, que no se definió en términos de vectores numéricos o productos escalares numéricos, simplemente se definió proyectando el espacio sobre una copia diagonal de la recta numérica.",
  "from_community_srt": "Teníamos una transformación lineal del espacio 2-D a la recta real, la cual no estaba definida en términos de vectores numéricos o un producto punto numérico. Sólo estaba definido como proyectar el espacio sobre una copia diagonal de la recta real Pero dado que la transformación es lineal,",
  "n_reviews": 0,
  "start": 679.89,
  "end": 690.89
 },
 {
  "input": "But because the transformation is linear, it was necessarily described by some 1x2 matrix.",
  "translatedText": "Pero como la transformación es lineal, necesariamente se describió mediante alguna matriz de 1x2.",
  "n_reviews": 0,
  "start": 691.67,
  "end": 696.83
 },
 {
  "input": "And since multiplying a 1x2 matrix by a 2D vector is the same as turning that matrix on its side and taking a dot product, this transformation was inescapably related to some 2D vector.",
  "translatedText": "Y dado que multiplicar una matriz de 1x2 por un vector 2D es lo mismo que girar esa matriz de lado y tomar un producto escalar, esta transformación estaba ineludiblemente relacionada con algún vector 2D.",
  "from_community_srt": "necesariamente era descrita por una matriz de 1x2, y dado que multiplicar una matriz 1x2 por un vector 2-D es lo mismo que voltear esa matriz y tomar el producto punto, esta transformación estaba, ineludiblemente,",
  "n_reviews": 0,
  "start": 697.33,
  "end": 707.91
 },
 {
  "input": "The lesson here is that any time you have one of these linear transformations whose output space is the number line, no matter how it was defined, there's going to be some unique vector v corresponding to that transformation, in the sense that applying the transformation is the same thing as taking a dot product with that vector.",
  "translatedText": "La lección aquí es que cada vez que tienes una de estas transformaciones lineales cuyo espacio de salida es la recta numérica, sin importar cómo se definió, habrá algún vector único v correspondiente a esa transformación, en el sentido de que aplicar la transformación es lo mismo que tomar un producto escalar con ese vector.",
  "from_community_srt": "relacionada con un vector 2-D. La lección aquí, es que cada vez que tengan una de estas transformaciones lineales cuyo espacio de salida es la recta real, sin importar cómo fuera definida habrá un vector único \"v\" correspondiente a esa transformación, en el sentido de que aplicar la transformación es lo mismo que aplicar el producto punto por ese vector.",
  "n_reviews": 0,
  "start": 709.41,
  "end": 726.35
 },
 {
  "input": "To me, this is utterly beautiful.",
  "translatedText": "Para mí, esto es absolutamente hermoso.",
  "from_community_srt": "Para mí esto es absolutamente hermoso.",
  "n_reviews": 0,
  "start": 729.93,
  "end": 732.03
 },
 {
  "input": "It's an example of something in math called duality.",
  "translatedText": "Es un ejemplo de algo en matemáticas llamado dualidad.",
  "from_community_srt": "Es un ejemplo de algo en las matemáticas llamado dualidad.",
  "n_reviews": 0,
  "start": 732.73,
  "end": 735.39
 },
 {
  "input": "Duality shows up in many different ways and forms throughout math, and it's super tricky to actually define.",
  "translatedText": "La dualidad aparece de muchas maneras y formas diferentes en las matemáticas, y es muy complicado definirla.",
  "from_community_srt": "La dualidad aparece de muchas maneras a lo largo de las matemáticas y es muy complicada de definir con exactitud.",
  "n_reviews": 0,
  "start": 736.27,
  "end": 741.93
 },
 {
  "input": "Loosely speaking, it refers to situations where you have a natural but surprising correspondence between two types of mathematical thing.",
  "translatedText": "En términos generales, se refiere a situaciones en las que existe una correspondencia natural pero sorprendente entre dos tipos de elementos matemáticos.",
  "from_community_srt": "De manera general se refiere a situaciones en donde tienen una correspondencia natural pero sorprendente entre dos tipos de objetos matemáticos.",
  "n_reviews": 0,
  "start": 742.67,
  "end": 750.23
 },
 {
  "input": "For the linear algebra case that you just learned about, you'd say that the dual of a vector is the linear transformation that it encodes, and the dual of a linear transformation from some space to one dimension is a certain vector in that space.",
  "translatedText": "Para el caso de álgebra lineal que acabas de aprender, dirías que el dual de un vector es la transformación lineal que codifica, y el dual de una transformación lineal de algún espacio a una dimensión es un determinado vector en ese espacio.",
  "from_community_srt": "Para el caso de álgebra lineal del que acaban de aprender, dirían que el \"dual\" de un vector es la transformación lineal que representa. y el dual de una transformación lineal de algún espacio a una dimensión, es algún vector en ese espacio.",
  "n_reviews": 0,
  "start": 751.01,
  "end": 764.65
 },
 {
  "input": "So to sum up, on the surface, the dot product is a very useful geometric tool for understanding projections and for testing whether or not vectors tend to point in the same direction.",
  "translatedText": "Entonces, para resumir, en la superficie, el producto escalar es una herramienta geométrica muy útil para comprender las proyecciones y para probar si los vectores tienden o no a apuntar en la misma dirección.",
  "from_community_srt": "Así que para resumir, en la superficie, el producto punto es una herramienta geométrica muy útil para entender proyecciones y para probar si dos vectores tienden a apuntar o no en la misma dirección.",
  "n_reviews": 0,
  "start": 766.73,
  "end": 776.31
 },
 {
  "input": "And that's probably the most important thing for you to remember about the dot product.",
  "translatedText": "Y eso es probablemente lo más importante que debes recordar sobre el producto escalar.",
  "from_community_srt": "Y esa es probablemente la parte más importante que deben recordar sobre el producto punto, pero a un nivel más profundo,",
  "n_reviews": 0,
  "start": 776.97,
  "end": 780.79
 },
 {
  "input": "But at a deeper level, dotting two vectors together is a way to translate one of them into the world of transformations.",
  "translatedText": "Pero a un nivel más profundo, unir dos vectores es una forma de traducir uno de ellos al mundo de las transformaciones.",
  "from_community_srt": "hacer el producto punto entre dos vectores es una forma de traducir a uno de ellos al mundo de las transformaciones:",
  "n_reviews": 0,
  "start": 781.27,
  "end": 787.73
 },
 {
  "input": "Again, numerically, this might feel like a silly point to emphasize.",
  "translatedText": "Una vez más, numéricamente, esto podría parecer un punto tonto que hay que enfatizar.",
  "from_community_srt": "De nuevo,",
  "n_reviews": 0,
  "start": 788.67,
  "end": 791.55
 },
 {
  "input": "It's just two computations that happen to look similar.",
  "translatedText": "Son sólo dos cálculos que parecen similares.",
  "from_community_srt": "numéricamente esto parece un punto un poco tonto en el que hacer énfasis, son sólo dos computaciones que sucede se ven similares.",
  "n_reviews": 0,
  "start": 791.67,
  "end": 794.49
 },
 {
  "input": "But the reason I find this so important is that throughout math, when you're dealing with a vector, once you really get to know its personality, sometimes you realize that it's easier to understand it not as an arrow in space, but as the physical embodiment of a linear transformation.",
  "translatedText": "Pero la razón por la que encuentro esto tan importante es que en matemáticas, cuando trabajas con un vector, una vez que realmente conoces su personalidad, a veces te das cuenta de que es más fácil entenderlo no como una flecha en el espacio, sino como el realización física de una transformación lineal.",
  "from_community_srt": "Pero la razón por la que esto me parece muy importante, es porque a lo largo de las matemáticas, cuando tratas con un vector, una vez conoces bien su personalidad a veces te das cuenta de que es más fácil entenderlo, no como una flecha en el espacio, sino como la manifestación física de una transformación lineal.",
  "n_reviews": 0,
  "start": 794.49,
  "end": 810.09
 },
 {
  "input": "It's as if the vector is really just a conceptual shorthand for a certain transformation, since it's easier for us to think about arrows in space rather than moving all of that space to the number line.",
  "translatedText": "Es como si el vector fuera en realidad sólo una abreviatura conceptual de una determinada transformación, ya que es más fácil para nosotros pensar en flechas en el espacio en lugar de mover todo ese espacio a la recta numérica.",
  "from_community_srt": "Es como si el vector fuera en realidad una abreviatura conceptual de una transformación particular, dado que es más fácil imaginarnos flechas en el espacio que imaginarnos mover todo ese espacio a la recta real.",
  "n_reviews": 0,
  "start": 810.73,
  "end": 820.97
 },
 {
  "input": "In the next video, you'll see another really cool example of this duality in action, as I talk about the cross product.",
  "translatedText": "En el siguiente video, verás otro ejemplo realmente interesante de esta dualidad en acción, mientras hablo sobre el producto cruzado.",
  "from_community_srt": "En el próximo video verán otro ejemplo de esta dualidad en acción cuando les hable del producto cruz.",
  "n_reviews": 0,
  "start": 822.61,
  "end": 829.19
 }
]