1
00:00:00,000 --> 00:00:24,760
Vektor eigen dan nilai eigen adalah salah satu

2
00:00:24,760 --> 00:00:26,460
topik yang menurut banyak siswa tidak intuitif.

3
00:00:26,460 --> 00:00:30,320
Hal-hal seperti, mengapa kita melakukan hal ini, dan apa maksud sebenarnya dari hal

4
00:00:30,320 --> 00:00:34,020
ini, sering kali dibiarkan begitu saja dalam lautan perhitungan yang tidak terjawab.

5
00:00:34,020 --> 00:00:37,340
Dan saat saya merilis video seri ini, banyak dari

6
00:00:37,340 --> 00:00:40,700
Anda berkomentar tentang menantikan memvisualisasikan topik ini secara khusus.

7
00:00:40,700 --> 00:00:44,700
Saya menduga alasannya bukan karena eigenthings menjadi

8
00:00:44,700 --> 00:00:46,460
rumit atau tidak dijelaskan dengan baik.

9
00:00:46,460 --> 00:00:51,020
Faktanya, ini relatif mudah, dan menurut saya

10
00:00:51,020 --> 00:00:52,020
sebagian besar buku mampu menjelaskannya dengan baik.

11
00:00:52,020 --> 00:00:56,500
Apa yang ingin saya lakukan adalah hal ini hanya masuk akal

12
00:00:56,500 --> 00:00:59,220
jika Anda memiliki pemahaman visual yang kuat untuk banyak topik sebelumnya.

13
00:00:59,220 --> 00:01:04,460
Yang terpenting di sini adalah Anda mengetahui cara berpikir

14
00:01:04,460 --> 00:01:09,140
matriks sebagai transformasi linier, namun Anda juga harus memahami

15
00:01:09,140 --> 00:01:10,780
hal-hal seperti determinan, sistem persamaan linier, dan perubahan basis.

16
00:01:10,780 --> 00:01:15,580
Kebingungan mengenai eigenstuff biasanya lebih berkaitan dengan fondasi yang goyah dalam salah

17
00:01:15,580 --> 00:01:20,420
satu topik ini dibandingkan dengan vektor eigen dan nilai eigen itu sendiri.

18
00:01:20,420 --> 00:01:25,500
Untuk memulai, pertimbangkan beberapa transformasi linier dalam dua dimensi, seperti yang ditunjukkan di sini.

19
00:01:25,500 --> 00:01:31,860
Ini memindahkan vektor basis i-hat ke koordinat 3, 0, dan j-hat ke 1, 2.

20
00:01:31,860 --> 00:01:36,860
Jadi direpresentasikan dengan matriks yang kolomnya 3, 0, dan 1, 2.

21
00:01:36,860 --> 00:01:42,020
Fokuslah pada apa yang dilakukannya pada satu vektor tertentu, dan pikirkan

22
00:01:42,020 --> 00:01:45,220
tentang rentang vektor tersebut, garis yang melalui titik asal dan ujungnya.

23
00:01:45,220 --> 00:01:48,460
Kebanyakan vektor akan kehilangan rentangnya selama transformasi.

24
00:01:48,500 --> 00:01:53,140
Maksud saya, akan terlihat sangat kebetulan jika tempat pendaratan

25
00:01:53,140 --> 00:01:57,500
vektor juga berada di suatu tempat di garis tersebut.

26
00:01:57,500 --> 00:02:02,380
Namun beberapa vektor khusus tetap berada pada rentangnya sendiri, yang berarti bahwa

27
00:02:02,380 --> 00:02:09,660
pengaruh matriks terhadap vektor tersebut hanyalah merenggangkan atau menekannya, seperti skalar.

28
00:02:09,660 --> 00:02:15,100
Untuk contoh spesifik ini, vektor basis i-hat adalah salah satu vektor khusus tersebut.

29
00:02:15,100 --> 00:02:19,940
Rentang i-hat adalah sumbu x, dan dari kolom pertama matriks terlihat

30
00:02:19,940 --> 00:02:26,500
bahwa i-hat berpindah sebanyak 3 kali, masih pada sumbu x tersebut.

31
00:02:26,500 --> 00:02:32,540
Terlebih lagi, karena cara kerja transformasi linier, vektor lain pada sumbu x juga

32
00:02:32,540 --> 00:02:38,580
hanya diregangkan sebanyak 3 kali, dan karenanya tetap berada pada rentangnya sendiri.

33
00:02:38,580 --> 00:02:42,760
Vektor yang sedikit lebih licik yang tetap berada pada

34
00:02:42,760 --> 00:02:44,880
rentangnya sendiri selama transformasi ini adalah negatif 1, 1.

35
00:02:44,880 --> 00:02:49,120
Itu akhirnya diregangkan dengan faktor 2.

36
00:02:49,120 --> 00:02:54,760
Dan lagi, linearitas akan menyiratkan bahwa vektor lain pada garis diagonal

37
00:02:54,760 --> 00:03:00,040
yang direntang oleh orang ini akan diregangkan sebanyak 2 kali.

38
00:03:00,040 --> 00:03:04,200
Dan untuk transformasi ini, itu semua adalah vektor

39
00:03:04,200 --> 00:03:05,860
dengan sifat khusus untuk tetap berada pada rentangnya.

40
00:03:05,860 --> 00:03:10,000
Garis yang berada pada sumbu x diregangkan sebanyak 3

41
00:03:10,000 --> 00:03:12,940
kali, dan garis diagonalnya diregangkan sebanyak 2 kali.

42
00:03:12,940 --> 00:03:16,600
Vektor lainnya akan diputar selama transformasi,

43
00:03:16,600 --> 00:03:22,700
sehingga menyimpang dari garis yang dibentangkannya.

44
00:03:22,700 --> 00:03:28,140
Seperti yang mungkin sudah Anda duga sekarang, vektor-vektor khusus ini disebut vektor eigen

45
00:03:28,140 --> 00:03:33,460
dari transformasi, dan setiap vektor eigen dikaitkan dengannya dengan apa yang disebut nilai

46
00:03:33,460 --> 00:03:40,620
eigen, yang merupakan faktor yang merenggangkan atau menekan vektor tersebut selama transformasi.

47
00:03:40,620 --> 00:03:44,220
Tentu saja, tidak ada yang istimewa tentang peregangan versus

48
00:03:44,220 --> 00:03:46,580
pemampatan atau fakta bahwa nilai eigen ini positif.

49
00:03:46,580 --> 00:03:51,820
Dalam contoh lain, Anda dapat memiliki vektor eigen dengan nilai eigen negatif

50
00:03:51,820 --> 00:03:57,460
1 setengah, artinya vektor tersebut dibalik dan diperas dengan faktor 1 setengah.

51
00:03:57,460 --> 00:04:01,580
Namun bagian yang penting di sini adalah ia tetap

52
00:04:01,580 --> 00:04:04,660
berada pada garis yang dibentangkannya tanpa terputar keluar.

53
00:04:04,660 --> 00:04:09,780
Untuk melihat sekilas mengapa hal ini berguna

54
00:04:09,780 --> 00:04:11,940
untuk dipikirkan, pertimbangkan beberapa rotasi tiga dimensi.

55
00:04:11,940 --> 00:04:17,780
Jika Anda dapat menemukan vektor eigen untuk rotasi tersebut, sebuah vektor yang

56
00:04:17,780 --> 00:04:23,020
tetap pada rentangnya sendiri, maka yang Anda temukan adalah sumbu rotasi.

57
00:04:23,020 --> 00:04:28,540
Dan jauh lebih mudah untuk memikirkan rotasi 3D dalam kaitannya

58
00:04:28,540 --> 00:04:33,880
dengan beberapa sumbu rotasi dan sudut rotasinya, daripada memikirkan matriks

59
00:04:33,880 --> 00:04:37,140
penuh 3 kali 3 yang terkait dengan transformasi tersebut.

60
00:04:37,140 --> 00:04:42,080
Dalam hal ini, nilai eigen yang sesuai haruslah 1, karena rotasi tidak

61
00:04:42,080 --> 00:04:48,180
pernah meregangkan atau menekan apa pun, sehingga panjang vektornya akan tetap sama.

62
00:04:48,180 --> 00:04:50,580
Pola ini banyak muncul dalam aljabar linier.

63
00:04:50,580 --> 00:04:55,420
Dengan transformasi linier apa pun yang dideskripsikan oleh sebuah matriks, Anda dapat

64
00:04:55,420 --> 00:05:00,120
memahami fungsinya dengan membaca kolom-kolom matriks ini sebagai titik awal vektor basis.

65
00:05:00,120 --> 00:05:04,180
Namun seringkali, cara yang lebih baik untuk memahami inti dari apa yang sebenarnya dilakukan transformasi linier,

66
00:05:04,220 --> 00:05:15,780
yang tidak terlalu bergantung pada sistem koordinat tertentu, adalah dengan mencari vektor eigen dan nilai eigen.

67
00:05:15,780 --> 00:05:19,980
Saya tidak akan membahas detail lengkap tentang metode penghitungan vektor eigen

68
00:05:19,980 --> 00:05:24,600
dan nilai eigen di sini, namun saya akan mencoba memberikan gambaran

69
00:05:24,600 --> 00:05:26,820
umum tentang ide komputasi yang paling penting untuk pemahaman konseptual.

70
00:05:26,820 --> 00:05:30,980
Secara simbolis, seperti inilah gagasan tentang vektor eigen.

71
00:05:30,980 --> 00:05:37,220
A adalah matriks yang mewakili suatu transformasi, dengan v sebagai vektor

72
00:05:37,220 --> 00:05:40,800
eigen, dan lambda adalah bilangan, yaitu nilai eigen yang bersesuaian.

73
00:05:40,800 --> 00:05:45,500
Maksud dari ungkapan ini adalah bahwa perkalian vektor-matriks, A kali v, memberikan hasil

74
00:05:45,500 --> 00:05:51,520
yang sama seperti hanya menskalakan vektor eigen v dengan beberapa nilai lambda.

75
00:05:51,520 --> 00:05:56,900
Jadi mencari vektor eigen dan nilai eigennya dari matriks A berarti

76
00:05:56,900 --> 00:06:02,420
mencari nilai v dan lambda yang membuat ungkapan ini benar.

77
00:06:02,420 --> 00:06:06,340
Agak canggung untuk mengerjakannya pada awalnya karena ruas kiri mewakili

78
00:06:06,340 --> 00:06:11,220
perkalian matriks-vektor, namun ruas kanan di sini adalah perkalian skalar-vektor.

79
00:06:11,220 --> 00:06:16,540
Jadi mari kita mulai dengan menulis ulang ruas kanan tersebut sebagai semacam perkalian

80
00:06:16,540 --> 00:06:21,740
matriks-vektor, menggunakan matriks yang memiliki efek menskalakan vektor apa pun dengan faktor lambda.

81
00:06:21,740 --> 00:06:26,260
Kolom-kolom matriks tersebut akan mewakili apa yang terjadi pada masing-masing vektor basis,

82
00:06:26,260 --> 00:06:31,580
dan setiap vektor basis hanya dikalikan dengan lambda, sehingga matriks ini akan

83
00:06:31,580 --> 00:06:36,360
mempunyai bilangan lambda di bawah diagonalnya, dengan nol di tempat lain.

84
00:06:36,360 --> 00:06:40,980
Cara umum untuk menulis orang ini adalah dengan memfaktorkan lambda tersebut dan menuliskannya sebagai

85
00:06:40,980 --> 00:06:45,980
lambda dikalikan i, dengan i adalah matriks identitas dengan matriks di bawah diagonal.

86
00:06:45,980 --> 00:06:50,260
Karena kedua ruasnya tampak seperti perkalian matriks-vektor, kita

87
00:06:50,260 --> 00:06:54,340
dapat mengurangkan ruas kanan tersebut dan memfaktorkan vnya.

88
00:06:54,420 --> 00:06:59,340
Jadi yang kita punya sekarang adalah matriks baru, A dikurangi lambda dikali identitas, dan

89
00:06:59,340 --> 00:07:05,860
kita mencari vektor v sehingga matriks baru ini, dikali v, menghasilkan vektor nol.

90
00:07:05,860 --> 00:07:11,420
Sekarang, ini akan selalu benar jika v itu sendiri adalah vektor nol, tapi itu membosankan.

91
00:07:11,420 --> 00:07:14,540
Yang kami inginkan adalah vektor eigen bukan nol.

92
00:07:14,540 --> 00:07:18,900
Dan jika Anda menonton bab 5 dan 6, Anda akan tahu bahwa satu-satunya

93
00:07:18,900 --> 00:07:24,940
cara agar hasil kali matriks dengan vektor bukan nol menjadi nol adalah jika

94
00:07:24,940 --> 00:07:29,940
transformasi yang terkait dengan matriks tersebut menekan ruang ke dimensi yang lebih rendah.

95
00:07:29,940 --> 00:07:35,560
Dan pemerasan itu sesuai dengan determinan nol untuk matriks tersebut.

96
00:07:35,560 --> 00:07:41,700
Untuk lebih konkretnya, misalkan matriks A Anda memiliki kolom 2, 1 dan 2,

97
00:07:41,700 --> 00:07:46,600
3, dan pikirkan tentang mengurangkan jumlah variabel, lambda, dari setiap entri diagonal.

98
00:07:46,600 --> 00:07:51,160
Sekarang bayangkan mengutak-atik lambda, memutar kenop untuk mengubah nilainya.

99
00:07:51,160 --> 00:07:56,320
Ketika nilai lambda berubah, matriks itu sendiri

100
00:07:56,320 --> 00:07:58,240
berubah, dan determinan matriks pun berubah.

101
00:07:58,240 --> 00:08:03,720
Tujuannya di sini adalah untuk menemukan nilai lambda yang akan membuat determinan ini menjadi

102
00:08:03,720 --> 00:08:08,240
nol, yang berarti transformasi yang disesuaikan akan menekan ruang ke dimensi yang lebih rendah.

103
00:08:08,240 --> 00:08:12,240
Dalam hal ini, sweet spot muncul ketika lambda sama dengan 1.

104
00:08:12,240 --> 00:08:16,480
Tentu saja, jika kita memilih matriks lain, nilai eigennya belum tentu 1.

105
00:08:16,480 --> 00:08:20,280
Titik manisnya mungkin terkena nilai lambda lainnya.

106
00:08:20,280 --> 00:08:23,620
Jadi ini agak banyak, tapi mari kita uraikan maksudnya.

107
00:08:23,620 --> 00:08:30,620
Ketika lambda sama dengan 1, matriks A dikurangi lambda dikalikan identitas menekan ruang ke dalam sebuah garis.

108
00:08:30,620 --> 00:08:36,440
Artinya ada vektor bukan nol v sehingga A dikurangi

109
00:08:36,440 --> 00:08:40,680
lambda dikali identitas dikali v sama dengan vektor nol.

110
00:08:40,680 --> 00:08:46,180
Dan ingat, alasan kita mempedulikannya adalah karena ini berarti A dikali v sama dengan

111
00:08:46,180 --> 00:08:54,040
lambda dikali v, yang dapat Anda baca dengan menyatakan bahwa vektor v adalah

112
00:08:54,040 --> 00:08:58,580
vektor eigen dari A, yang tetap berada pada rentangnya sendiri selama transformasi A.

113
00:08:58,580 --> 00:09:03,440
Dalam contoh ini, nilai eigen yang terkait adalah

114
00:09:03,440 --> 00:09:06,200
1, jadi v sebenarnya akan tetap di tempatnya.

115
00:09:06,240 --> 00:09:13,840
Berhentilah sejenak dan renungkan apakah Anda perlu memastikan bahwa alur pemikiran tersebut terasa tepat.

116
00:09:13,840 --> 00:09:16,280
Ini adalah hal yang saya sebutkan di pendahuluan.

117
00:09:16,280 --> 00:09:21,320
Jika Anda tidak memiliki pemahaman yang kuat tentang determinan dan mengapa determinan tersebut berhubungan dengan

118
00:09:21,320 --> 00:09:28,460
sistem persamaan linier yang memiliki solusi bukan nol, ekspresi seperti ini akan terasa tiba-tiba.

119
00:09:28,460 --> 00:09:32,400
Untuk melihat cara kerjanya, mari kita lihat kembali contoh dari awal,

120
00:09:32,400 --> 00:09:35,640
dengan matriks yang kolomnya adalah 3, 0 dan 1, 2.

121
00:09:35,640 --> 00:09:41,600
Untuk mengetahui apakah suatu nilai lambda merupakan nilai

122
00:09:41,600 --> 00:09:51,240
eigen, kurangi diagonal matriks ini dan hitung determinannya.

123
00:09:51,240 --> 00:09:57,920
Dengan melakukan ini, kita mendapatkan polinomial kuadrat tertentu di lambda, 3 dikurangi lambda dikali 2 dikurangi lambda.

124
00:09:57,920 --> 00:10:03,000
Karena lambda hanya dapat menjadi nilai eigen jika determinannya sama dengan nol, Anda dapat menyimpulkan bahwa

125
00:10:03,000 --> 00:10:10,120
satu-satunya nilai eigen yang mungkin adalah lambda sama dengan 2 dan lambda sama dengan 3.

126
00:10:10,120 --> 00:10:14,340
Untuk mengetahui vektor eigen apa yang sebenarnya memiliki salah satu nilai eigen ini,

127
00:10:14,340 --> 00:10:20,840
katakanlah lambda sama dengan 2, masukkan nilai lambda tersebut ke matriks, lalu selesaikan

128
00:10:20,840 --> 00:10:25,300
vektor mana yang dikirim ke nol oleh matriks yang diubah secara diagonal ini.

129
00:10:25,300 --> 00:10:29,800
Jika Anda menghitungnya seperti yang Anda lakukan pada sistem linier lainnya, Anda akan melihat

130
00:10:29,800 --> 00:10:35,480
bahwa solusinya adalah semua vektor pada garis diagonal yang direntang oleh negatif 1, 1.

131
00:10:35,480 --> 00:10:41,200
Hal ini sesuai dengan fakta bahwa matriks yang tidak diubah, 3, 0,

132
00:10:41,200 --> 00:10:44,680
1, 2, mempunyai efek meregangkan semua vektor tersebut dengan faktor 2.

133
00:10:44,680 --> 00:10:50,880
Sekarang, transformasi 2D tidak harus memiliki vektor eigen.

134
00:10:50,880 --> 00:10:53,960
Misalnya, bayangkan rotasi sebesar 90 derajat.

135
00:10:53,960 --> 00:11:01,200
Ini tidak memiliki vektor eigen apa pun karena ia memutar setiap vektor dari rentangnya sendiri.

136
00:11:01,200 --> 00:11:06,400
Jika Anda benar-benar mencoba menghitung nilai eigen dari rotasi seperti ini, perhatikan apa yang terjadi.

137
00:11:06,400 --> 00:11:11,120
Matriksnya memiliki kolom 0, 1 dan negatif 1, 0.

138
00:11:11,120 --> 00:11:18,440
Kurangi lambda dari elemen diagonal dan cari determinannya nol.

139
00:11:18,440 --> 00:11:22,960
Dalam hal ini, Anda mendapatkan lambda polinomial kuadrat ditambah 1.

140
00:11:22,960 --> 00:11:29,000
Akar polinomial tersebut hanyalah bilangan imajiner, i dan negatif i.

141
00:11:29,000 --> 00:11:36,120
Fakta bahwa tidak ada solusi bilangan real menunjukkan bahwa tidak ada vektor eigen.

142
00:11:36,120 --> 00:11:40,640
Contoh lain yang cukup menarik yang patut diingat adalah sebuah guntingan.

143
00:11:40,640 --> 00:11:47,460
Ini memperbaiki i-hat di tempatnya dan memindahkan j-hat 1 ke

144
00:11:47,460 --> 00:11:49,000
atas, sehingga matriksnya memiliki kolom 1, 0 dan 1, 1.

145
00:11:49,040 --> 00:11:54,060
Semua vektor pada sumbu x merupakan vektor eigen dengan

146
00:11:54,060 --> 00:11:55,060
nilai eigen 1 karena vektor-vektor tersebut tetap pada tempatnya.

147
00:11:55,060 --> 00:11:58,880
Faktanya, ini adalah satu-satunya vektor eigen.

148
00:11:58,880 --> 00:12:04,400
Saat Anda mengurangi lambda dari diagonal dan menghitung determinannya,

149
00:12:04,400 --> 00:12:09,640
yang Anda dapatkan adalah 1 dikurangi lambda kuadrat.

150
00:12:09,640 --> 00:12:15,080
Dan satu-satunya akar dari ungkapan ini adalah lambda sama dengan 1.

151
00:12:15,080 --> 00:12:19,640
Hal ini sejalan dengan apa yang kita lihat secara

152
00:12:19,640 --> 00:12:21,200
geometris, bahwa semua vektor eigen memiliki nilai eigen 1.

153
00:12:21,200 --> 00:12:26,280
Namun perlu diingat, dimungkinkan juga untuk hanya memiliki satu nilai eigen,

154
00:12:26,280 --> 00:12:30,000
namun dengan lebih dari sekedar garis yang penuh dengan vektor eigen.

155
00:12:30,000 --> 00:12:34,040
Contoh sederhananya adalah matriks yang menskalakan semuanya dengan 2.

156
00:12:34,040 --> 00:12:39,680
Satu-satunya nilai eigen adalah 2, tetapi setiap vektor pada bidang

157
00:12:39,680 --> 00:12:42,380
tersebut akan menjadi vektor eigen dengan nilai eigen tersebut.

158
00:12:42,380 --> 00:12:46,020
Sekarang adalah saat yang tepat untuk berhenti sejenak dan merenungkan

159
00:12:46,020 --> 00:12:46,900
beberapa hal ini sebelum saya melanjutkan ke topik terakhir.

160
00:13:03,900 --> 00:13:08,940
Saya ingin mengakhiri di sini dengan gagasan tentang eigenbasis,

161
00:13:08,940 --> 00:13:11,720
yang sangat bergantung pada gagasan dari video terakhir.

162
00:13:11,720 --> 00:13:17,220
Lihatlah apa yang terjadi jika vektor basis kita kebetulan merupakan vektor eigen.

163
00:13:17,220 --> 00:13:23,760
Misalnya, mungkin i-hat berskala negatif 1, dan j-hat berskala 2.

164
00:13:23,760 --> 00:13:28,800
Menuliskan koordinat barunya sebagai kolom matriks, perhatikan bahwa kelipatan skalar tersebut, negatif

165
00:13:28,800 --> 00:13:34,500
1 dan 2, yang merupakan nilai eigen dari i-hat dan j-hat, berada

166
00:13:34,500 --> 00:13:39,060
pada diagonal matriks kita, dan setiap entri lainnya adalah 0 .

167
00:13:39,060 --> 00:13:43,940
Setiap kali suatu matriks mempunyai angka 0 di mana pun selain diagonal, maka

168
00:13:43,940 --> 00:13:48,940
matriks tersebut disebut matriks diagonal, dan cara untuk menafsirkannya adalah bahwa semua vektor

169
00:13:48,940 --> 00:13:57,380
basis adalah vektor eigen, dengan entri diagonal dari matriks ini menjadi nilai eigennya.

170
00:13:57,380 --> 00:14:02,060
Ada banyak hal yang membuat matriks diagonal lebih baik untuk dikerjakan.

171
00:14:02,060 --> 00:14:06,380
Salah satu kelebihannya adalah lebih mudah menghitung apa yang akan terjadi

172
00:14:06,380 --> 00:14:09,500
jika Anda mengalikan matriks ini dengan matriks itu sendiri beberapa kali.

173
00:14:09,500 --> 00:14:15,140
Karena yang dilakukan matriks ini hanyalah menskalakan setiap vektor basis dengan beberapa

174
00:14:15,140 --> 00:14:20,900
nilai eigen, menerapkan matriks tersebut berkali-kali, katakanlah 100 kali, hanya akan menyamakan

175
00:14:20,900 --> 00:14:25,880
penskalaan setiap vektor basis dengan pangkat 100 dari nilai eigen yang bersangkutan.

176
00:14:25,880 --> 00:14:29,940
Sebaliknya, coba hitung pangkat 100 dari matriks non-diagonal.

177
00:14:29,940 --> 00:14:31,940
Sungguh, cobalah sejenak.

178
00:14:31,940 --> 00:14:32,580
Ini mimpi buruk.

179
00:14:36,500 --> 00:14:42,220
Tentu saja, Anda jarang sekali beruntung karena vektor basis Anda juga merupakan vektor eigen.

180
00:14:42,220 --> 00:14:46,900
Namun jika transformasi Anda memiliki banyak vektor eigen, seperti yang ada di awal

181
00:14:46,900 --> 00:14:52,160
video ini, sehingga Anda dapat memilih himpunan yang mencakup seluruh ruang, maka Anda

182
00:14:52,160 --> 00:14:56,940
dapat mengubah sistem koordinat sehingga vektor eigen tersebut menjadi vektor basis Anda.

183
00:14:56,940 --> 00:15:01,140
Saya berbicara tentang perubahan basis di video terakhir, tapi saya akan membahas

184
00:15:01,140 --> 00:15:06,180
pengingat super cepat di sini tentang cara mengekspresikan transformasi yang saat

185
00:15:06,180 --> 00:15:08,540
ini ditulis dalam sistem koordinat kita ke dalam sistem yang berbeda.

186
00:15:08,540 --> 00:15:12,420
Ambil koordinat vektor-vektor yang ingin dijadikan basis baru, yang dalam hal

187
00:15:12,420 --> 00:15:17,540
ini berarti dua vektor eigen kita, lalu jadikan koordinat tersebut

188
00:15:17,540 --> 00:15:20,380
sebagai kolom-kolom suatu matriks, yang disebut dengan matriks perubahan basis.

189
00:15:20,380 --> 00:15:24,460
Ketika Anda mengapit transformasi asli, meletakkan matriks perubahan basis di

190
00:15:24,460 --> 00:15:30,560
sebelah kanannya dan kebalikan dari matriks perubahan basis di

191
00:15:30,560 --> 00:15:35,520
sebelah kirinya, hasilnya akan berupa matriks yang mewakili transformasi yang

192
00:15:35,520 --> 00:15:37,640
sama, tetapi dari perspektif koordinat vektor basis baru sistem.

193
00:15:37,640 --> 00:15:42,640
Inti dari melakukan hal ini dengan vektor eigen adalah bahwa matriks baru ini

194
00:15:42,640 --> 00:15:47,300
dijamin berbentuk diagonal dengan nilai eigen yang sesuai di bawah diagonal tersebut.

195
00:15:47,300 --> 00:15:51,080
Hal ini karena ini mewakili pekerjaan dalam sistem koordinat di mana apa

196
00:15:51,080 --> 00:15:55,740
yang terjadi pada vektor basis adalah vektor-vektor tersebut diskalakan selama transformasi.

197
00:15:55,740 --> 00:16:02,400
Sekumpulan vektor basis yang juga merupakan vektor eigen disebut dengan basis eigen.

198
00:16:02,400 --> 00:16:07,620
Jadi jika, misalnya, Anda perlu menghitung pangkat ke-100 dari matriks ini,

199
00:16:07,620 --> 00:16:14,060
akan lebih mudah untuk mengubahnya ke basis eigen, menghitung pangkat ke-100

200
00:16:14,060 --> 00:16:16,760
dalam sistem tersebut, lalu mengonversinya kembali ke sistem standar kita.

201
00:16:16,760 --> 00:16:18,460
Anda tidak dapat melakukan ini dengan semua transformasi.

202
00:16:18,460 --> 00:16:23,800
Sebuah geser, misalnya, tidak memiliki vektor eigen yang cukup untuk menjangkau seluruh ruang.

203
00:16:23,800 --> 00:16:29,180
Tetapi jika Anda dapat menemukan basis eigen, itu membuat operasi matriks menjadi sangat menyenangkan.

204
00:16:29,180 --> 00:16:32,060
Bagi Anda yang ingin menyelesaikan teka-teki yang cukup rapi untuk melihat seperti

205
00:16:32,060 --> 00:16:35,880
apa aksinya dan bagaimana hal ini dapat digunakan untuk menghasilkan beberapa

206
00:16:35,880 --> 00:16:37,960
hasil yang mengejutkan, saya akan meninggalkan petunjuk di sini di layar.

207
00:16:37,960 --> 00:16:40,960
Memang butuh sedikit usaha, tapi menurut saya Anda akan menikmatinya.

208
00:16:40,960 --> 00:16:46,000
Video berikutnya dan terakhir dari seri ini akan membahas tentang ruang vektor abstrak.

209
00:16:46,000 --> 00:16:46,360
Sampai jumpa lagi!

