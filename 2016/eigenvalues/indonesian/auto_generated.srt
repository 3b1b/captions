1
00:00:19,282 --> 00:00:22,871
Vektor eigen dan nilai eigen adalah salah satu

2
00:00:22,871 --> 00:00:26,460
topik yang menurut banyak siswa tidak intuitif.

3
00:00:26,460 --> 00:00:30,240
Hal-hal seperti, mengapa kita melakukan hal ini, dan apa maksud sebenarnya dari hal

4
00:00:30,240 --> 00:00:34,020
ini, sering kali dibiarkan begitu saja dalam lautan perhitungan yang tidak terjawab.

5
00:00:34,020 --> 00:00:37,516
Dan saat saya merilis video seri ini, banyak dari Anda berkomentar

6
00:00:37,516 --> 00:00:40,700
tentang menantikan memvisualisasikan topik ini secara khusus.

7
00:00:40,700 --> 00:00:43,580
Saya menduga alasannya bukan karena eigenthings

8
00:00:43,580 --> 00:00:46,460
menjadi rumit atau tidak dijelaskan dengan baik.

9
00:00:46,460 --> 00:00:49,043
Faktanya, ini relatif mudah, dan menurut saya

10
00:00:49,043 --> 00:00:52,020
sebagian besar buku mampu menjelaskannya dengan baik.

11
00:00:52,020 --> 00:00:55,725
Apa yang ingin saya lakukan adalah hal ini hanya masuk akal jika Anda

12
00:00:55,725 --> 00:00:59,220
memiliki pemahaman visual yang kuat untuk banyak topik sebelumnya.

13
00:00:59,220 --> 00:01:03,168
Yang terpenting di sini adalah Anda mengetahui cara berpikir matriks

14
00:01:03,168 --> 00:01:07,060
sebagai transformasi linier, namun Anda juga harus memahami hal-hal

15
00:01:07,060 --> 00:01:10,780
seperti determinan, sistem persamaan linier, dan perubahan basis.

16
00:01:10,780 --> 00:01:15,459
Kebingungan mengenai eigenstuff biasanya lebih berkaitan dengan fondasi yang goyah

17
00:01:15,459 --> 00:01:20,420
dalam salah satu topik ini dibandingkan dengan vektor eigen dan nilai eigen itu sendiri.

18
00:01:20,420 --> 00:01:23,098
Untuk memulai, pertimbangkan beberapa transformasi linier

19
00:01:23,098 --> 00:01:25,500
dalam dua dimensi, seperti yang ditunjukkan di sini.

20
00:01:25,500 --> 00:01:31,860
Ini memindahkan vektor basis i-hat ke koordinat 3, 0, dan j-hat ke 1, 2.

21
00:01:31,860 --> 00:01:36,860
Jadi direpresentasikan dengan matriks yang kolomnya 3, 0, dan 1, 2.

22
00:01:36,860 --> 00:01:41,040
Fokuslah pada apa yang dilakukannya pada satu vektor tertentu, dan pikirkan

23
00:01:41,040 --> 00:01:45,220
tentang rentang vektor tersebut, garis yang melalui titik asal dan ujungnya.

24
00:01:45,220 --> 00:01:48,500
Kebanyakan vektor akan kehilangan rentangnya selama transformasi.

25
00:01:48,500 --> 00:01:52,700
Maksud saya, akan terlihat sangat kebetulan jika tempat

26
00:01:52,700 --> 00:01:57,500
pendaratan vektor juga berada di suatu tempat di garis tersebut.

27
00:01:57,500 --> 00:02:01,353
Namun beberapa vektor khusus tetap berada pada rentangnya

28
00:02:01,353 --> 00:02:05,407
sendiri, yang berarti bahwa pengaruh matriks terhadap vektor

29
00:02:05,407 --> 00:02:09,660
tersebut hanyalah merenggangkan atau menekannya, seperti skalar.

30
00:02:09,660 --> 00:02:15,100
Untuk contoh spesifik ini, vektor basis i-hat adalah salah satu vektor khusus tersebut.

31
00:02:15,100 --> 00:02:20,924
Rentang i-hat adalah sumbu x, dan dari kolom pertama matriks terlihat

32
00:02:20,924 --> 00:02:26,500
bahwa i-hat berpindah sebanyak 3 kali, masih pada sumbu x tersebut.

33
00:02:26,500 --> 00:02:32,468
Terlebih lagi, karena cara kerja transformasi linier, vektor lain pada sumbu x juga

34
00:02:32,468 --> 00:02:38,580
hanya diregangkan sebanyak 3 kali, dan karenanya tetap berada pada rentangnya sendiri.

35
00:02:38,580 --> 00:02:41,516
Vektor yang sedikit lebih licik yang tetap berada pada

36
00:02:41,516 --> 00:02:44,880
rentangnya sendiri selama transformasi ini adalah negatif 1, 1.

37
00:02:44,880 --> 00:02:49,120
Itu akhirnya diregangkan dengan faktor 2.

38
00:02:49,120 --> 00:02:54,383
Dan lagi, linearitas akan menyiratkan bahwa vektor lain pada garis

39
00:02:54,383 --> 00:03:00,040
diagonal yang direntang oleh orang ini akan diregangkan sebanyak 2 kali.

40
00:03:00,040 --> 00:03:02,868
Dan untuk transformasi ini, itu semua adalah vektor

41
00:03:02,868 --> 00:03:05,860
dengan sifat khusus untuk tetap berada pada rentangnya.

42
00:03:05,860 --> 00:03:09,335
Garis yang berada pada sumbu x diregangkan sebanyak 3

43
00:03:09,335 --> 00:03:12,940
kali, dan garis diagonalnya diregangkan sebanyak 2 kali.

44
00:03:12,940 --> 00:03:17,675
Vektor lainnya akan diputar selama transformasi,

45
00:03:17,675 --> 00:03:22,700
sehingga menyimpang dari garis yang dibentangkannya.

46
00:03:22,700 --> 00:03:27,005
Seperti yang mungkin sudah Anda duga sekarang, vektor-vektor khusus

47
00:03:27,005 --> 00:03:31,311
ini disebut vektor eigen dari transformasi, dan setiap vektor eigen

48
00:03:31,311 --> 00:03:35,870
dikaitkan dengannya dengan apa yang disebut nilai eigen, yang merupakan

49
00:03:35,870 --> 00:03:40,620
faktor yang merenggangkan atau menekan vektor tersebut selama transformasi.

50
00:03:40,620 --> 00:03:43,495
Tentu saja, tidak ada yang istimewa tentang peregangan

51
00:03:43,495 --> 00:03:46,580
versus pemampatan atau fakta bahwa nilai eigen ini positif.

52
00:03:46,580 --> 00:03:51,952
Dalam contoh lain, Anda dapat memiliki vektor eigen dengan nilai eigen negatif

53
00:03:51,952 --> 00:03:57,460
1 setengah, artinya vektor tersebut dibalik dan diperas dengan faktor 1 setengah.

54
00:03:57,460 --> 00:04:01,157
Namun bagian yang penting di sini adalah ia tetap berada

55
00:04:01,157 --> 00:04:04,660
pada garis yang dibentangkannya tanpa terputar keluar.

56
00:04:04,660 --> 00:04:08,197
Untuk melihat sekilas mengapa hal ini berguna untuk

57
00:04:08,197 --> 00:04:11,940
dipikirkan, pertimbangkan beberapa rotasi tiga dimensi.

58
00:04:11,940 --> 00:04:17,372
Jika Anda dapat menemukan vektor eigen untuk rotasi tersebut, sebuah vektor

59
00:04:17,372 --> 00:04:23,020
yang tetap pada rentangnya sendiri, maka yang Anda temukan adalah sumbu rotasi.

60
00:04:23,020 --> 00:04:27,561
Dan jauh lebih mudah untuk memikirkan rotasi 3D dalam kaitannya

61
00:04:27,561 --> 00:04:32,527
dengan beberapa sumbu rotasi dan sudut rotasinya, daripada memikirkan

62
00:04:32,527 --> 00:04:37,140
matriks penuh 3 kali 3 yang terkait dengan transformasi tersebut.

63
00:04:37,140 --> 00:04:42,695
Dalam hal ini, nilai eigen yang sesuai haruslah 1, karena rotasi tidak pernah

64
00:04:42,695 --> 00:04:48,180
meregangkan atau menekan apa pun, sehingga panjang vektornya akan tetap sama.

65
00:04:48,180 --> 00:04:50,580
Pola ini banyak muncul dalam aljabar linier.

66
00:04:50,580 --> 00:04:55,269
Dengan transformasi linier apa pun yang dideskripsikan oleh sebuah matriks, Anda dapat

67
00:04:55,269 --> 00:05:00,120
memahami fungsinya dengan membaca kolom-kolom matriks ini sebagai titik awal vektor basis.

68
00:05:00,120 --> 00:05:05,133
Namun seringkali, cara yang lebih baik untuk memahami inti dari apa yang

69
00:05:05,133 --> 00:05:10,422
sebenarnya dilakukan transformasi linier, yang tidak terlalu bergantung pada

70
00:05:10,422 --> 00:05:15,780
sistem koordinat tertentu, adalah dengan mencari vektor eigen dan nilai eigen.

71
00:05:15,780 --> 00:05:19,476
Saya tidak akan membahas detail lengkap tentang metode penghitungan vektor

72
00:05:19,476 --> 00:05:23,172
eigen dan nilai eigen di sini, namun saya akan mencoba memberikan gambaran

73
00:05:23,172 --> 00:05:26,820
umum tentang ide komputasi yang paling penting untuk pemahaman konseptual.

74
00:05:26,820 --> 00:05:30,980
Secara simbolis, seperti inilah gagasan tentang vektor eigen.

75
00:05:30,980 --> 00:05:36,059
A adalah matriks yang mewakili suatu transformasi, dengan v sebagai vektor

76
00:05:36,059 --> 00:05:40,800
eigen, dan lambda adalah bilangan, yaitu nilai eigen yang bersesuaian.

77
00:05:40,800 --> 00:05:46,128
Maksud dari ungkapan ini adalah bahwa perkalian vektor-matriks, A kali v, memberikan

78
00:05:46,128 --> 00:05:51,520
hasil yang sama seperti hanya menskalakan vektor eigen v dengan beberapa nilai lambda.

79
00:05:51,520 --> 00:05:56,669
Jadi mencari vektor eigen dan nilai eigennya dari matriks A

80
00:05:56,669 --> 00:06:02,420
berarti mencari nilai v dan lambda yang membuat ungkapan ini benar.

81
00:06:02,420 --> 00:06:06,594
Agak canggung untuk mengerjakannya pada awalnya karena ruas kiri mewakili

82
00:06:06,594 --> 00:06:11,220
perkalian matriks-vektor, namun ruas kanan di sini adalah perkalian skalar-vektor.

83
00:06:11,220 --> 00:06:14,634
Jadi mari kita mulai dengan menulis ulang ruas kanan tersebut

84
00:06:14,634 --> 00:06:18,049
sebagai semacam perkalian matriks-vektor, menggunakan matriks

85
00:06:18,049 --> 00:06:21,740
yang memiliki efek menskalakan vektor apa pun dengan faktor lambda.

86
00:06:21,740 --> 00:06:26,397
Kolom-kolom matriks tersebut akan mewakili apa yang terjadi pada masing-masing

87
00:06:26,397 --> 00:06:30,995
vektor basis, dan setiap vektor basis hanya dikalikan dengan lambda, sehingga

88
00:06:30,995 --> 00:06:35,652
matriks ini akan mempunyai bilangan lambda di bawah diagonalnya, dengan nol di

89
00:06:35,652 --> 00:06:36,360
tempat lain.

90
00:06:36,360 --> 00:06:39,448
Cara umum untuk menulis orang ini adalah dengan memfaktorkan

91
00:06:39,448 --> 00:06:42,587
lambda tersebut dan menuliskannya sebagai lambda dikalikan i,

92
00:06:42,587 --> 00:06:45,980
dengan i adalah matriks identitas dengan matriks di bawah diagonal.

93
00:06:45,980 --> 00:06:50,068
Karena kedua ruasnya tampak seperti perkalian matriks-vektor,

94
00:06:50,068 --> 00:06:54,420
kita dapat mengurangkan ruas kanan tersebut dan memfaktorkan vnya.

95
00:06:54,420 --> 00:07:00,172
Jadi yang kita punya sekarang adalah matriks baru, A dikurangi lambda dikali identitas,

96
00:07:00,172 --> 00:07:05,860
dan kita mencari vektor v sehingga matriks baru ini, dikali v, menghasilkan vektor nol.

97
00:07:05,860 --> 00:07:08,976
Sekarang, ini akan selalu benar jika v itu sendiri

98
00:07:08,976 --> 00:07:11,420
adalah vektor nol, tapi itu membosankan.

99
00:07:11,420 --> 00:07:14,540
Yang kami inginkan adalah vektor eigen bukan nol.

100
00:07:14,540 --> 00:07:19,673
Dan jika Anda menonton bab 5 dan 6, Anda akan tahu bahwa satu-satunya cara agar

101
00:07:19,673 --> 00:07:24,806
hasil kali matriks dengan vektor bukan nol menjadi nol adalah jika transformasi

102
00:07:24,806 --> 00:07:29,940
yang terkait dengan matriks tersebut menekan ruang ke dimensi yang lebih rendah.

103
00:07:29,940 --> 00:07:35,560
Dan pemerasan itu sesuai dengan determinan nol untuk matriks tersebut.

104
00:07:35,560 --> 00:07:41,080
Untuk lebih konkretnya, misalkan matriks A Anda memiliki kolom 2, 1 dan 2, 3, dan

105
00:07:41,080 --> 00:07:46,600
pikirkan tentang mengurangkan jumlah variabel, lambda, dari setiap entri diagonal.

106
00:07:46,600 --> 00:07:51,160
Sekarang bayangkan mengutak-atik lambda, memutar kenop untuk mengubah nilainya.

107
00:07:51,160 --> 00:07:54,890
Ketika nilai lambda berubah, matriks itu sendiri

108
00:07:54,890 --> 00:07:58,240
berubah, dan determinan matriks pun berubah.

109
00:07:58,240 --> 00:08:01,590
Tujuannya di sini adalah untuk menemukan nilai lambda yang akan

110
00:08:01,590 --> 00:08:04,836
membuat determinan ini menjadi nol, yang berarti transformasi

111
00:08:04,836 --> 00:08:08,240
yang disesuaikan akan menekan ruang ke dimensi yang lebih rendah.

112
00:08:08,240 --> 00:08:12,240
Dalam hal ini, sweet spot muncul ketika lambda sama dengan 1.

113
00:08:12,240 --> 00:08:16,480
Tentu saja, jika kita memilih matriks lain, nilai eigennya belum tentu 1.

114
00:08:16,480 --> 00:08:20,280
Titik manisnya mungkin terkena nilai lambda lainnya.

115
00:08:20,280 --> 00:08:23,620
Jadi ini agak banyak, tapi mari kita uraikan maksudnya.

116
00:08:23,620 --> 00:08:27,120
Ketika lambda sama dengan 1, matriks A dikurangi lambda

117
00:08:27,120 --> 00:08:30,620
dikalikan identitas menekan ruang ke dalam sebuah garis.

118
00:08:30,620 --> 00:08:35,463
Artinya ada vektor bukan nol v sehingga A dikurangi

119
00:08:35,463 --> 00:08:40,680
lambda dikali identitas dikali v sama dengan vektor nol.

120
00:08:40,680 --> 00:08:46,456
Dan ingat, alasan kita mempedulikannya adalah karena ini berarti A dikali v sama

121
00:08:46,456 --> 00:08:52,518
dengan lambda dikali v, yang dapat Anda baca dengan menyatakan bahwa vektor v adalah

122
00:08:52,518 --> 00:08:58,580
vektor eigen dari A, yang tetap berada pada rentangnya sendiri selama transformasi A.

123
00:08:58,580 --> 00:09:02,611
Dalam contoh ini, nilai eigen yang terkait adalah

124
00:09:02,611 --> 00:09:06,240
1, jadi v sebenarnya akan tetap di tempatnya.

125
00:09:06,240 --> 00:09:09,968
Berhentilah sejenak dan renungkan apakah Anda perlu

126
00:09:09,968 --> 00:09:13,840
memastikan bahwa alur pemikiran tersebut terasa tepat.

127
00:09:13,840 --> 00:09:16,280
Ini adalah hal yang saya sebutkan di pendahuluan.

128
00:09:16,280 --> 00:09:20,150
Jika Anda tidak memiliki pemahaman yang kuat tentang determinan dan

129
00:09:20,150 --> 00:09:24,191
mengapa determinan tersebut berhubungan dengan sistem persamaan linier

130
00:09:24,191 --> 00:09:28,460
yang memiliki solusi bukan nol, ekspresi seperti ini akan terasa tiba-tiba.

131
00:09:28,460 --> 00:09:32,020
Untuk melihat cara kerjanya, mari kita lihat kembali contoh

132
00:09:32,020 --> 00:09:35,640
dari awal, dengan matriks yang kolomnya adalah 3, 0 dan 1, 2.

133
00:09:35,640 --> 00:09:43,310
Untuk mengetahui apakah suatu nilai lambda merupakan nilai

134
00:09:43,310 --> 00:09:51,240
eigen, kurangi diagonal matriks ini dan hitung determinannya.

135
00:09:51,240 --> 00:09:54,389
Dengan melakukan ini, kita mendapatkan polinomial kuadrat

136
00:09:54,389 --> 00:09:57,920
tertentu di lambda, 3 dikurangi lambda dikali 2 dikurangi lambda.

137
00:09:57,920 --> 00:10:01,826
Karena lambda hanya dapat menjadi nilai eigen jika determinannya

138
00:10:01,826 --> 00:10:05,792
sama dengan nol, Anda dapat menyimpulkan bahwa satu-satunya nilai

139
00:10:05,792 --> 00:10:10,120
eigen yang mungkin adalah lambda sama dengan 2 dan lambda sama dengan 3.

140
00:10:10,120 --> 00:10:15,278
Untuk mengetahui vektor eigen apa yang sebenarnya memiliki salah satu nilai eigen ini,

141
00:10:15,278 --> 00:10:20,081
katakanlah lambda sama dengan 2, masukkan nilai lambda tersebut ke matriks, lalu

142
00:10:20,081 --> 00:10:25,300
selesaikan vektor mana yang dikirim ke nol oleh matriks yang diubah secara diagonal ini.

143
00:10:25,300 --> 00:10:28,711
Jika Anda menghitungnya seperti yang Anda lakukan pada sistem

144
00:10:28,711 --> 00:10:32,178
linier lainnya, Anda akan melihat bahwa solusinya adalah semua

145
00:10:32,178 --> 00:10:35,480
vektor pada garis diagonal yang direntang oleh negatif 1, 1.

146
00:10:35,480 --> 00:10:40,146
Hal ini sesuai dengan fakta bahwa matriks yang tidak diubah, 3, 0, 1,

147
00:10:40,146 --> 00:10:44,680
2, mempunyai efek meregangkan semua vektor tersebut dengan faktor 2.

148
00:10:44,680 --> 00:10:50,880
Sekarang, transformasi 2D tidak harus memiliki vektor eigen.

149
00:10:50,880 --> 00:10:53,960
Misalnya, bayangkan rotasi sebesar 90 derajat.

150
00:10:53,960 --> 00:10:57,504
Ini tidak memiliki vektor eigen apa pun karena

151
00:10:57,504 --> 00:11:01,200
ia memutar setiap vektor dari rentangnya sendiri.

152
00:11:01,200 --> 00:11:03,800
Jika Anda benar-benar mencoba menghitung nilai eigen

153
00:11:03,800 --> 00:11:06,400
dari rotasi seperti ini, perhatikan apa yang terjadi.

154
00:11:06,400 --> 00:11:11,120
Matriksnya memiliki kolom 0, 1 dan negatif 1, 0.

155
00:11:11,120 --> 00:11:18,440
Kurangi lambda dari elemen diagonal dan cari determinannya nol.

156
00:11:18,440 --> 00:11:22,960
Dalam hal ini, Anda mendapatkan lambda polinomial kuadrat ditambah 1.

157
00:11:22,960 --> 00:11:29,000
Akar polinomial tersebut hanyalah bilangan imajiner, i dan negatif i.

158
00:11:29,000 --> 00:11:36,120
Fakta bahwa tidak ada solusi bilangan real menunjukkan bahwa tidak ada vektor eigen.

159
00:11:36,120 --> 00:11:40,640
Contoh lain yang cukup menarik yang patut diingat adalah sebuah guntingan.

160
00:11:40,640 --> 00:11:44,732
Ini memperbaiki i-hat di tempatnya dan memindahkan j-hat

161
00:11:44,732 --> 00:11:49,040
1 ke atas, sehingga matriksnya memiliki kolom 1, 0 dan 1, 1.

162
00:11:49,040 --> 00:11:52,124
Semua vektor pada sumbu x merupakan vektor eigen dengan nilai

163
00:11:52,124 --> 00:11:55,060
eigen 1 karena vektor-vektor tersebut tetap pada tempatnya.

164
00:11:55,060 --> 00:11:58,880
Faktanya, ini adalah satu-satunya vektor eigen.

165
00:11:58,880 --> 00:12:03,786
Saat Anda mengurangi lambda dari diagonal dan menghitung

166
00:12:03,786 --> 00:12:09,640
determinannya, yang Anda dapatkan adalah 1 dikurangi lambda kuadrat.

167
00:12:09,640 --> 00:12:15,080
Dan satu-satunya akar dari ungkapan ini adalah lambda sama dengan 1.

168
00:12:15,080 --> 00:12:17,887
Hal ini sejalan dengan apa yang kita lihat secara

169
00:12:17,887 --> 00:12:21,200
geometris, bahwa semua vektor eigen memiliki nilai eigen 1.

170
00:12:21,200 --> 00:12:25,450
Namun perlu diingat, dimungkinkan juga untuk hanya memiliki satu nilai

171
00:12:25,450 --> 00:12:30,000
eigen, namun dengan lebih dari sekedar garis yang penuh dengan vektor eigen.

172
00:12:30,000 --> 00:12:34,040
Contoh sederhananya adalah matriks yang menskalakan semuanya dengan 2.

173
00:12:34,040 --> 00:12:38,369
Satu-satunya nilai eigen adalah 2, tetapi setiap vektor pada bidang

174
00:12:38,369 --> 00:12:42,380
tersebut akan menjadi vektor eigen dengan nilai eigen tersebut.

175
00:12:42,380 --> 00:12:52,072
Sekarang adalah saat yang tepat untuk berhenti sejenak dan

176
00:12:52,072 --> 00:13:03,900
merenungkan beberapa hal ini sebelum saya melanjutkan ke topik terakhir.

177
00:13:03,900 --> 00:13:08,100
Saya ingin mengakhiri di sini dengan gagasan tentang eigenbasis,

178
00:13:08,100 --> 00:13:11,720
yang sangat bergantung pada gagasan dari video terakhir.

179
00:13:11,720 --> 00:13:17,220
Lihatlah apa yang terjadi jika vektor basis kita kebetulan merupakan vektor eigen.

180
00:13:17,220 --> 00:13:23,760
Misalnya, mungkin i-hat berskala negatif 1, dan j-hat berskala 2.

181
00:13:23,760 --> 00:13:28,992
Menuliskan koordinat barunya sebagai kolom matriks, perhatikan bahwa kelipatan

182
00:13:28,992 --> 00:13:34,026
skalar tersebut, negatif 1 dan 2, yang merupakan nilai eigen dari i-hat dan

183
00:13:34,026 --> 00:13:39,060
j-hat, berada pada diagonal matriks kita, dan setiap entri lainnya adalah 0.

184
00:13:39,060 --> 00:13:44,983
Setiap kali suatu matriks mempunyai angka 0 di mana pun selain diagonal, maka matriks

185
00:13:44,983 --> 00:13:50,768
tersebut disebut matriks diagonal, dan cara untuk menafsirkannya adalah bahwa semua

186
00:13:50,768 --> 00:13:56,760
vektor basis adalah vektor eigen, dengan entri diagonal dari matriks ini menjadi nilai

187
00:13:56,760 --> 00:13:57,380
eigennya.

188
00:13:57,380 --> 00:14:02,060
Ada banyak hal yang membuat matriks diagonal lebih baik untuk dikerjakan.

189
00:14:02,060 --> 00:14:05,829
Salah satu kelebihannya adalah lebih mudah menghitung apa yang akan terjadi

190
00:14:05,829 --> 00:14:09,500
jika Anda mengalikan matriks ini dengan matriks itu sendiri beberapa kali.

191
00:14:09,500 --> 00:14:13,624
Karena yang dilakukan matriks ini hanyalah menskalakan setiap vektor

192
00:14:13,624 --> 00:14:17,391
basis dengan beberapa nilai eigen, menerapkan matriks tersebut

193
00:14:17,391 --> 00:14:21,456
berkali-kali, katakanlah 100 kali, hanya akan menyamakan penskalaan

194
00:14:21,456 --> 00:14:25,880
setiap vektor basis dengan pangkat 100 dari nilai eigen yang bersangkutan.

195
00:14:25,880 --> 00:14:29,940
Sebaliknya, coba hitung pangkat 100 dari matriks non-diagonal.

196
00:14:29,940 --> 00:14:31,940
Sungguh, cobalah sejenak.

197
00:14:31,940 --> 00:14:36,500
Ini mimpi buruk.

198
00:14:36,500 --> 00:14:39,420
Tentu saja, Anda jarang sekali beruntung karena

199
00:14:39,420 --> 00:14:42,220
vektor basis Anda juga merupakan vektor eigen.

200
00:14:42,220 --> 00:14:46,975
Namun jika transformasi Anda memiliki banyak vektor eigen, seperti yang ada di awal

201
00:14:46,975 --> 00:14:51,901
video ini, sehingga Anda dapat memilih himpunan yang mencakup seluruh ruang, maka Anda

202
00:14:51,901 --> 00:14:56,940
dapat mengubah sistem koordinat sehingga vektor eigen tersebut menjadi vektor basis Anda.

203
00:14:56,940 --> 00:15:00,574
Saya berbicara tentang perubahan basis di video terakhir, tapi saya akan

204
00:15:00,574 --> 00:15:04,606
membahas pengingat super cepat di sini tentang cara mengekspresikan transformasi

205
00:15:04,606 --> 00:15:08,540
yang saat ini ditulis dalam sistem koordinat kita ke dalam sistem yang berbeda.

206
00:15:08,540 --> 00:15:12,451
Ambil koordinat vektor-vektor yang ingin dijadikan basis baru, yang dalam

207
00:15:12,451 --> 00:15:16,204
hal ini berarti dua vektor eigen kita, lalu jadikan koordinat tersebut

208
00:15:16,204 --> 00:15:20,380
sebagai kolom-kolom suatu matriks, yang disebut dengan matriks perubahan basis.

209
00:15:20,380 --> 00:15:24,588
Ketika Anda mengapit transformasi asli, meletakkan matriks perubahan

210
00:15:24,588 --> 00:15:28,796
basis di sebelah kanannya dan kebalikan dari matriks perubahan basis

211
00:15:28,796 --> 00:15:33,431
di sebelah kirinya, hasilnya akan berupa matriks yang mewakili transformasi

212
00:15:33,431 --> 00:15:37,640
yang sama, tetapi dari perspektif koordinat vektor basis baru sistem.

213
00:15:37,640 --> 00:15:42,262
Inti dari melakukan hal ini dengan vektor eigen adalah bahwa matriks baru ini

214
00:15:42,262 --> 00:15:47,300
dijamin berbentuk diagonal dengan nilai eigen yang sesuai di bawah diagonal tersebut.

215
00:15:47,300 --> 00:15:51,289
Hal ini karena ini mewakili pekerjaan dalam sistem koordinat di mana apa yang

216
00:15:51,289 --> 00:15:55,740
terjadi pada vektor basis adalah vektor-vektor tersebut diskalakan selama transformasi.

217
00:15:55,740 --> 00:16:02,400
Sekumpulan vektor basis yang juga merupakan vektor eigen disebut dengan basis eigen.

218
00:16:02,400 --> 00:16:07,207
Jadi jika, misalnya, Anda perlu menghitung pangkat ke-100 dari matriks ini,

219
00:16:07,207 --> 00:16:12,078
akan lebih mudah untuk mengubahnya ke basis eigen, menghitung pangkat ke-100

220
00:16:12,078 --> 00:16:16,760
dalam sistem tersebut, lalu mengonversinya kembali ke sistem standar kita.

221
00:16:16,760 --> 00:16:18,460
Anda tidak dapat melakukan ini dengan semua transformasi.

222
00:16:18,460 --> 00:16:21,073
Sebuah geser, misalnya, tidak memiliki vektor

223
00:16:21,073 --> 00:16:23,800
eigen yang cukup untuk menjangkau seluruh ruang.

224
00:16:23,800 --> 00:16:26,437
Tetapi jika Anda dapat menemukan basis eigen, itu

225
00:16:26,437 --> 00:16:29,180
membuat operasi matriks menjadi sangat menyenangkan.

226
00:16:29,180 --> 00:16:31,994
Bagi Anda yang ingin menyelesaikan teka-teki yang cukup rapi untuk melihat

227
00:16:31,994 --> 00:16:34,883
seperti apa aksinya dan bagaimana hal ini dapat digunakan untuk menghasilkan

228
00:16:34,883 --> 00:16:37,960
beberapa hasil yang mengejutkan, saya akan meninggalkan petunjuk di sini di layar.

229
00:16:37,960 --> 00:16:40,960
Memang butuh sedikit usaha, tapi menurut saya Anda akan menikmatinya.

230
00:16:40,960 --> 00:16:46,000
Video berikutnya dan terakhir dari seri ini akan membahas tentang ruang vektor abstrak.

231
00:16:46,000 --> 00:16:46,000
Sampai jumpa lagi!

