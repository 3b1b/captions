1
00:00:19,282 --> 00:00:22,871
Vektor eigen dan nilai eigen adalah salah satu

2
00:00:22,871 --> 00:00:26,460
topik yang menurut banyak siswa tidak intuitif.

3
00:00:26,460 --> 00:00:30,465
Hal-hal seperti, mengapa kita melakukan hal ini, dan apa maksud sebenarnya dari hal ini,

4
00:00:30,465 --> 00:00:34,020
sering kali dibiarkan begitu saja dalam lautan perhitungan yang tidak terjawab.

5
00:00:34,020 --> 00:00:37,516
Dan saat saya merilis video seri ini, banyak dari Anda berkomentar

6
00:00:37,516 --> 00:00:40,700
tentang menantikan memvisualisasikan topik ini secara khusus.

7
00:00:40,700 --> 00:00:43,580
Saya menduga alasannya bukan karena eigenthings

8
00:00:43,580 --> 00:00:46,460
menjadi rumit atau tidak dijelaskan dengan baik.

9
00:00:46,460 --> 00:00:49,043
Faktanya, ini relatif mudah, dan menurut saya

10
00:00:49,043 --> 00:00:52,020
sebagian besar buku mampu menjelaskannya dengan baik.

11
00:00:52,020 --> 00:00:55,725
Apa yang ingin saya lakukan adalah hal ini hanya masuk akal jika Anda

12
00:00:55,725 --> 00:00:59,220
memiliki pemahaman visual yang kuat untuk banyak topik sebelumnya.

13
00:00:59,220 --> 00:01:03,168
Yang terpenting di sini adalah Anda mengetahui cara berpikir matriks

14
00:01:03,168 --> 00:01:08,204
sebagai transformasi linier, namun Anda juga harus memahami hal-hal seperti determinan,

15
00:01:08,204 --> 00:01:10,780
sistem persamaan linier, dan perubahan basis.

16
00:01:10,780 --> 00:01:15,459
Kebingungan mengenai eigenstuff biasanya lebih berkaitan dengan fondasi yang goyah

17
00:01:15,459 --> 00:01:20,420
dalam salah satu topik ini dibandingkan dengan vektor eigen dan nilai eigen itu sendiri.

18
00:01:20,420 --> 00:01:23,976
Untuk memulai, pertimbangkan beberapa transformasi linier dalam dua dimensi,

19
00:01:23,976 --> 00:01:25,500
seperti yang ditunjukkan di sini.

20
00:01:25,500 --> 00:01:31,860
Ini memindahkan vektor basis i-hat ke koordinat 3, 0, dan j-hat ke 1, 2.

21
00:01:31,860 --> 00:01:36,860
Jadi direpresentasikan dengan matriks yang kolomnya 3, 0, dan 1, 2.

22
00:01:36,860 --> 00:01:40,325
Fokuslah pada apa yang dilakukannya pada satu vektor tertentu,

23
00:01:40,325 --> 00:01:45,220
dan pikirkan tentang rentang vektor tersebut, garis yang melalui titik asal dan ujungnya.

24
00:01:45,220 --> 00:01:48,500
Kebanyakan vektor akan kehilangan rentangnya selama transformasi.

25
00:01:48,500 --> 00:01:52,700
Maksud saya, akan terlihat sangat kebetulan jika tempat

26
00:01:52,700 --> 00:01:57,500
pendaratan vektor juga berada di suatu tempat di garis tersebut.

27
00:01:57,500 --> 00:02:01,952
Namun beberapa vektor khusus tetap berada pada rentangnya sendiri,

28
00:02:01,952 --> 00:02:06,005
yang berarti bahwa pengaruh matriks terhadap vektor tersebut

29
00:02:06,005 --> 00:02:09,660
hanyalah merenggangkan atau menekannya, seperti skalar.

30
00:02:09,660 --> 00:02:15,100
Untuk contoh spesifik ini, vektor basis i-hat adalah salah satu vektor khusus tersebut.

31
00:02:15,100 --> 00:02:20,924
Rentang i-hat adalah sumbu x, dan dari kolom pertama matriks terlihat

32
00:02:20,924 --> 00:02:26,500
bahwa i-hat berpindah sebanyak 3 kali, masih pada sumbu x tersebut.

33
00:02:26,500 --> 00:02:30,337
Terlebih lagi, karena cara kerja transformasi linier,

34
00:02:30,337 --> 00:02:34,956
vektor lain pada sumbu x juga hanya diregangkan sebanyak 3 kali,

35
00:02:34,956 --> 00:02:38,580
dan karenanya tetap berada pada rentangnya sendiri.

36
00:02:38,580 --> 00:02:41,516
Vektor yang sedikit lebih licik yang tetap berada pada

37
00:02:41,516 --> 00:02:44,880
rentangnya sendiri selama transformasi ini adalah negatif 1, 1.

38
00:02:44,880 --> 00:02:49,120
Itu akhirnya diregangkan dengan faktor 2.

39
00:02:49,120 --> 00:02:54,383
Dan lagi, linearitas akan menyiratkan bahwa vektor lain pada garis

40
00:02:54,383 --> 00:03:00,040
diagonal yang direntang oleh orang ini akan diregangkan sebanyak 2 kali.

41
00:03:00,040 --> 00:03:02,868
Dan untuk transformasi ini, itu semua adalah vektor

42
00:03:02,868 --> 00:03:05,860
dengan sifat khusus untuk tetap berada pada rentangnya.

43
00:03:05,860 --> 00:03:09,721
Garis yang berada pada sumbu x diregangkan sebanyak 3 kali,

44
00:03:09,721 --> 00:03:12,940
dan garis diagonalnya diregangkan sebanyak 2 kali.

45
00:03:12,940 --> 00:03:17,675
Vektor lainnya akan diputar selama transformasi,

46
00:03:17,675 --> 00:03:22,700
sehingga menyimpang dari garis yang dibentangkannya.

47
00:03:22,700 --> 00:03:25,676
Seperti yang mungkin sudah Anda duga sekarang,

48
00:03:25,676 --> 00:03:29,792
vektor-vektor khusus ini disebut vektor eigen dari transformasi,

49
00:03:29,792 --> 00:03:34,921
dan setiap vektor eigen dikaitkan dengannya dengan apa yang disebut nilai eigen,

50
00:03:34,921 --> 00:03:40,620
yang merupakan faktor yang merenggangkan atau menekan vektor tersebut selama transformasi.

51
00:03:40,620 --> 00:03:43,495
Tentu saja, tidak ada yang istimewa tentang peregangan

52
00:03:43,495 --> 00:03:46,580
versus pemampatan atau fakta bahwa nilai eigen ini positif.

53
00:03:46,580 --> 00:03:51,952
Dalam contoh lain, Anda dapat memiliki vektor eigen dengan nilai eigen negatif

54
00:03:51,952 --> 00:03:57,460
1 setengah, artinya vektor tersebut dibalik dan diperas dengan faktor 1 setengah.

55
00:03:57,460 --> 00:04:01,157
Namun bagian yang penting di sini adalah ia tetap berada

56
00:04:01,157 --> 00:04:04,660
pada garis yang dibentangkannya tanpa terputar keluar.

57
00:04:04,660 --> 00:04:09,014
Untuk melihat sekilas mengapa hal ini berguna untuk dipikirkan,

58
00:04:09,014 --> 00:04:11,940
pertimbangkan beberapa rotasi tiga dimensi.

59
00:04:11,940 --> 00:04:16,372
Jika Anda dapat menemukan vektor eigen untuk rotasi tersebut,

60
00:04:16,372 --> 00:04:19,946
sebuah vektor yang tetap pada rentangnya sendiri,

61
00:04:19,946 --> 00:04:23,020
maka yang Anda temukan adalah sumbu rotasi.

62
00:04:23,020 --> 00:04:27,561
Dan jauh lebih mudah untuk memikirkan rotasi 3D dalam kaitannya

63
00:04:27,561 --> 00:04:31,108
dengan beberapa sumbu rotasi dan sudut rotasinya,

64
00:04:31,108 --> 00:04:37,140
daripada memikirkan matriks penuh 3 kali 3 yang terkait dengan transformasi tersebut.

65
00:04:37,140 --> 00:04:40,772
Dalam hal ini, nilai eigen yang sesuai haruslah 1,

66
00:04:40,772 --> 00:04:45,117
karena rotasi tidak pernah meregangkan atau menekan apa pun,

67
00:04:45,117 --> 00:04:48,180
sehingga panjang vektornya akan tetap sama.

68
00:04:48,180 --> 00:04:50,580
Pola ini banyak muncul dalam aljabar linier.

69
00:04:50,580 --> 00:04:54,676
Dengan transformasi linier apa pun yang dideskripsikan oleh sebuah matriks,

70
00:04:54,676 --> 00:04:59,419
Anda dapat memahami fungsinya dengan membaca kolom-kolom matriks ini sebagai titik awal

71
00:04:59,419 --> 00:05:00,120
vektor basis.

72
00:05:00,120 --> 00:05:05,133
Namun seringkali, cara yang lebih baik untuk memahami inti dari apa yang

73
00:05:05,133 --> 00:05:10,422
sebenarnya dilakukan transformasi linier, yang tidak terlalu bergantung pada

74
00:05:10,422 --> 00:05:15,780
sistem koordinat tertentu, adalah dengan mencari vektor eigen dan nilai eigen.

75
00:05:15,780 --> 00:05:19,476
Saya tidak akan membahas detail lengkap tentang metode penghitungan vektor

76
00:05:19,476 --> 00:05:23,172
eigen dan nilai eigen di sini, namun saya akan mencoba memberikan gambaran

77
00:05:23,172 --> 00:05:26,820
umum tentang ide komputasi yang paling penting untuk pemahaman konseptual.

78
00:05:26,820 --> 00:05:30,980
Secara simbolis, seperti inilah gagasan tentang vektor eigen.

79
00:05:30,980 --> 00:05:36,533
A adalah matriks yang mewakili suatu transformasi, dengan v sebagai vektor eigen,

80
00:05:36,533 --> 00:05:40,800
dan lambda adalah bilangan, yaitu nilai eigen yang bersesuaian.

81
00:05:40,800 --> 00:05:45,439
Maksud dari ungkapan ini adalah bahwa perkalian vektor-matriks, A kali v,

82
00:05:45,439 --> 00:05:50,705
memberikan hasil yang sama seperti hanya menskalakan vektor eigen v dengan beberapa

83
00:05:50,705 --> 00:05:51,520
nilai lambda.

84
00:05:51,520 --> 00:05:56,669
Jadi mencari vektor eigen dan nilai eigennya dari matriks A

85
00:05:56,669 --> 00:06:02,420
berarti mencari nilai v dan lambda yang membuat ungkapan ini benar.

86
00:06:02,420 --> 00:06:06,594
Agak canggung untuk mengerjakannya pada awalnya karena ruas kiri mewakili

87
00:06:06,594 --> 00:06:11,220
perkalian matriks-vektor, namun ruas kanan di sini adalah perkalian skalar-vektor.

88
00:06:11,220 --> 00:06:14,634
Jadi mari kita mulai dengan menulis ulang ruas kanan tersebut

89
00:06:14,634 --> 00:06:18,049
sebagai semacam perkalian matriks-vektor, menggunakan matriks

90
00:06:18,049 --> 00:06:21,740
yang memiliki efek menskalakan vektor apa pun dengan faktor lambda.

91
00:06:21,740 --> 00:06:26,397
Kolom-kolom matriks tersebut akan mewakili apa yang terjadi pada masing-masing

92
00:06:26,397 --> 00:06:30,464
vektor basis, dan setiap vektor basis hanya dikalikan dengan lambda,

93
00:06:30,464 --> 00:06:34,827
sehingga matriks ini akan mempunyai bilangan lambda di bawah diagonalnya,

94
00:06:34,827 --> 00:06:36,360
dengan nol di tempat lain.

95
00:06:36,360 --> 00:06:39,448
Cara umum untuk menulis orang ini adalah dengan memfaktorkan

96
00:06:39,448 --> 00:06:42,587
lambda tersebut dan menuliskannya sebagai lambda dikalikan i,

97
00:06:42,587 --> 00:06:45,980
dengan i adalah matriks identitas dengan matriks di bawah diagonal.

98
00:06:45,980 --> 00:06:50,068
Karena kedua ruasnya tampak seperti perkalian matriks-vektor,

99
00:06:50,068 --> 00:06:54,420
kita dapat mengurangkan ruas kanan tersebut dan memfaktorkan vnya.

100
00:06:54,420 --> 00:07:00,172
Jadi yang kita punya sekarang adalah matriks baru, A dikurangi lambda dikali identitas,

101
00:07:00,172 --> 00:07:05,860
dan kita mencari vektor v sehingga matriks baru ini, dikali v, menghasilkan vektor nol.

102
00:07:05,860 --> 00:07:10,136
Sekarang, ini akan selalu benar jika v itu sendiri adalah vektor nol,

103
00:07:10,136 --> 00:07:11,420
tapi itu membosankan.

104
00:07:11,420 --> 00:07:14,540
Yang kami inginkan adalah vektor eigen bukan nol.

105
00:07:14,540 --> 00:07:19,673
Dan jika Anda menonton bab 5 dan 6, Anda akan tahu bahwa satu-satunya cara agar

106
00:07:19,673 --> 00:07:24,806
hasil kali matriks dengan vektor bukan nol menjadi nol adalah jika transformasi

107
00:07:24,806 --> 00:07:29,940
yang terkait dengan matriks tersebut menekan ruang ke dimensi yang lebih rendah.

108
00:07:29,940 --> 00:07:35,560
Dan pemerasan itu sesuai dengan determinan nol untuk matriks tersebut.

109
00:07:35,560 --> 00:07:40,810
Untuk lebih konkretnya, misalkan matriks A Anda memiliki kolom 2, 1 dan 2, 3,

110
00:07:40,810 --> 00:07:46,600
dan pikirkan tentang mengurangkan jumlah variabel, lambda, dari setiap entri diagonal.

111
00:07:46,600 --> 00:07:51,160
Sekarang bayangkan mengutak-atik lambda, memutar kenop untuk mengubah nilainya.

112
00:07:51,160 --> 00:07:55,575
Ketika nilai lambda berubah, matriks itu sendiri berubah,

113
00:07:55,575 --> 00:07:58,240
dan determinan matriks pun berubah.

114
00:07:58,240 --> 00:08:01,590
Tujuannya di sini adalah untuk menemukan nilai lambda yang akan

115
00:08:01,590 --> 00:08:04,836
membuat determinan ini menjadi nol, yang berarti transformasi

116
00:08:04,836 --> 00:08:08,240
yang disesuaikan akan menekan ruang ke dimensi yang lebih rendah.

117
00:08:08,240 --> 00:08:12,240
Dalam hal ini, sweet spot muncul ketika lambda sama dengan 1.

118
00:08:12,240 --> 00:08:16,480
Tentu saja, jika kita memilih matriks lain, nilai eigennya belum tentu 1.

119
00:08:16,480 --> 00:08:20,280
Titik manisnya mungkin terkena nilai lambda lainnya.

120
00:08:20,280 --> 00:08:23,620
Jadi ini agak banyak, tapi mari kita uraikan maksudnya.

121
00:08:23,620 --> 00:08:27,120
Ketika lambda sama dengan 1, matriks A dikurangi lambda

122
00:08:27,120 --> 00:08:30,620
dikalikan identitas menekan ruang ke dalam sebuah garis.

123
00:08:30,620 --> 00:08:35,463
Artinya ada vektor bukan nol v sehingga A dikurangi

124
00:08:35,463 --> 00:08:40,680
lambda dikali identitas dikali v sama dengan vektor nol.

125
00:08:40,680 --> 00:08:46,456
Dan ingat, alasan kita mempedulikannya adalah karena ini berarti A dikali v sama

126
00:08:46,456 --> 00:08:52,518
dengan lambda dikali v, yang dapat Anda baca dengan menyatakan bahwa vektor v adalah

127
00:08:52,518 --> 00:08:58,580
vektor eigen dari A, yang tetap berada pada rentangnya sendiri selama transformasi A.

128
00:08:58,580 --> 00:09:02,853
Dalam contoh ini, nilai eigen yang terkait adalah 1,

129
00:09:02,853 --> 00:09:06,240
jadi v sebenarnya akan tetap di tempatnya.

130
00:09:06,240 --> 00:09:09,968
Berhentilah sejenak dan renungkan apakah Anda perlu

131
00:09:09,968 --> 00:09:13,840
memastikan bahwa alur pemikiran tersebut terasa tepat.

132
00:09:13,840 --> 00:09:16,280
Ini adalah hal yang saya sebutkan di pendahuluan.

133
00:09:16,280 --> 00:09:20,150
Jika Anda tidak memiliki pemahaman yang kuat tentang determinan dan

134
00:09:20,150 --> 00:09:24,191
mengapa determinan tersebut berhubungan dengan sistem persamaan linier

135
00:09:24,191 --> 00:09:28,460
yang memiliki solusi bukan nol, ekspresi seperti ini akan terasa tiba-tiba.

136
00:09:28,460 --> 00:09:32,673
Untuk melihat cara kerjanya, mari kita lihat kembali contoh dari awal,

137
00:09:32,673 --> 00:09:35,640
dengan matriks yang kolomnya adalah 3, 0 dan 1, 2.

138
00:09:35,640 --> 00:09:44,220
Untuk mengetahui apakah suatu nilai lambda merupakan nilai eigen,

139
00:09:44,220 --> 00:09:51,240
kurangi diagonal matriks ini dan hitung determinannya.

140
00:09:51,240 --> 00:09:55,476
Dengan melakukan ini, kita mendapatkan polinomial kuadrat tertentu di lambda,

141
00:09:55,476 --> 00:09:57,920
3 dikurangi lambda dikali 2 dikurangi lambda.

142
00:09:57,920 --> 00:10:02,848
Karena lambda hanya dapat menjadi nilai eigen jika determinannya sama dengan nol,

143
00:10:02,848 --> 00:10:06,934
Anda dapat menyimpulkan bahwa satu-satunya nilai eigen yang mungkin

144
00:10:06,934 --> 00:10:10,120
adalah lambda sama dengan 2 dan lambda sama dengan 3.

145
00:10:10,120 --> 00:10:15,278
Untuk mengetahui vektor eigen apa yang sebenarnya memiliki salah satu nilai eigen ini,

146
00:10:15,278 --> 00:10:19,785
katakanlah lambda sama dengan 2, masukkan nilai lambda tersebut ke matriks,

147
00:10:19,785 --> 00:10:25,062
lalu selesaikan vektor mana yang dikirim ke nol oleh matriks yang diubah secara diagonal

148
00:10:25,062 --> 00:10:25,300
ini.

149
00:10:25,300 --> 00:10:29,592
Jika Anda menghitungnya seperti yang Anda lakukan pada sistem linier lainnya,

150
00:10:29,592 --> 00:10:32,838
Anda akan melihat bahwa solusinya adalah semua vektor pada

151
00:10:32,838 --> 00:10:35,480
garis diagonal yang direntang oleh negatif 1, 1.

152
00:10:35,480 --> 00:10:40,146
Hal ini sesuai dengan fakta bahwa matriks yang tidak diubah, 3, 0, 1,

153
00:10:40,146 --> 00:10:44,680
2, mempunyai efek meregangkan semua vektor tersebut dengan faktor 2.

154
00:10:44,680 --> 00:10:50,880
Sekarang, transformasi 2D tidak harus memiliki vektor eigen.

155
00:10:50,880 --> 00:10:53,960
Misalnya, bayangkan rotasi sebesar 90 derajat.

156
00:10:53,960 --> 00:10:57,504
Ini tidak memiliki vektor eigen apa pun karena

157
00:10:57,504 --> 00:11:01,200
ia memutar setiap vektor dari rentangnya sendiri.

158
00:11:01,200 --> 00:11:05,026
Jika Anda benar-benar mencoba menghitung nilai eigen dari rotasi seperti ini,

159
00:11:05,026 --> 00:11:06,400
perhatikan apa yang terjadi.

160
00:11:06,400 --> 00:11:11,120
Matriksnya memiliki kolom 0, 1 dan negatif 1, 0.

161
00:11:11,120 --> 00:11:18,440
Kurangi lambda dari elemen diagonal dan cari determinannya nol.

162
00:11:18,440 --> 00:11:22,960
Dalam hal ini, Anda mendapatkan lambda polinomial kuadrat ditambah 1.

163
00:11:22,960 --> 00:11:29,000
Akar polinomial tersebut hanyalah bilangan imajiner, i dan negatif i.

164
00:11:29,000 --> 00:11:36,120
Fakta bahwa tidak ada solusi bilangan real menunjukkan bahwa tidak ada vektor eigen.

165
00:11:36,120 --> 00:11:40,640
Contoh lain yang cukup menarik yang patut diingat adalah sebuah guntingan.

166
00:11:40,640 --> 00:11:45,522
Ini memperbaiki i-hat di tempatnya dan memindahkan j-hat 1 ke atas,

167
00:11:45,522 --> 00:11:49,040
sehingga matriksnya memiliki kolom 1, 0 dan 1, 1.

168
00:11:49,040 --> 00:11:52,124
Semua vektor pada sumbu x merupakan vektor eigen dengan nilai

169
00:11:52,124 --> 00:11:55,060
eigen 1 karena vektor-vektor tersebut tetap pada tempatnya.

170
00:11:55,060 --> 00:11:58,880
Faktanya, ini adalah satu-satunya vektor eigen.

171
00:11:58,880 --> 00:12:05,077
Saat Anda mengurangi lambda dari diagonal dan menghitung determinannya,

172
00:12:05,077 --> 00:12:09,640
yang Anda dapatkan adalah 1 dikurangi lambda kuadrat.

173
00:12:09,640 --> 00:12:15,080
Dan satu-satunya akar dari ungkapan ini adalah lambda sama dengan 1.

174
00:12:15,080 --> 00:12:18,504
Hal ini sejalan dengan apa yang kita lihat secara geometris,

175
00:12:18,504 --> 00:12:21,200
bahwa semua vektor eigen memiliki nilai eigen 1.

176
00:12:21,200 --> 00:12:25,869
Namun perlu diingat, dimungkinkan juga untuk hanya memiliki satu nilai eigen,

177
00:12:25,869 --> 00:12:30,000
namun dengan lebih dari sekedar garis yang penuh dengan vektor eigen.

178
00:12:30,000 --> 00:12:34,040
Contoh sederhananya adalah matriks yang menskalakan semuanya dengan 2.

179
00:12:34,040 --> 00:12:38,369
Satu-satunya nilai eigen adalah 2, tetapi setiap vektor pada bidang

180
00:12:38,369 --> 00:12:42,380
tersebut akan menjadi vektor eigen dengan nilai eigen tersebut.

181
00:12:42,380 --> 00:12:52,072
Sekarang adalah saat yang tepat untuk berhenti sejenak dan

182
00:12:52,072 --> 00:13:03,900
merenungkan beberapa hal ini sebelum saya melanjutkan ke topik terakhir.

183
00:13:03,900 --> 00:13:08,100
Saya ingin mengakhiri di sini dengan gagasan tentang eigenbasis,

184
00:13:08,100 --> 00:13:11,720
yang sangat bergantung pada gagasan dari video terakhir.

185
00:13:11,720 --> 00:13:17,220
Lihatlah apa yang terjadi jika vektor basis kita kebetulan merupakan vektor eigen.

186
00:13:17,220 --> 00:13:23,760
Misalnya, mungkin i-hat berskala negatif 1, dan j-hat berskala 2.

187
00:13:23,760 --> 00:13:27,204
Menuliskan koordinat barunya sebagai kolom matriks,

188
00:13:27,204 --> 00:13:31,244
perhatikan bahwa kelipatan skalar tersebut, negatif 1 dan 2,

189
00:13:31,244 --> 00:13:36,808
yang merupakan nilai eigen dari i-hat dan j-hat, berada pada diagonal matriks kita,

190
00:13:36,808 --> 00:13:39,060
dan setiap entri lainnya adalah 0.

191
00:13:39,060 --> 00:13:44,087
Setiap kali suatu matriks mempunyai angka 0 di mana pun selain diagonal,

192
00:13:44,087 --> 00:13:47,393
maka matriks tersebut disebut matriks diagonal,

193
00:13:47,393 --> 00:13:53,109
dan cara untuk menafsirkannya adalah bahwa semua vektor basis adalah vektor eigen,

194
00:13:53,109 --> 00:13:57,380
dengan entri diagonal dari matriks ini menjadi nilai eigennya.

195
00:13:57,380 --> 00:14:02,060
Ada banyak hal yang membuat matriks diagonal lebih baik untuk dikerjakan.

196
00:14:02,060 --> 00:14:05,829
Salah satu kelebihannya adalah lebih mudah menghitung apa yang akan terjadi

197
00:14:05,829 --> 00:14:09,500
jika Anda mengalikan matriks ini dengan matriks itu sendiri beberapa kali.

198
00:14:09,500 --> 00:14:13,624
Karena yang dilakukan matriks ini hanyalah menskalakan setiap vektor

199
00:14:13,624 --> 00:14:18,228
basis dengan beberapa nilai eigen, menerapkan matriks tersebut berkali-kali,

200
00:14:18,228 --> 00:14:22,293
katakanlah 100 kali, hanya akan menyamakan penskalaan setiap vektor

201
00:14:22,293 --> 00:14:25,880
basis dengan pangkat 100 dari nilai eigen yang bersangkutan.

202
00:14:25,880 --> 00:14:29,940
Sebaliknya, coba hitung pangkat 100 dari matriks non-diagonal.

203
00:14:29,940 --> 00:14:31,940
Sungguh, cobalah sejenak.

204
00:14:31,940 --> 00:14:36,500
Ini mimpi buruk.

205
00:14:36,500 --> 00:14:39,420
Tentu saja, Anda jarang sekali beruntung karena

206
00:14:39,420 --> 00:14:42,220
vektor basis Anda juga merupakan vektor eigen.

207
00:14:42,220 --> 00:14:45,560
Namun jika transformasi Anda memiliki banyak vektor eigen,

208
00:14:45,560 --> 00:14:50,485
seperti yang ada di awal video ini, sehingga Anda dapat memilih himpunan yang mencakup

209
00:14:50,485 --> 00:14:55,468
seluruh ruang, maka Anda dapat mengubah sistem koordinat sehingga vektor eigen tersebut

210
00:14:55,468 --> 00:14:56,940
menjadi vektor basis Anda.

211
00:14:56,940 --> 00:14:59,827
Saya berbicara tentang perubahan basis di video terakhir,

212
00:14:59,827 --> 00:15:03,959
tapi saya akan membahas pengingat super cepat di sini tentang cara mengekspresikan

213
00:15:03,959 --> 00:15:07,892
transformasi yang saat ini ditulis dalam sistem koordinat kita ke dalam sistem

214
00:15:07,892 --> 00:15:08,540
yang berbeda.

215
00:15:08,540 --> 00:15:11,870
Ambil koordinat vektor-vektor yang ingin dijadikan basis baru,

216
00:15:11,870 --> 00:15:14,512
yang dalam hal ini berarti dua vektor eigen kita,

217
00:15:14,512 --> 00:15:18,054
lalu jadikan koordinat tersebut sebagai kolom-kolom suatu matriks,

218
00:15:18,054 --> 00:15:20,380
yang disebut dengan matriks perubahan basis.

219
00:15:20,380 --> 00:15:24,588
Ketika Anda mengapit transformasi asli, meletakkan matriks perubahan

220
00:15:24,588 --> 00:15:30,016
basis di sebelah kanannya dan kebalikan dari matriks perubahan basis di sebelah kirinya,

221
00:15:30,016 --> 00:15:34,102
hasilnya akan berupa matriks yang mewakili transformasi yang sama,

222
00:15:34,102 --> 00:15:37,640
tetapi dari perspektif koordinat vektor basis baru sistem.

223
00:15:37,640 --> 00:15:42,262
Inti dari melakukan hal ini dengan vektor eigen adalah bahwa matriks baru ini

224
00:15:42,262 --> 00:15:47,300
dijamin berbentuk diagonal dengan nilai eigen yang sesuai di bawah diagonal tersebut.

225
00:15:47,300 --> 00:15:51,289
Hal ini karena ini mewakili pekerjaan dalam sistem koordinat di mana apa yang

226
00:15:51,289 --> 00:15:55,740
terjadi pada vektor basis adalah vektor-vektor tersebut diskalakan selama transformasi.

227
00:15:55,740 --> 00:16:02,400
Sekumpulan vektor basis yang juga merupakan vektor eigen disebut dengan basis eigen.

228
00:16:02,400 --> 00:16:07,207
Jadi jika, misalnya, Anda perlu menghitung pangkat ke-100 dari matriks ini,

229
00:16:07,207 --> 00:16:10,434
akan lebih mudah untuk mengubahnya ke basis eigen,

230
00:16:10,434 --> 00:16:13,533
menghitung pangkat ke-100 dalam sistem tersebut,

231
00:16:13,533 --> 00:16:16,760
lalu mengonversinya kembali ke sistem standar kita.

232
00:16:16,760 --> 00:16:18,460
Anda tidak dapat melakukan ini dengan semua transformasi.

233
00:16:18,460 --> 00:16:21,073
Sebuah geser, misalnya, tidak memiliki vektor

234
00:16:21,073 --> 00:16:23,800
eigen yang cukup untuk menjangkau seluruh ruang.

235
00:16:23,800 --> 00:16:26,437
Tetapi jika Anda dapat menemukan basis eigen, itu

236
00:16:26,437 --> 00:16:29,180
membuat operasi matriks menjadi sangat menyenangkan.

237
00:16:29,180 --> 00:16:31,994
Bagi Anda yang ingin menyelesaikan teka-teki yang cukup rapi untuk melihat

238
00:16:31,994 --> 00:16:34,883
seperti apa aksinya dan bagaimana hal ini dapat digunakan untuk menghasilkan

239
00:16:34,883 --> 00:16:37,960
beberapa hasil yang mengejutkan, saya akan meninggalkan petunjuk di sini di layar.

240
00:16:37,960 --> 00:16:40,960
Memang butuh sedikit usaha, tapi menurut saya Anda akan menikmatinya.

241
00:16:40,960 --> 00:16:46,000
Video berikutnya dan terakhir dari seri ini akan membahas tentang ruang vektor abstrak.

242
00:16:46,000 --> 00:16:46,000
Sampai jumpa lagi!

