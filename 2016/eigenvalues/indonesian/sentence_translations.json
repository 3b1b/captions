[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "model": "nmt",
  "translatedText": "Vektor eigen dan nilai eigen adalah salah satu topik yang menurut banyak siswa tidak intuitif.",
  "time_range": [
   19.282,
   26.46
  ]
 },
 {
  "input": "Things like, why are we doing this, and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "model": "nmt",
  "translatedText": "Hal-hal seperti, mengapa kita melakukan hal ini, dan apa maksud sebenarnya dari hal ini, sering kali dibiarkan begitu saja dalam lautan perhitungan yang tidak terjawab.",
  "time_range": [
   26.46,
   34.02
  ]
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "model": "nmt",
  "translatedText": "Dan saat saya merilis video seri ini, banyak dari Anda berkomentar tentang menantikan memvisualisasikan topik ini secara khusus.",
  "time_range": [
   34.02,
   40.7
  ]
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "model": "nmt",
  "translatedText": "Saya menduga alasannya bukan karena eigenthings menjadi rumit atau tidak dijelaskan dengan baik.",
  "time_range": [
   40.7,
   46.46
  ]
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "model": "nmt",
  "translatedText": "Faktanya, ini relatif mudah, dan menurut saya sebagian besar buku mampu menjelaskannya dengan baik.",
  "time_range": [
   46.46,
   52.02
  ]
 },
 {
  "input": "What I want to do is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "model": "nmt",
  "translatedText": "Apa yang ingin saya lakukan adalah hal ini hanya masuk akal jika Anda memiliki pemahaman visual yang kuat untuk banyak topik sebelumnya.",
  "time_range": [
   52.02,
   59.22
  ]
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "model": "nmt",
  "translatedText": "Yang terpenting di sini adalah Anda mengetahui cara berpikir matriks sebagai transformasi linier, namun Anda juga harus memahami hal-hal seperti determinan, sistem persamaan linier, dan perubahan basis.",
  "time_range": [
   59.22,
   70.78
  ]
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "model": "nmt",
  "translatedText": "Kebingungan mengenai eigenstuff biasanya lebih berkaitan dengan fondasi yang goyah dalam salah satu topik ini dibandingkan dengan vektor eigen dan nilai eigen itu sendiri.",
  "time_range": [
   70.78,
   80.42
  ]
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "model": "nmt",
  "translatedText": "Untuk memulai, pertimbangkan beberapa transformasi linier dalam dua dimensi, seperti yang ditunjukkan di sini.",
  "time_range": [
   80.42,
   85.5
  ]
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "model": "nmt",
  "translatedText": "Ini memindahkan vektor basis i-hat ke koordinat 3, 0, dan j-hat ke 1, 2.",
  "time_range": [
   85.5,
   91.86
  ]
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "model": "nmt",
  "translatedText": "Jadi direpresentasikan dengan matriks yang kolomnya 3, 0, dan 1, 2.",
  "time_range": [
   91.86,
   96.86
  ]
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "model": "nmt",
  "translatedText": "Fokuslah pada apa yang dilakukannya pada satu vektor tertentu, dan pikirkan tentang rentang vektor tersebut, garis yang melalui titik asal dan ujungnya.",
  "time_range": [
   96.86,
   105.22
  ]
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "model": "nmt",
  "translatedText": "Kebanyakan vektor akan kehilangan rentangnya selama transformasi.",
  "time_range": [
   105.22,
   108.5
  ]
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "model": "nmt",
  "translatedText": "Maksud saya, akan terlihat sangat kebetulan jika tempat pendaratan vektor juga berada di suatu tempat di garis tersebut.",
  "time_range": [
   108.5,
   117.5
  ]
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "model": "nmt",
  "translatedText": "Namun beberapa vektor khusus tetap berada pada rentangnya sendiri, yang berarti bahwa pengaruh matriks terhadap vektor tersebut hanyalah merenggangkan atau menekannya, seperti skalar.",
  "time_range": [
   117.5,
   129.66
  ]
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "model": "nmt",
  "translatedText": "Untuk contoh spesifik ini, vektor basis i-hat adalah salah satu vektor khusus tersebut.",
  "time_range": [
   129.66,
   135.1
  ]
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "model": "nmt",
  "translatedText": "Rentang i-hat adalah sumbu x, dan dari kolom pertama matriks terlihat bahwa i-hat berpindah sebanyak 3 kali, masih pada sumbu x tersebut.",
  "time_range": [
   135.1,
   146.5
  ]
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "model": "nmt",
  "translatedText": "Terlebih lagi, karena cara kerja transformasi linier, vektor lain pada sumbu x juga hanya diregangkan sebanyak 3 kali, dan karenanya tetap berada pada rentangnya sendiri.",
  "time_range": [
   146.5,
   158.58
  ]
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "model": "nmt",
  "translatedText": "Vektor yang sedikit lebih licik yang tetap berada pada rentangnya sendiri selama transformasi ini adalah negatif 1, 1.",
  "time_range": [
   158.58,
   164.88
  ]
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "model": "nmt",
  "translatedText": "Itu akhirnya diregangkan dengan faktor 2.",
  "time_range": [
   164.88,
   169.12
  ]
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "model": "nmt",
  "translatedText": "Dan lagi, linearitas akan menyiratkan bahwa vektor lain pada garis diagonal yang direntang oleh orang ini akan diregangkan sebanyak 2 kali.",
  "time_range": [
   169.12,
   180.04
  ]
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "model": "nmt",
  "translatedText": "Dan untuk transformasi ini, itu semua adalah vektor dengan sifat khusus untuk tetap berada pada rentangnya.",
  "time_range": [
   180.04,
   185.86
  ]
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "model": "nmt",
  "translatedText": "Garis yang berada pada sumbu x diregangkan sebanyak 3 kali, dan garis diagonalnya diregangkan sebanyak 2 kali.",
  "time_range": [
   185.86,
   192.94
  ]
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "model": "nmt",
  "translatedText": "Vektor lainnya akan diputar selama transformasi, sehingga menyimpang dari garis yang dibentangkannya.",
  "time_range": [
   192.94,
   202.7
  ]
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "model": "nmt",
  "translatedText": "Seperti yang mungkin sudah Anda duga sekarang, vektor-vektor khusus ini disebut vektor eigen dari transformasi, dan setiap vektor eigen dikaitkan dengannya dengan apa yang disebut nilai eigen, yang merupakan faktor yang merenggangkan atau menekan vektor tersebut selama transformasi.",
  "time_range": [
   202.7,
   220.62
  ]
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing or the fact that these eigenvalues happen to be positive.",
  "model": "nmt",
  "translatedText": "Tentu saja, tidak ada yang istimewa tentang peregangan versus pemampatan atau fakta bahwa nilai eigen ini positif.",
  "time_range": [
   220.62,
   226.58
  ]
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "model": "nmt",
  "translatedText": "Dalam contoh lain, Anda dapat memiliki vektor eigen dengan nilai eigen negatif 1 setengah, artinya vektor tersebut dibalik dan diperas dengan faktor 1 setengah.",
  "time_range": [
   226.58,
   237.46
  ]
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "model": "nmt",
  "translatedText": "Namun bagian yang penting di sini adalah ia tetap berada pada garis yang dibentangkannya tanpa terputar keluar.",
  "time_range": [
   237.46,
   244.66
  ]
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "model": "nmt",
  "translatedText": "Untuk melihat sekilas mengapa hal ini berguna untuk dipikirkan, pertimbangkan beberapa rotasi tiga dimensi.",
  "time_range": [
   244.66,
   251.94
  ]
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "model": "nmt",
  "translatedText": "Jika Anda dapat menemukan vektor eigen untuk rotasi tersebut, sebuah vektor yang tetap pada rentangnya sendiri, maka yang Anda temukan adalah sumbu rotasi.",
  "time_range": [
   251.94,
   263.02
  ]
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3 by 3 matrix associated with that transformation.",
  "model": "nmt",
  "translatedText": "Dan jauh lebih mudah untuk memikirkan rotasi 3D dalam kaitannya dengan beberapa sumbu rotasi dan sudut rotasinya, daripada memikirkan matriks penuh 3 kali 3 yang terkait dengan transformasi tersebut.",
  "time_range": [
   263.02,
   277.14
  ]
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "model": "nmt",
  "translatedText": "Dalam hal ini, nilai eigen yang sesuai haruslah 1, karena rotasi tidak pernah meregangkan atau menekan apa pun, sehingga panjang vektornya akan tetap sama.",
  "time_range": [
   277.14,
   288.18
  ]
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "model": "nmt",
  "translatedText": "Pola ini banyak muncul dalam aljabar linier.",
  "time_range": [
   288.18,
   290.58
  ]
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "model": "nmt",
  "translatedText": "Dengan transformasi linier apa pun yang dideskripsikan oleh sebuah matriks, Anda dapat memahami fungsinya dengan membaca kolom-kolom matriks ini sebagai titik awal vektor basis.",
  "time_range": [
   290.58,
   300.12
  ]
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "model": "nmt",
  "translatedText": "Namun seringkali, cara yang lebih baik untuk memahami inti dari apa yang sebenarnya dilakukan transformasi linier, yang tidak terlalu bergantung pada sistem koordinat tertentu, adalah dengan mencari vektor eigen dan nilai eigen.",
  "time_range": [
   300.12,
   315.78
  ]
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "model": "nmt",
  "translatedText": "Saya tidak akan membahas detail lengkap tentang metode penghitungan vektor eigen dan nilai eigen di sini, namun saya akan mencoba memberikan gambaran umum tentang ide komputasi yang paling penting untuk pemahaman konseptual.",
  "time_range": [
   315.78,
   326.82
  ]
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "model": "nmt",
  "translatedText": "Secara simbolis, seperti inilah gagasan tentang vektor eigen.",
  "time_range": [
   326.82,
   330.98
  ]
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "model": "nmt",
  "translatedText": "A adalah matriks yang mewakili suatu transformasi, dengan v sebagai vektor eigen, dan lambda adalah bilangan, yaitu nilai eigen yang bersesuaian.",
  "time_range": [
   330.98,
   340.8
  ]
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "model": "nmt",
  "translatedText": "Maksud dari ungkapan ini adalah bahwa perkalian vektor-matriks, A kali v, memberikan hasil yang sama seperti hanya menskalakan vektor eigen v dengan beberapa nilai lambda.",
  "time_range": [
   340.8,
   351.52
  ]
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "model": "nmt",
  "translatedText": "Jadi mencari vektor eigen dan nilai eigennya dari matriks A berarti mencari nilai v dan lambda yang membuat ungkapan ini benar.",
  "time_range": [
   351.52,
   362.42
  ]
 },
 {
  "input": "It's a little awkward to work with at first because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "model": "nmt",
  "translatedText": "Agak canggung untuk mengerjakannya pada awalnya karena ruas kiri mewakili perkalian matriks-vektor, namun ruas kanan di sini adalah perkalian skalar-vektor.",
  "time_range": [
   362.42,
   371.22
  ]
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "model": "nmt",
  "translatedText": "Jadi mari kita mulai dengan menulis ulang ruas kanan tersebut sebagai semacam perkalian matriks-vektor, menggunakan matriks yang memiliki efek menskalakan vektor apa pun dengan faktor lambda.",
  "time_range": [
   371.22,
   381.74
  ]
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "model": "nmt",
  "translatedText": "Kolom-kolom matriks tersebut akan mewakili apa yang terjadi pada masing-masing vektor basis, dan setiap vektor basis hanya dikalikan dengan lambda, sehingga matriks ini akan mempunyai bilangan lambda di bawah diagonalnya, dengan nol di tempat lain.",
  "time_range": [
   381.74,
   396.36
  ]
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with ones down the diagonal.",
  "model": "nmt",
  "translatedText": "Cara umum untuk menulis orang ini adalah dengan memfaktorkan lambda tersebut dan menuliskannya sebagai lambda dikalikan i, dengan i adalah matriks identitas dengan matriks di bawah diagonal.",
  "time_range": [
   396.36,
   405.98
  ]
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "model": "nmt",
  "translatedText": "Karena kedua ruasnya tampak seperti perkalian matriks-vektor, kita dapat mengurangkan ruas kanan tersebut dan memfaktorkan vnya.",
  "time_range": [
   405.98,
   414.42
  ]
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix, times v, gives the zero vector.",
  "model": "nmt",
  "translatedText": "Jadi yang kita punya sekarang adalah matriks baru, A dikurangi lambda dikali identitas, dan kita mencari vektor v sehingga matriks baru ini, dikali v, menghasilkan vektor nol.",
  "time_range": [
   414.42,
   425.86
  ]
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "model": "nmt",
  "translatedText": "Sekarang, ini akan selalu benar jika v itu sendiri adalah vektor nol, tapi itu membosankan.",
  "time_range": [
   425.86,
   431.42
  ]
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "model": "nmt",
  "translatedText": "Yang kami inginkan adalah vektor eigen bukan nol.",
  "time_range": [
   431.42,
   434.54
  ]
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "model": "nmt",
  "translatedText": "Dan jika Anda menonton bab 5 dan 6, Anda akan tahu bahwa satu-satunya cara agar hasil kali matriks dengan vektor bukan nol menjadi nol adalah jika transformasi yang terkait dengan matriks tersebut menekan ruang ke dimensi yang lebih rendah.",
  "time_range": [
   434.54,
   449.94
  ]
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "model": "nmt",
  "translatedText": "Dan pemerasan itu sesuai dengan determinan nol untuk matriks tersebut.",
  "time_range": [
   449.94,
   455.56
  ]
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "model": "nmt",
  "translatedText": "Untuk lebih konkretnya, misalkan matriks A Anda memiliki kolom 2, 1 dan 2, 3, dan pikirkan tentang mengurangkan jumlah variabel, lambda, dari setiap entri diagonal.",
  "time_range": [
   455.56,
   466.6
  ]
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "model": "nmt",
  "translatedText": "Sekarang bayangkan mengutak-atik lambda, memutar kenop untuk mengubah nilainya.",
  "time_range": [
   466.6,
   471.16
  ]
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "model": "nmt",
  "translatedText": "Ketika nilai lambda berubah, matriks itu sendiri berubah, dan determinan matriks pun berubah.",
  "time_range": [
   471.16,
   478.24
  ]
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "model": "nmt",
  "translatedText": "Tujuannya di sini adalah untuk menemukan nilai lambda yang akan membuat determinan ini menjadi nol, yang berarti transformasi yang disesuaikan akan menekan ruang ke dimensi yang lebih rendah.",
  "time_range": [
   478.24,
   488.24
  ]
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "model": "nmt",
  "translatedText": "Dalam hal ini, sweet spot muncul ketika lambda sama dengan 1.",
  "time_range": [
   488.24,
   492.24
  ]
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "model": "nmt",
  "translatedText": "Tentu saja, jika kita memilih matriks lain, nilai eigennya belum tentu 1.",
  "time_range": [
   492.24,
   496.48
  ]
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "model": "nmt",
  "translatedText": "Titik manisnya mungkin terkena nilai lambda lainnya.",
  "time_range": [
   496.48,
   500.28
  ]
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "model": "nmt",
  "translatedText": "Jadi ini agak banyak, tapi mari kita uraikan maksudnya.",
  "time_range": [
   500.28,
   503.62
  ]
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "model": "nmt",
  "translatedText": "Ketika lambda sama dengan 1, matriks A dikurangi lambda dikalikan identitas menekan ruang ke dalam sebuah garis.",
  "time_range": [
   503.62,
   510.62
  ]
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "model": "nmt",
  "translatedText": "Artinya ada vektor bukan nol v sehingga A dikurangi lambda dikali identitas dikali v sama dengan vektor nol.",
  "time_range": [
   510.62,
   520.68
  ]
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "model": "nmt",
  "translatedText": "Dan ingat, alasan kita mempedulikannya adalah karena ini berarti A dikali v sama dengan lambda dikali v, yang dapat Anda baca dengan menyatakan bahwa vektor v adalah vektor eigen dari A, yang tetap berada pada rentangnya sendiri selama transformasi A.",
  "time_range": [
   520.68,
   538.58
  ]
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "model": "nmt",
  "translatedText": "Dalam contoh ini, nilai eigen yang terkait adalah 1, jadi v sebenarnya akan tetap di tempatnya.",
  "time_range": [
   538.58,
   546.24
  ]
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "model": "nmt",
  "translatedText": "Berhentilah sejenak dan renungkan apakah Anda perlu memastikan bahwa alur pemikiran tersebut terasa tepat.",
  "time_range": [
   546.24,
   553.84
  ]
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "model": "nmt",
  "translatedText": "Ini adalah hal yang saya sebutkan di pendahuluan.",
  "time_range": [
   553.84,
   556.28
  ]
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "model": "nmt",
  "translatedText": "Jika Anda tidak memiliki pemahaman yang kuat tentang determinan dan mengapa determinan tersebut berhubungan dengan sistem persamaan linier yang memiliki solusi bukan nol, ekspresi seperti ini akan terasa tiba-tiba.",
  "time_range": [
   556.28,
   568.46
  ]
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "model": "nmt",
  "translatedText": "Untuk melihat cara kerjanya, mari kita lihat kembali contoh dari awal, dengan matriks yang kolomnya adalah 3, 0 dan 1, 2.",
  "time_range": [
   568.46,
   575.64
  ]
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "model": "nmt",
  "translatedText": "Untuk mengetahui apakah suatu nilai lambda merupakan nilai eigen, kurangi diagonal matriks ini dan hitung determinannya.",
  "time_range": [
   575.64,
   591.24
  ]
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "model": "nmt",
  "translatedText": "Dengan melakukan ini, kita mendapatkan polinomial kuadrat tertentu di lambda, 3 dikurangi lambda dikali 2 dikurangi lambda.",
  "time_range": [
   591.24,
   597.92
  ]
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "model": "nmt",
  "translatedText": "Karena lambda hanya dapat menjadi nilai eigen jika determinannya sama dengan nol, Anda dapat menyimpulkan bahwa satu-satunya nilai eigen yang mungkin adalah lambda sama dengan 2 dan lambda sama dengan 3.",
  "time_range": [
   597.92,
   610.12
  ]
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "model": "nmt",
  "translatedText": "Untuk mengetahui vektor eigen apa yang sebenarnya memiliki salah satu nilai eigen ini, katakanlah lambda sama dengan 2, masukkan nilai lambda tersebut ke matriks, lalu selesaikan vektor mana yang dikirim ke nol oleh matriks yang diubah secara diagonal ini.",
  "time_range": [
   610.12,
   625.3
  ]
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "model": "nmt",
  "translatedText": "Jika Anda menghitungnya seperti yang Anda lakukan pada sistem linier lainnya, Anda akan melihat bahwa solusinya adalah semua vektor pada garis diagonal yang direntang oleh negatif 1, 1.",
  "time_range": [
   625.3,
   635.48
  ]
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "model": "nmt",
  "translatedText": "Hal ini sesuai dengan fakta bahwa matriks yang tidak diubah, 3, 0, 1, 2, mempunyai efek meregangkan semua vektor tersebut dengan faktor 2.",
  "time_range": [
   635.48,
   644.68
  ]
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "model": "nmt",
  "translatedText": "Sekarang, transformasi 2D tidak harus memiliki vektor eigen.",
  "time_range": [
   644.68,
   650.88
  ]
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "model": "nmt",
  "translatedText": "Misalnya, bayangkan rotasi sebesar 90 derajat.",
  "time_range": [
   650.88,
   653.96
  ]
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "model": "nmt",
  "translatedText": "Ini tidak memiliki vektor eigen apa pun karena ia memutar setiap vektor dari rentangnya sendiri.",
  "time_range": [
   653.96,
   661.2
  ]
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "model": "nmt",
  "translatedText": "Jika Anda benar-benar mencoba menghitung nilai eigen dari rotasi seperti ini, perhatikan apa yang terjadi.",
  "time_range": [
   661.2,
   666.4
  ]
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "model": "nmt",
  "translatedText": "Matriksnya memiliki kolom 0, 1 dan negatif 1, 0.",
  "time_range": [
   666.4,
   671.12
  ]
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "model": "nmt",
  "translatedText": "Kurangi lambda dari elemen diagonal dan cari determinannya nol.",
  "time_range": [
   671.12,
   678.44
  ]
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "model": "nmt",
  "translatedText": "Dalam hal ini, Anda mendapatkan lambda polinomial kuadrat ditambah 1.",
  "time_range": [
   678.44,
   682.96
  ]
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "model": "nmt",
  "translatedText": "Akar polinomial tersebut hanyalah bilangan imajiner, i dan negatif i.",
  "time_range": [
   682.96,
   689.0
  ]
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "model": "nmt",
  "translatedText": "Fakta bahwa tidak ada solusi bilangan real menunjukkan bahwa tidak ada vektor eigen.",
  "time_range": [
   689.0,
   696.12
  ]
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "model": "nmt",
  "translatedText": "Contoh lain yang cukup menarik yang patut diingat adalah sebuah guntingan.",
  "time_range": [
   696.12,
   700.64
  ]
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "model": "nmt",
  "translatedText": "Ini memperbaiki i-hat di tempatnya dan memindahkan j-hat 1 ke atas, sehingga matriksnya memiliki kolom 1, 0 dan 1, 1.",
  "time_range": [
   700.64,
   709.04
  ]
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "model": "nmt",
  "translatedText": "Semua vektor pada sumbu x merupakan vektor eigen dengan nilai eigen 1 karena vektor-vektor tersebut tetap pada tempatnya.",
  "time_range": [
   709.04,
   715.06
  ]
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "model": "nmt",
  "translatedText": "Faktanya, ini adalah satu-satunya vektor eigen.",
  "time_range": [
   715.06,
   718.88
  ]
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "model": "nmt",
  "translatedText": "Saat Anda mengurangi lambda dari diagonal dan menghitung determinannya, yang Anda dapatkan adalah 1 dikurangi lambda kuadrat.",
  "time_range": [
   718.88,
   729.64
  ]
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "model": "nmt",
  "translatedText": "Dan satu-satunya akar dari ungkapan ini adalah lambda sama dengan 1.",
  "time_range": [
   729.64,
   735.08
  ]
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "model": "nmt",
  "translatedText": "Hal ini sejalan dengan apa yang kita lihat secara geometris, bahwa semua vektor eigen memiliki nilai eigen 1.",
  "time_range": [
   735.08,
   741.2
  ]
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "model": "nmt",
  "translatedText": "Namun perlu diingat, dimungkinkan juga untuk hanya memiliki satu nilai eigen, namun dengan lebih dari sekedar garis yang penuh dengan vektor eigen.",
  "time_range": [
   741.2,
   750.0
  ]
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "model": "nmt",
  "translatedText": "Contoh sederhananya adalah matriks yang menskalakan semuanya dengan 2.",
  "time_range": [
   750.0,
   754.04
  ]
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "model": "nmt",
  "translatedText": "Satu-satunya nilai eigen adalah 2, tetapi setiap vektor pada bidang tersebut akan menjadi vektor eigen dengan nilai eigen tersebut.",
  "time_range": [
   754.04,
   762.38
  ]
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "model": "nmt",
  "translatedText": "Sekarang adalah saat yang tepat untuk berhenti sejenak dan merenungkan beberapa hal ini sebelum saya melanjutkan ke topik terakhir.",
  "time_range": [
   762.38,
   783.9
  ]
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "model": "nmt",
  "translatedText": "Saya ingin mengakhiri di sini dengan gagasan tentang eigenbasis, yang sangat bergantung pada gagasan dari video terakhir.",
  "time_range": [
   783.9,
   791.72
  ]
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "model": "nmt",
  "translatedText": "Lihatlah apa yang terjadi jika vektor basis kita kebetulan merupakan vektor eigen.",
  "time_range": [
   791.72,
   797.22
  ]
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1, and j-hat is scaled by 2.",
  "model": "nmt",
  "translatedText": "Misalnya, mungkin i-hat berskala negatif 1, dan j-hat berskala 2.",
  "time_range": [
   797.22,
   803.76
  ]
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "model": "nmt",
  "translatedText": "Menuliskan koordinat barunya sebagai kolom matriks, perhatikan bahwa kelipatan skalar tersebut, negatif 1 dan 2, yang merupakan nilai eigen dari i-hat dan j-hat, berada pada diagonal matriks kita, dan setiap entri lainnya adalah 0.",
  "time_range": [
   803.76,
   819.06
  ]
 },
 {
  "input": "Any time a matrix has 0s everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix, and the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "model": "nmt",
  "translatedText": "Setiap kali suatu matriks mempunyai angka 0 di mana pun selain diagonal, maka matriks tersebut disebut matriks diagonal, dan cara untuk menafsirkannya adalah bahwa semua vektor basis adalah vektor eigen, dengan entri diagonal dari matriks ini menjadi nilai eigennya.",
  "time_range": [
   819.06,
   837.38
  ]
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "model": "nmt",
  "translatedText": "Ada banyak hal yang membuat matriks diagonal lebih baik untuk dikerjakan.",
  "time_range": [
   837.38,
   842.06
  ]
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "model": "nmt",
  "translatedText": "Salah satu kelebihannya adalah lebih mudah menghitung apa yang akan terjadi jika Anda mengalikan matriks ini dengan matriks itu sendiri beberapa kali.",
  "time_range": [
   842.06,
   849.5
  ]
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "model": "nmt",
  "translatedText": "Karena yang dilakukan matriks ini hanyalah menskalakan setiap vektor basis dengan beberapa nilai eigen, menerapkan matriks tersebut berkali-kali, katakanlah 100 kali, hanya akan menyamakan penskalaan setiap vektor basis dengan pangkat 100 dari nilai eigen yang bersangkutan.",
  "time_range": [
   849.5,
   865.88
  ]
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "model": "nmt",
  "translatedText": "Sebaliknya, coba hitung pangkat 100 dari matriks non-diagonal.",
  "time_range": [
   865.88,
   869.94
  ]
 },
 {
  "input": "Really, try it for a moment.",
  "model": "nmt",
  "translatedText": "Sungguh, cobalah sejenak.",
  "time_range": [
   869.94,
   871.94
  ]
 },
 {
  "input": "It's a nightmare.",
  "model": "nmt",
  "translatedText": "Ini mimpi buruk.",
  "time_range": [
   871.94,
   876.5
  ]
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "model": "nmt",
  "translatedText": "Tentu saja, Anda jarang sekali beruntung karena vektor basis Anda juga merupakan vektor eigen.",
  "time_range": [
   876.5,
   882.22
  ]
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "model": "nmt",
  "translatedText": "Namun jika transformasi Anda memiliki banyak vektor eigen, seperti yang ada di awal video ini, sehingga Anda dapat memilih himpunan yang mencakup seluruh ruang, maka Anda dapat mengubah sistem koordinat sehingga vektor eigen tersebut menjadi vektor basis Anda.",
  "time_range": [
   882.22,
   896.94
  ]
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "model": "nmt",
  "translatedText": "Saya berbicara tentang perubahan basis di video terakhir, tapi saya akan membahas pengingat super cepat di sini tentang cara mengekspresikan transformasi yang saat ini ditulis dalam sistem koordinat kita ke dalam sistem yang berbeda.",
  "time_range": [
   896.94,
   908.54
  ]
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "model": "nmt",
  "translatedText": "Ambil koordinat vektor-vektor yang ingin dijadikan basis baru, yang dalam hal ini berarti dua vektor eigen kita, lalu jadikan koordinat tersebut sebagai kolom-kolom suatu matriks, yang disebut dengan matriks perubahan basis.",
  "time_range": [
   908.54,
   920.38
  ]
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "model": "nmt",
  "translatedText": "Ketika Anda mengapit transformasi asli, meletakkan matriks perubahan basis di sebelah kanannya dan kebalikan dari matriks perubahan basis di sebelah kirinya, hasilnya akan berupa matriks yang mewakili transformasi yang sama, tetapi dari perspektif koordinat vektor basis baru sistem.",
  "time_range": [
   920.38,
   937.64
  ]
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "model": "nmt",
  "translatedText": "Inti dari melakukan hal ini dengan vektor eigen adalah bahwa matriks baru ini dijamin berbentuk diagonal dengan nilai eigen yang sesuai di bawah diagonal tersebut.",
  "time_range": [
   937.64,
   947.3
  ]
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "model": "nmt",
  "translatedText": "Hal ini karena ini mewakili pekerjaan dalam sistem koordinat di mana apa yang terjadi pada vektor basis adalah vektor-vektor tersebut diskalakan selama transformasi.",
  "time_range": [
   947.3,
   955.74
  ]
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "model": "nmt",
  "translatedText": "Sekumpulan vektor basis yang juga merupakan vektor eigen disebut dengan basis eigen.",
  "time_range": [
   955.74,
   962.4
  ]
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "model": "nmt",
  "translatedText": "Jadi jika, misalnya, Anda perlu menghitung pangkat ke-100 dari matriks ini, akan lebih mudah untuk mengubahnya ke basis eigen, menghitung pangkat ke-100 dalam sistem tersebut, lalu mengonversinya kembali ke sistem standar kita.",
  "time_range": [
   962.4,
   976.76
  ]
 },
 {
  "input": "You can't do this with all transformations.",
  "model": "nmt",
  "translatedText": "Anda tidak dapat melakukan ini dengan semua transformasi.",
  "time_range": [
   976.76,
   978.46
  ]
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "model": "nmt",
  "translatedText": "Sebuah geser, misalnya, tidak memiliki vektor eigen yang cukup untuk menjangkau seluruh ruang.",
  "time_range": [
   978.46,
   983.8
  ]
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "model": "nmt",
  "translatedText": "Tetapi jika Anda dapat menemukan basis eigen, itu membuat operasi matriks menjadi sangat menyenangkan.",
  "time_range": [
   983.8,
   989.18
  ]
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "model": "nmt",
  "translatedText": "Bagi Anda yang ingin menyelesaikan teka-teki yang cukup rapi untuk melihat seperti apa aksinya dan bagaimana hal ini dapat digunakan untuk menghasilkan beberapa hasil yang mengejutkan, saya akan meninggalkan petunjuk di sini di layar.",
  "time_range": [
   989.18,
   997.96
  ]
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "model": "nmt",
  "translatedText": "Memang butuh sedikit usaha, tapi menurut saya Anda akan menikmatinya.",
  "time_range": [
   997.96,
   1000.96
  ]
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "model": "nmt",
  "translatedText": "Video berikutnya dan terakhir dari seri ini akan membahas tentang ruang vektor abstrak.",
  "time_range": [
   1000.96,
   1006.0
  ]
 },
 {
  "input": "See you then!",
  "model": "nmt",
  "translatedText": "Sampai jumpa lagi!",
  "time_range": [
   1006.0,
   1006.0
  ]
 }
]