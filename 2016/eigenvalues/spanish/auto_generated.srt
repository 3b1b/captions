1
00:00:19,920 --> 00:00:22,817
Los vectores propios y los valores propios es uno de esos temas 

2
00:00:22,817 --> 00:00:25,760
que muchos estudiantes encuentran particularmente poco intuitivo.

3
00:00:25,760 --> 00:00:29,135
Preguntas como por qué hacemos esto y qué significa realmente, 

4
00:00:29,135 --> 00:00:33,260
con demasiada frecuencia quedan flotando en un mar de cálculos sin respuesta.

5
00:00:33,920 --> 00:00:36,299
Y a medida que publiqué los videos de esta serie, 

6
00:00:36,299 --> 00:00:40,060
muchos de ustedes han comentado que esperan visualizar este tema en particular.

7
00:00:40,680 --> 00:00:43,330
Sospecho que la razón de esto no es tanto que las cosas 

8
00:00:43,330 --> 00:00:46,360
propias sean particularmente complicadas o estén mal explicadas.

9
00:00:46,860 --> 00:00:48,929
De hecho, es comparativamente sencillo y creo 

10
00:00:48,929 --> 00:00:51,180
que la mayoría de los libros lo explican muy bien.

11
00:00:51,520 --> 00:00:54,613
El problema es que sólo tiene sentido si tienes una 

12
00:00:54,613 --> 00:00:58,480
comprensión visual sólida de muchos de los temas que lo preceden.

13
00:00:59,060 --> 00:01:02,440
Lo más importante aquí es que sepas pensar en las matrices como 

14
00:01:02,440 --> 00:01:05,926
transformaciones lineales, pero también debes sentirte cómodo con 

15
00:01:05,926 --> 00:01:09,940
cosas como determinantes, sistemas lineales de ecuaciones y cambios de base.

16
00:01:10,720 --> 00:01:14,735
La confusión sobre las cosas propias suele tener más que ver con una base 

17
00:01:14,735 --> 00:01:19,240
inestable en uno de estos temas que con los vectores propios y los valores propios.

18
00:01:19,980 --> 00:01:23,492
Para empezar, considere alguna transformación lineal en dos dimensiones, 

19
00:01:23,492 --> 00:01:24,840
como la que se muestra aquí.

20
00:01:25,460 --> 00:01:31,040
Mueve el vector base i-hat a las coordenadas 3, 0 y j-hat a 1, 2.

21
00:01:31,780 --> 00:01:35,640
Entonces se representa con una matriz cuyas columnas son 3, 0 y 1, 2.

22
00:01:36,600 --> 00:01:40,352
Concéntrese en lo que le hace a un vector en particular y piense en 

23
00:01:40,352 --> 00:01:44,160
el alcance de ese vector, la línea que pasa por su origen y su punta.

24
00:01:44,920 --> 00:01:48,380
La mayoría de los vectores quedarán fuera de su alcance durante la transformación.

25
00:01:48,780 --> 00:01:51,998
Quiero decir, parecería bastante coincidente si el lugar donde 

26
00:01:51,998 --> 00:01:55,320
aterrizó el vector también estuviera en algún lugar de esa línea.

27
00:01:57,400 --> 00:02:00,664
Pero algunos vectores especiales permanecen en su propio lapso, 

28
00:02:00,664 --> 00:02:03,877
lo que significa que el efecto que tiene la matriz sobre dicho 

29
00:02:03,877 --> 00:02:07,040
vector es simplemente estirarlo o aplastarlo, como un escalar.

30
00:02:09,460 --> 00:02:14,100
Para este ejemplo específico, el vector base i-hat es uno de esos vectores especiales.

31
00:02:14,640 --> 00:02:19,574
El intervalo de i-hat es el eje x, y desde la primera columna de la matriz, 

32
00:02:19,574 --> 00:02:24,120
podemos ver que i-hat se mueve 3 veces él mismo, todavía en ese eje x.

33
00:02:26,320 --> 00:02:30,277
Es más, debido a la forma en que funcionan las transformaciones lineales, 

34
00:02:30,277 --> 00:02:34,180
cualquier otro vector en el eje x también se estira en un factor de 3 y, 

35
00:02:34,180 --> 00:02:36,480
por lo tanto, permanece en su propio tramo.

36
00:02:38,500 --> 00:02:41,399
Un vector un poco más astuto que permanece en su propio 

37
00:02:41,399 --> 00:02:44,040
lapso durante esta transformación es negativo 1, 1.

38
00:02:44,660 --> 00:02:47,140
Termina estirándose por un factor de 2.

39
00:02:49,000 --> 00:02:53,702
Y nuevamente, la linealidad implicará que cualquier otro vector en la línea 

40
00:02:53,702 --> 00:02:58,220
diagonal trazada por este tipo simplemente se estirará en un factor de 2.

41
00:02:59,820 --> 00:03:02,548
Y para esta transformación, esos son todos los vectores 

42
00:03:02,548 --> 00:03:05,180
con esta propiedad especial de permanecer en su tramo.

43
00:03:05,620 --> 00:03:08,774
Los que están en el eje x se estiran en un factor de 3 y los 

44
00:03:08,774 --> 00:03:11,980
que están en esta línea diagonal se estiran en un factor de 2.

45
00:03:12,760 --> 00:03:16,358
Cualquier otro vector será rotado un poco durante la transformación, 

46
00:03:16,358 --> 00:03:18,080
eliminado de la línea que abarca.

47
00:03:22,520 --> 00:03:27,378
Como ya habrás adivinado, estos vectores especiales se llaman vectores propios de la 

48
00:03:27,378 --> 00:03:32,236
transformación, y cada vector propio tiene asociado lo que se llama un valor propio, 

49
00:03:32,236 --> 00:03:37,380
que es simplemente el factor por el cual se estira o se aplasta durante la transformación.

50
00:03:40,280 --> 00:03:43,044
Por supuesto, no hay nada especial en estirar versus aplastar, 

51
00:03:43,044 --> 00:03:45,940
o en el hecho de que estos valores propios resulten ser positivos.

52
00:03:46,380 --> 00:03:50,859
En otro ejemplo, podría tener un vector propio con valor propio negativo 1 mitad, 

53
00:03:50,859 --> 00:03:55,120
lo que significa que el vector se voltea y se aplasta en un factor de 1 mitad.

54
00:03:56,980 --> 00:03:59,839
Pero la parte importante aquí es que permanece 

55
00:03:59,839 --> 00:04:02,760
en la línea que se extiende sin salirse de ella.

56
00:04:04,460 --> 00:04:07,790
Para tener una idea de por qué podría ser útil pensar en esto, 

57
00:04:07,790 --> 00:04:09,800
considere una rotación tridimensional.

58
00:04:11,660 --> 00:04:15,097
Si puedes encontrar un vector propio para esa rotación, 

59
00:04:15,097 --> 00:04:20,500
un vector que permanece en su propio lapso, lo que has encontrado es el eje de rotación.

60
00:04:22,600 --> 00:04:26,440
Y es mucho más fácil pensar en una rotación 3D en términos de 

61
00:04:26,440 --> 00:04:29,784
algún eje de rotación y un ángulo según el cual gira, 

62
00:04:29,784 --> 00:04:34,740
en lugar de pensar en la matriz completa de 3x3 asociada con esa transformación.

63
00:04:37,000 --> 00:04:40,590
En este caso, por cierto, el valor propio correspondiente tendría que ser 1, 

64
00:04:40,590 --> 00:04:43,108
ya que las rotaciones nunca estiran ni aplastan nada, 

65
00:04:43,108 --> 00:04:45,860
por lo que la longitud del vector seguiría siendo la misma.

66
00:04:48,080 --> 00:04:50,020
Este patrón aparece mucho en álgebra lineal.

67
00:04:50,440 --> 00:04:53,545
Con cualquier transformación lineal descrita por una matriz, 

68
00:04:53,545 --> 00:04:57,669
se puede entender lo que hace leyendo las columnas de esta matriz como puntos de 

69
00:04:57,669 --> 00:04:59,400
aterrizaje para los vectores base.

70
00:05:00,020 --> 00:05:03,586
Pero a menudo, una mejor manera de llegar al núcleo de lo que realmente 

71
00:05:03,586 --> 00:05:08,045
hace la transformación lineal, menos dependiente de su sistema de coordenadas particular, 

72
00:05:08,045 --> 00:05:10,820
es encontrar los vectores propios y los valores propios.

73
00:05:15,460 --> 00:05:18,777
No cubriré todos los detalles sobre los métodos para calcular vectores 

74
00:05:18,777 --> 00:05:22,188
propios y valores propios aquí, pero intentaré dar una visión general de 

75
00:05:22,188 --> 00:05:26,020
las ideas computacionales que son más importantes para una comprensión conceptual.

76
00:05:27,180 --> 00:05:30,480
Simbólicamente, así es como se ve la idea de un vector propio.

77
00:05:31,040 --> 00:05:34,264
A es la matriz que representa alguna transformación, 

78
00:05:34,264 --> 00:05:39,740
con v como vector propio y lambda es un número, es decir, el valor propio correspondiente.

79
00:05:40,680 --> 00:05:45,155
Lo que esta expresión dice es que el producto matriz-vector, A multiplicado por v, 

80
00:05:45,155 --> 00:05:49,900
da el mismo resultado que simplemente escalar el vector propio v por algún valor lambda.

81
00:05:51,000 --> 00:05:55,389
Entonces, encontrar los vectores propios y sus valores propios de una matriz A se 

82
00:05:55,389 --> 00:06:00,100
reduce a encontrar los valores de v y lambda que hacen que esta expresión sea verdadera.

83
00:06:01,920 --> 00:06:04,224
Es un poco incómodo trabajar con él al principio, 

84
00:06:04,224 --> 00:06:07,543
porque el lado izquierdo representa la multiplicación de matriz-vector, 

85
00:06:07,543 --> 00:06:10,540
pero el lado derecho aquí es la multiplicación de vector escalar.

86
00:06:11,120 --> 00:06:14,186
Entonces, comencemos reescribiendo ese lado derecho como una 

87
00:06:14,186 --> 00:06:17,352
especie de multiplicación matriz-vector, usando una matriz que 

88
00:06:17,352 --> 00:06:20,620
tiene el efecto de escalar cualquier vector por un factor lambda.

89
00:06:21,680 --> 00:06:26,198
Las columnas de dicha matriz representarán lo que sucede con cada vector base, 

90
00:06:26,198 --> 00:06:29,458
y cada vector base simplemente se multiplica por lambda, 

91
00:06:29,458 --> 00:06:34,320
por lo que esta matriz tendrá el número lambda en la diagonal, con ceros en el resto.

92
00:06:36,180 --> 00:06:40,466
La forma común de escribir este tipo es factorizar esa lambda y escribirla como 

93
00:06:40,466 --> 00:06:44,860
lambda multiplicada por i, donde i es la matriz de identidad con 1 en la diagonal.

94
00:06:45,860 --> 00:06:49,272
Como ambos lados parecen una multiplicación de matriz-vector, 

95
00:06:49,272 --> 00:06:51,860
podemos restar ese lado derecho y factorizar v.

96
00:06:54,160 --> 00:06:57,074
Entonces, lo que ahora tenemos es una nueva matriz, 

97
00:06:57,074 --> 00:07:00,716
A menos lambda multiplicada por la identidad, y estamos buscando 

98
00:07:00,716 --> 00:07:04,920
un vector v tal que esta nueva matriz multiplicada por v dé el vector cero.

99
00:07:06,380 --> 00:07:11,100
Ahora bien, esto siempre será cierto si v mismo es el vector cero, pero eso es aburrido.

100
00:07:11,340 --> 00:07:13,640
Lo que queremos es un vector propio distinto de cero.

101
00:07:14,420 --> 00:07:18,953
Y si miras los capítulos 5 y 6, sabrás que la única forma en que es posible que el 

102
00:07:18,953 --> 00:07:23,541
producto de una matriz con un vector distinto de cero se convierta en cero es si la 

103
00:07:23,541 --> 00:07:28,020
transformación asociada con esa matriz reduce el espacio a una dimensión inferior.

104
00:07:29,300 --> 00:07:34,220
Y esa compresión corresponde a un determinante cero para la matriz.

105
00:07:35,480 --> 00:07:40,533
Para ser concretos, digamos que su matriz A tiene las columnas 2, 1 y 2, 3, 

106
00:07:40,533 --> 00:07:45,520
y piense en restar una cantidad variable, lambda, de cada entrada diagonal.

107
00:07:46,480 --> 00:07:50,280
Ahora imagina ajustar lambda, girando una perilla para cambiar su valor.

108
00:07:50,940 --> 00:07:54,547
A medida que cambia ese valor de lambda, la matriz misma cambia y, 

109
00:07:54,547 --> 00:07:57,240
por lo tanto, cambia el determinante de la matriz.

110
00:07:58,220 --> 00:08:02,631
El objetivo aquí es encontrar un valor de lambda que haga que este determinante sea cero, 

111
00:08:02,631 --> 00:08:05,622
lo que significa que la transformación modificada aplasta el 

112
00:08:05,622 --> 00:08:07,240
espacio a una dimensión inferior.

113
00:08:08,160 --> 00:08:11,160
En este caso, el punto óptimo se produce cuando lambda es igual a 1.

114
00:08:12,180 --> 00:08:14,301
Por supuesto, si hubiéramos elegido otra matriz, 

115
00:08:14,301 --> 00:08:16,120
el valor propio no necesariamente sería 1.

116
00:08:16,240 --> 00:08:18,600
El punto óptimo podría alcanzarse con algún otro valor de lambda.

117
00:08:20,080 --> 00:08:22,960
Esto es mucho, pero analicemos lo que dice.

118
00:08:22,960 --> 00:08:26,001
Cuando lambda es igual a 1, la matriz A menos lambda 

119
00:08:26,001 --> 00:08:29,560
multiplicada por la identidad aplasta el espacio en una línea.

120
00:08:30,440 --> 00:08:34,527
Eso significa que hay un vector v distinto de cero tal que A menos lambda 

121
00:08:34,527 --> 00:08:38,559
multiplicado por la identidad multiplicado por v es igual al vector cero.

122
00:08:40,480 --> 00:08:45,996
Y recuerde, la razón por la que esto nos importa es porque significa que A multiplicado 

123
00:08:45,996 --> 00:08:51,262
por v es igual a lambda multiplicado por v, lo que se puede interpretar como que el 

124
00:08:51,262 --> 00:08:56,214
vector v es un vector propio de A, que permanece en su propio lapso durante la 

125
00:08:56,214 --> 00:08:57,280
transformación A.

126
00:08:58,320 --> 00:09:01,170
En este ejemplo, el valor propio correspondiente es 1, 

127
00:09:01,170 --> 00:09:04,020
por lo que v en realidad permanecería fijo en su lugar.

128
00:09:06,220 --> 00:09:07,909
Haga una pausa y reflexione si necesita asegurarse 

129
00:09:07,909 --> 00:09:09,500
de que esa línea de razonamiento se sienta bien.

130
00:09:13,380 --> 00:09:15,640
Este es el tipo de cosas que mencioné en la introducción.

131
00:09:16,220 --> 00:09:19,625
Si no tuvieras una comprensión sólida de los determinantes y de por qué se 

132
00:09:19,625 --> 00:09:23,621
relacionan con sistemas lineales de ecuaciones que tienen soluciones distintas de cero, 

133
00:09:23,621 --> 00:09:26,300
una expresión como esta parecería completamente inesperada.

134
00:09:28,320 --> 00:09:31,962
Para ver esto en acción, volvamos al ejemplo desde el principio, 

135
00:09:31,962 --> 00:09:34,540
con una matriz cuyas columnas son 3, 0 y 1, 2.

136
00:09:35,350 --> 00:09:38,942
Para encontrar si un valor lambda es un valor propio, 

137
00:09:38,942 --> 00:09:43,400
réstalo de las diagonales de esta matriz y calcula el determinante.

138
00:09:50,580 --> 00:09:54,750
Al hacer esto, obtenemos un determinado polinomio cuadrático en lambda, 

139
00:09:54,750 --> 00:09:56,720
3 menos lambda por 2 menos lambda.

140
00:09:57,800 --> 00:10:02,657
Dado que lambda solo puede ser un valor propio si este determinante es cero, 

141
00:10:02,657 --> 00:10:08,209
se puede concluir que los únicos valores propios posibles son lambda igual a 2 y lambda 

142
00:10:08,209 --> 00:10:08,840
igual a 3.

143
00:10:09,640 --> 00:10:14,278
Para descubrir cuáles son los vectores propios que realmente tienen uno de estos 

144
00:10:14,278 --> 00:10:17,142
valores propios, digamos que lambda es igual a 2, 

145
00:10:17,142 --> 00:10:21,838
conecte ese valor de lambda a la matriz y luego resuelva qué vectores esta matriz 

146
00:10:21,838 --> 00:10:23,900
alterada diagonalmente envía a cero.

147
00:10:24,940 --> 00:10:29,360
Si calculas esto de la misma manera que lo harías con cualquier otro sistema lineal, 

148
00:10:29,360 --> 00:10:34,040
verás que las soluciones son todos los vectores en la línea diagonal atravesada por menos 

149
00:10:34,040 --> 00:10:34,300
1, 1.

150
00:10:35,220 --> 00:10:39,370
Esto corresponde al hecho de que la matriz inalterada, 3, 0, 1, 2, 

151
00:10:39,370 --> 00:10:43,460
tiene el efecto de estirar todos esos vectores por un factor de 2.

152
00:10:46,320 --> 00:10:50,200
Ahora bien, una transformación 2D no tiene por qué tener vectores propios.

153
00:10:50,720 --> 00:10:53,400
Por ejemplo, considere una rotación de 90 grados.

154
00:10:53,660 --> 00:10:58,200
Esto no tiene vectores propios ya que rota cada vector fuera de su propio intervalo.

155
00:11:00,800 --> 00:11:04,512
Si realmente intentas calcular los valores propios de una rotación como esta, 

156
00:11:04,512 --> 00:11:05,560
observa lo que sucede.

157
00:11:06,300 --> 00:11:10,140
Su matriz tiene columnas 0, 1 y negativo 1, 0.

158
00:11:11,100 --> 00:11:15,800
Resta lambda de los elementos de la diagonal y busca cuándo el determinante es cero.

159
00:11:18,140 --> 00:11:21,940
En este caso, obtienes el polinomio lambda al cuadrado más 1.

160
00:11:22,680 --> 00:11:27,920
Las únicas raíces de ese polinomio son los números imaginarios, i y i negativo.

161
00:11:28,840 --> 00:11:33,600
El hecho de que no haya soluciones de números reales indica que no hay vectores propios.

162
00:11:35,540 --> 00:11:39,820
Otro ejemplo bastante interesante que vale la pena tener en cuenta es una cizalla.

163
00:11:40,560 --> 00:11:47,164
Esto fija i-hat en su lugar y mueve j-hat 1, por lo que su matriz tiene las columnas 1, 

164
00:11:47,164 --> 00:11:47,840
0 y 1, 1.

165
00:11:48,740 --> 00:11:51,558
Todos los vectores en el eje x son vectores propios 

166
00:11:51,558 --> 00:11:54,540
con valor propio 1 ya que permanecen fijos en su lugar.

167
00:11:55,680 --> 00:11:57,820
De hecho, estos son los únicos vectores propios.

168
00:11:58,760 --> 00:12:03,372
Cuando restas lambda de las diagonales y calculas el determinante, 

169
00:12:03,372 --> 00:12:06,540
lo que obtienes es 1 menos lambda al cuadrado.

170
00:12:09,320 --> 00:12:12,860
Y la única raíz de esta expresión es lambda igual a 1.

171
00:12:14,560 --> 00:12:17,038
Esto se alinea con lo que vemos geométricamente, 

172
00:12:17,038 --> 00:12:19,720
que todos los vectores propios tienen valor propio 1.

173
00:12:21,080 --> 00:12:25,045
Sin embargo, tenga en cuenta que también es posible tener un solo valor propio, 

174
00:12:25,045 --> 00:12:28,020
pero con más que una simple línea llena de vectores propios.

175
00:12:29,900 --> 00:12:33,180
Un ejemplo sencillo es una matriz que escala todo en 2.

176
00:12:33,900 --> 00:12:37,141
El único valor propio es 2, pero cada vector en el 

177
00:12:37,141 --> 00:12:40,700
plano llega a ser un vector propio con ese valor propio.

178
00:12:42,000 --> 00:12:44,234
Ahora es otro buen momento para hacer una pausa y 

179
00:12:44,234 --> 00:12:46,960
reflexionar sobre algo de esto antes de pasar al último tema.

180
00:13:03,540 --> 00:13:06,594
Quiero terminar aquí con la idea de una base propia, 

181
00:13:06,594 --> 00:13:09,880
que se basa en gran medida en las ideas del último vídeo.

182
00:13:11,480 --> 00:13:16,380
Eche un vistazo a lo que sucede si nuestros vectores base resultan ser vectores propios.

183
00:13:17,120 --> 00:13:22,380
Por ejemplo, tal vez i-hat esté escalado por 1 negativo y j-hat esté escalado por 2.

184
00:13:23,420 --> 00:13:27,192
Al escribir sus nuevas coordenadas como las columnas de una matriz, 

185
00:13:27,192 --> 00:13:30,244
observe que esos múltiplos escalares, negativos 1 y 2, 

186
00:13:30,244 --> 00:13:35,238
que son los valores propios de i-hat y j-hat, se ubican en la diagonal de nuestra matriz, 

187
00:13:35,238 --> 00:13:37,180
y todas las demás entradas son 0. .

188
00:13:38,880 --> 00:13:43,092
Cada vez que una matriz tiene ceros en todas partes excepto en la diagonal, 

189
00:13:43,092 --> 00:13:45,420
se llama, razonablemente, matriz diagonal.

190
00:13:45,840 --> 00:13:50,633
Y la forma de interpretar esto es que todos los vectores base son vectores propios, 

191
00:13:50,633 --> 00:13:54,400
siendo las entradas diagonales de esta matriz sus valores propios.

192
00:13:57,100 --> 00:14:01,060
Hay muchas cosas que hacen que sea mucho más agradable trabajar con matrices diagonales.

193
00:14:01,780 --> 00:14:05,086
Uno de los más importantes es que es más fácil calcular lo que 

194
00:14:05,086 --> 00:14:08,340
sucederá si multiplicas esta matriz por sí misma muchas veces.

195
00:14:09,420 --> 00:14:14,322
Dado que lo único que hace una de estas matrices es escalar cada vector base según 

196
00:14:14,322 --> 00:14:18,575
algún valor propio, aplicar esa matriz muchas veces, digamos 100 veces, 

197
00:14:18,575 --> 00:14:23,654
corresponderá a escalar cada vector base según la centésima potencia del valor propio 

198
00:14:23,654 --> 00:14:24,600
correspondiente.

199
00:14:25,700 --> 00:14:29,680
Por el contrario, intente calcular la potencia número 100 de una matriz no diagonal.

200
00:14:29,680 --> 00:14:31,320
De verdad, pruébalo por un momento.

201
00:14:31,740 --> 00:14:32,440
Es una pesadilla.

202
00:14:36,080 --> 00:14:38,718
Por supuesto, rara vez tendrás tanta suerte como para 

203
00:14:38,718 --> 00:14:41,260
que tus vectores base también sean vectores propios.

204
00:14:42,040 --> 00:14:45,067
Pero si tu transformación tiene muchos vectores propios, 

205
00:14:45,067 --> 00:14:48,732
como el del inicio de este vídeo, suficientes para que puedas elegir 

206
00:14:48,732 --> 00:14:52,397
un conjunto que abarque todo el espacio, entonces podrías cambiar tu 

207
00:14:52,397 --> 00:14:56,540
sistema de coordenadas para que estos vectores propios sean tus vectores base.

208
00:14:57,140 --> 00:14:59,519
Hablé sobre el cambio de base en el último video, 

209
00:14:59,519 --> 00:15:02,613
pero aquí haré un recordatorio súper rápido de cómo expresar una 

210
00:15:02,613 --> 00:15:05,897
transformación actualmente escrita en nuestro sistema de coordenadas 

211
00:15:05,897 --> 00:15:07,040
en un sistema diferente.

212
00:15:08,440 --> 00:15:11,871
Tome las coordenadas de los vectores que desea usar como una nueva base, 

213
00:15:11,871 --> 00:15:14,598
que en este caso significa nuestros dos vectores propios, 

214
00:15:14,598 --> 00:15:17,606
luego convierta esas coordenadas en las columnas de una matriz, 

215
00:15:17,606 --> 00:15:19,440
conocida como matriz de cambio de base.

216
00:15:20,180 --> 00:15:24,273
Cuando intercala la transformación original, poniendo la matriz de cambio de 

217
00:15:24,273 --> 00:15:28,419
base a su derecha y la inversa de la matriz de cambio de base a su izquierda, 

218
00:15:28,419 --> 00:15:32,140
el resultado será una matriz que representa esa misma transformación, 

219
00:15:32,140 --> 00:15:36,500
pero desde la perspectiva de las nuevas coordenadas de los vectores base. sistema.

220
00:15:37,440 --> 00:15:42,175
El objetivo de hacer esto con vectores propios es que se garantiza que esta nueva 

221
00:15:42,175 --> 00:15:46,680
matriz será diagonal con sus valores propios correspondientes en esa diagonal.

222
00:15:46,860 --> 00:15:50,590
Esto se debe a que representa trabajar en un sistema de coordenadas donde lo 

223
00:15:50,590 --> 00:15:54,320
que sucede con los vectores base es que se escalan durante la transformación.

224
00:15:55,800 --> 00:15:59,556
Un conjunto de vectores base que también son vectores propios se denomina, 

225
00:15:59,556 --> 00:16:01,560
nuevamente, razonablemente, base propia.

226
00:16:02,340 --> 00:16:07,201
Entonces, si, por ejemplo, necesitara calcular la potencia número 100 de esta matriz, 

227
00:16:07,201 --> 00:16:09,970
sería mucho más fácil cambiar a una base propia, 

228
00:16:09,970 --> 00:16:14,266
calcular la potencia número 100 en ese sistema y luego volver a convertir a 

229
00:16:14,266 --> 00:16:15,680
nuestro sistema estándar.

230
00:16:16,620 --> 00:16:18,320
No puedes hacer esto con todas las transformaciones.

231
00:16:18,320 --> 00:16:22,980
Un corte, por ejemplo, no tiene suficientes vectores propios para abarcar todo el espacio.

232
00:16:23,460 --> 00:16:25,784
Pero si puedes encontrar una base propia, las 

233
00:16:25,784 --> 00:16:28,160
operaciones matriciales son realmente hermosas.

234
00:16:29,120 --> 00:16:31,804
Para aquellos de ustedes que estén dispuestos a resolver un rompecabezas 

235
00:16:31,804 --> 00:16:34,451
bastante interesante para ver cómo se ve en acción y cómo se puede usar 

236
00:16:34,451 --> 00:16:37,320
para producir resultados sorprendentes, dejaré un mensaje aquí en la pantalla.

237
00:16:37,600 --> 00:16:40,280
Requiere un poco de trabajo, pero creo que lo disfrutarás.

238
00:16:40,840 --> 00:16:46,120
El siguiente y último vídeo de esta serie tratará sobre espacios vectoriales abstractos.

