[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "translatedText": "Los vectores propios y los valores propios es uno de esos temas que muchos estudiantes encuentran particularmente poco intuitivo.",
  "from_community_srt": "Los vectores propios y los valores propios son de aquellos conceptos que muchos estudiantes encuentran particularmente poco intuitivos",
  "n_reviews": 0,
  "start": 19.92,
  "end": 25.76
 },
 {
  "input": "Questions like, why are we doing this and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "translatedText": "Preguntas como por qué hacemos esto y qué significa realmente, con demasiada frecuencia quedan flotando en un mar de cálculos sin respuesta.",
  "from_community_srt": "Preguntas como: \"Por qué estamos haciendo esto?\" y \"Qué quiere decir ésto realmente?\" son frecuentemente dejadas al flote",
  "n_reviews": 0,
  "start": 25.76,
  "end": 33.26
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "translatedText": "Y a medida que publiqué los videos de esta serie, muchos de ustedes han comentado que esperan visualizar este tema en particular.",
  "from_community_srt": "en un mar de cálculos sin respuestas Y a medida que publico los videos de esta serie muchos de vosotros habéis expresado vuestro interés en poder visualizar este tema en concreto",
  "n_reviews": 0,
  "start": 33.92,
  "end": 40.06
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "translatedText": "Sospecho que la razón de esto no es tanto que las cosas propias sean particularmente complicadas o estén mal explicadas.",
  "from_community_srt": "Sospecho que la razón para esto no es tanto por el hecho de que el mundo de las cosas \"propias\" sea particularmente complicado o pobremente explicado",
  "n_reviews": 0,
  "start": 40.68,
  "end": 46.36
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "translatedText": "De hecho, es comparativamente sencillo y creo que la mayoría de los libros lo explican muy bien.",
  "from_community_srt": "De hecho, es bastante sencillo en comparación con otros conceptos y creo que la mayoría de los libros hacen un buen trabajo explicándolo",
  "n_reviews": 0,
  "start": 46.86,
  "end": 51.18
 },
 {
  "input": "The issue is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "translatedText": "El problema es que sólo tiene sentido si tienes una comprensión visual sólida de muchos de los temas que lo preceden.",
  "from_community_srt": "El problema es que solo tiene de veras sentido si tienes una sólida concepción visual de muchos de los otros conceptos que lo preceden",
  "n_reviews": 0,
  "start": 51.52,
  "end": 58.48
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "translatedText": "Lo más importante aquí es que sepas pensar en las matrices como transformaciones lineales, pero también debes sentirte cómodo con cosas como determinantes, sistemas lineales de ecuaciones y cambios de base.",
  "from_community_srt": "En este caso, lo más importante es que sepas como pensar en matrices como aplicaciones lineales pero también tienes que sentirte cómodo con cosas como determinantes, sistemas lineales de ecuaciones,",
  "n_reviews": 0,
  "start": 59.06,
  "end": 69.94
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "translatedText": "La confusión sobre las cosas propias suele tener más que ver con una base inestable en uno de estos temas que con los vectores propios y los valores propios.",
  "from_community_srt": "y cambios de base Confusión con cosas \"propias\" normalmente tiene más que ver con una concepción débil en alguno de estos temas que con los vectores y valores propios en sí Para empezar,",
  "n_reviews": 0,
  "start": 70.72,
  "end": 79.24
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "translatedText": "Para empezar, considere alguna transformación lineal en dos dimensiones, como la que se muestra aquí.",
  "n_reviews": 0,
  "start": 79.98,
  "end": 84.84
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "translatedText": "Mueve el vector base i-hat a las coordenadas 3, 0 y j-hat a 1, 2.",
  "from_community_srt": "considera una aplicación lineal en dos dimensiones como la mostrada aquí Mueve el vector unitario i de la base a las coordenadas [3,0] y el vector j a [1,2]",
  "n_reviews": 0,
  "start": 85.46,
  "end": 91.04
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "translatedText": "Entonces se representa con una matriz cuyas columnas son 3, 0 y 1, 2.",
  "from_community_srt": "de manera que queda representado con una matriz cuyas columnas son [3,0] y [1,2] Céntrate en lo que la aplicación le hace a un vector en particular",
  "n_reviews": 0,
  "start": 91.78,
  "end": 95.64
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "translatedText": "Concéntrese en lo que le hace a un vector en particular y piense en el alcance de ese vector, la línea que pasa por su origen y su punta.",
  "from_community_srt": "y piensa en el sistema generador de ese vector; la línea pasando a través de su origen y su punta",
  "n_reviews": 0,
  "start": 96.6,
  "end": 104.16
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "translatedText": "La mayoría de los vectores quedarán fuera de su alcance durante la transformación.",
  "from_community_srt": "La mayoría de los vectores van a verse desplazados respecto su sistema generador durante la transformación",
  "n_reviews": 0,
  "start": 104.92,
  "end": 108.38
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "translatedText": "Quiero decir, parecería bastante coincidente si el lugar donde aterrizó el vector también estuviera en algún lugar de esa línea.",
  "from_community_srt": "Quiero decir, sería toda una coincidencia si el lugar en donde el vector fuera a parar también resultara ser algún sitio en esa misma línea",
  "n_reviews": 0,
  "start": 108.78,
  "end": 115.32
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "translatedText": "Pero algunos vectores especiales permanecen en su propio lapso, lo que significa que el efecto que tiene la matriz sobre dicho vector es simplemente estirarlo o aplastarlo, como un escalar.",
  "from_community_srt": "Pero algunos vectores especiales sí que se mantienen en su propio sistema generador Queriendo decir que el efecto que la matriz asociada a la aplicación lineal  tiene sobre tal vector",
  "n_reviews": 0,
  "start": 117.4,
  "end": 127.04
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "translatedText": "Para este ejemplo específico, el vector base i-hat es uno de esos vectores especiales.",
  "from_community_srt": "es simplemente el de alargarlo o encogerlo como un escalar Para este ejemplo en concreto, El vector de la base i es un vector así de especial",
  "n_reviews": 0,
  "start": 129.46,
  "end": 134.1
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "translatedText": "El intervalo de i-hat es el eje x, y desde la primera columna de la matriz, podemos ver que i-hat se mueve 3 veces él mismo, todavía en ese eje x.",
  "from_community_srt": "El sistema generador del vector i es el eje x y a partir de la primera columna de la matriz podemos ver que i se mueve 3 veces sí mismo hacia la derecha, todavía en ese eje x.",
  "n_reviews": 0,
  "start": 134.64,
  "end": 144.12
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "translatedText": "Es más, debido a la forma en que funcionan las transformaciones lineales, cualquier otro vector en el eje x también se estira en un factor de 3 y, por lo tanto, permanece en su propio tramo.",
  "from_community_srt": "Es más, debido a cómo las aplicaciones lineales funcionan cualquier otro vector en el eje x también es alargado o encogido por un factor de 3 y, por consiguiente,",
  "n_reviews": 0,
  "start": 146.32,
  "end": 156.48
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "translatedText": "Un vector un poco más astuto que permanece en su propio lapso durante esta transformación es negativo 1, 1.",
  "from_community_srt": "permanece en su propio sistema generador Un vector algo escondido que también permanece sobre su propio sistema generador a lo largo de esta transformación",
  "n_reviews": 0,
  "start": 158.5,
  "end": 164.04
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "translatedText": "Termina estirándose por un factor de 2.",
  "from_community_srt": "es el [-1,1] el cuál acaba siendo alargado por un factor de 2 Y una vez más,",
  "n_reviews": 0,
  "start": 164.66,
  "end": 167.14
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "translatedText": "Y nuevamente, la linealidad implicará que cualquier otro vector en la línea diagonal trazada por este tipo simplemente se estirará en un factor de 2.",
  "from_community_srt": "la linealidad de la aplicación va a implicar que cualquier otro vector en la línea diagonal que genera este vector",
  "n_reviews": 0,
  "start": 169.0,
  "end": 178.22
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "translatedText": "Y para esta transformación, esos son todos los vectores con esta propiedad especial de permanecer en su tramo.",
  "from_community_srt": "va también a ser alargado por un factor de 2 Y para esta aplicación lineal esos son todos los vectores con esta propiedad especial de mantenerse en su generador",
  "n_reviews": 0,
  "start": 179.82,
  "end": 185.18
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "translatedText": "Los que están en el eje x se estiran en un factor de 3 y los que están en esta línea diagonal se estiran en un factor de 2.",
  "from_community_srt": "Aquellos que en el eje x son encogidos por un factor 3 y aquellos sobre esta linea diagonal que son encogidos por un factor 2",
  "n_reviews": 0,
  "start": 185.62,
  "end": 191.98
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "translatedText": "Cualquier otro vector será rotado un poco durante la transformación, eliminado de la línea que abarca.",
  "from_community_srt": "Cualquier otro vector va a ser rotado aunque sea un poco durante la transformación; desplazado de la linea que genera.",
  "n_reviews": 0,
  "start": 192.76,
  "end": 198.08
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "translatedText": "Como ya habrás adivinado, estos vectores especiales se llaman vectores propios de la transformación, y cada vector propio tiene asociado lo que se llama un valor propio, que es simplemente el factor por el cual se estira o se aplasta durante la transformación.",
  "from_community_srt": "Como ya habrás adivinado probablemente a estos vectores especiales se les llama \"vectores propios\" de la aplicación y cada vector propio tiene asociado con él lo que se llama un \"valor propio\" que no es más que el factor por el cuál el vector es alargado o encogido durante la transformación",
  "n_reviews": 0,
  "start": 202.52,
  "end": 217.38
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing, or the fact that these eigenvalues happen to be positive.",
  "translatedText": "Por supuesto, no hay nada especial en estirar versus aplastar, o en el hecho de que estos valores propios resulten ser positivos.",
  "from_community_srt": "Por supuesto, no hay nada especial en que se alarguen o en que se encojan o en el hecho de que estos valores propios resulten haber sido positivos",
  "n_reviews": 0,
  "start": 220.28,
  "end": 225.94
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "translatedText": "En otro ejemplo, podría tener un vector propio con valor propio negativo 1 mitad, lo que significa que el vector se voltea y se aplasta en un factor de 1 mitad.",
  "from_community_srt": "En otro ejemplo, podrías tener un vector propio con un valor propio -1/2 queriendo decir que el vector  es volteado y encogido por un factor de 1/2",
  "n_reviews": 0,
  "start": 226.38,
  "end": 235.12
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "translatedText": "Pero la parte importante aquí es que permanece en la línea que se extiende sin salirse de ella.",
  "from_community_srt": "Pero la parte importante aquí es que se queda en la linea que genera sin ser desplazado fuera de ella",
  "n_reviews": 0,
  "start": 236.98,
  "end": 242.76
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "translatedText": "Para tener una idea de por qué podría ser útil pensar en esto, considere una rotación tridimensional.",
  "from_community_srt": "Para que puedas ver por qué esto podría ser algo útil a tener en cuenta Considera una rotación en tres dimensiones",
  "n_reviews": 0,
  "start": 244.46,
  "end": 249.8
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "translatedText": "Si puedes encontrar un vector propio para esa rotación, un vector que permanece en su propio lapso, lo que has encontrado es el eje de rotación.",
  "from_community_srt": "Si tú puedes encontrar un vector propio para esa rotación un vector que se mantiene en su sistema generador",
  "n_reviews": 0,
  "start": 251.66,
  "end": 260.5
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3x3 matrix associated with that transformation.",
  "translatedText": "Y es mucho más fácil pensar en una rotación 3D en términos de algún eje de rotación y un ángulo según el cual gira, en lugar de pensar en la matriz completa de 3x3 asociada con esa transformación.",
  "from_community_srt": "lo que has encontrado es el eje de rotación Y es mucho más facil pensar en una rotación 3D desde el punto de vista de un eje de rotación y un ángulo bajo el cuál está rotando que tener que pensar en la matriz 3x3 entera asociada a esa aplicación lineal",
  "n_reviews": 0,
  "start": 262.6,
  "end": 274.74
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "translatedText": "En este caso, por cierto, el valor propio correspondiente tendría que ser 1, ya que las rotaciones nunca estiran ni aplastan nada, por lo que la longitud del vector seguiría siendo la misma.",
  "from_community_srt": "En este caso, por cierto El valor propio correspondiente tendría que ser 1 ya que las rotaciones nunca alargan ni encogen nada",
  "n_reviews": 0,
  "start": 277.0,
  "end": 285.86
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "translatedText": "Este patrón aparece mucho en álgebra lineal.",
  "from_community_srt": "de manera que la longitud del vector siempre permanecería igual Este patrón aparece con mucha frecuencia en álgebra lineal",
  "n_reviews": 0,
  "start": 288.08,
  "end": 290.02
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "translatedText": "Con cualquier transformación lineal descrita por una matriz, se puede entender lo que hace leyendo las columnas de esta matriz como puntos de aterrizaje para los vectores base.",
  "from_community_srt": "Con cualquier aplicación lineal descrita por una matriz tú podrías entender lo que está haciendo leyendo las columnas de esa matriz como los sitios en los que los vectores de la base aterrizan",
  "n_reviews": 0,
  "start": 290.44,
  "end": 299.4
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "translatedText": "Pero a menudo, una mejor manera de llegar al núcleo de lo que realmente hace la transformación lineal, menos dependiente de su sistema de coordenadas particular, es encontrar los vectores propios y los valores propios.",
  "from_community_srt": "Pero a menudo, una mejor manera de llegar al corazón de lo que las aplicaciones lineales de verdad hacen —sin tener que depender de tus sistema de coordenadas en particular— es encontrar los vectores propios y los valores propios.",
  "n_reviews": 0,
  "start": 300.02,
  "end": 310.82
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "translatedText": "No cubriré todos los detalles sobre los métodos para calcular vectores propios y valores propios aquí, pero intentaré dar una visión general de las ideas computacionales que son más importantes para una comprensión conceptual.",
  "from_community_srt": "No cubriré en lujo de detalles los métodos para calcular vectores propios y valores propios en este video Pero intentaré dar un resumen de las ideas referidas a su cálculo que son más importantes para un entendimiento conceptual",
  "n_reviews": 0,
  "start": 315.46,
  "end": 326.02
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "translatedText": "Simbólicamente, así es como se ve la idea de un vector propio.",
  "from_community_srt": "Simbólicamente hablando,",
  "n_reviews": 0,
  "start": 327.18,
  "end": 330.48
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "translatedText": "A es la matriz que representa alguna transformación, con v como vector propio y lambda es un número, es decir, el valor propio correspondiente.",
  "from_community_srt": "así es como se ve la idea de un vector propio A es la matriz que representa una aplicación lineal con v como el vector propio y , λ, es un número, conocido como el valor propio asociado a este vector propio Lo que está diciendo esta expresión",
  "n_reviews": 0,
  "start": 331.04,
  "end": 339.74
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "translatedText": "Lo que esta expresión dice es que el producto matriz-vector, A multiplicado por v, da el mismo resultado que simplemente escalar el vector propio v por algún valor lambda.",
  "from_community_srt": "es que el producto entre la matriz y el vector,",
  "n_reviews": 0,
  "start": 340.68,
  "end": 349.9
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "translatedText": "Entonces, encontrar los vectores propios y sus valores propios de una matriz A se reduce a encontrar los valores de v y lambda que hacen que esta expresión sea verdadera.",
  "from_community_srt": "Av da el mismo resultado que simplemente escalando el vector propio v por algún valor λ Así que encontrar los vectores propios y sus respectivos valores propios de la matriz A se reduce a encontrar los valores de v y λ que hacen esta expresión verdadera.",
  "n_reviews": 0,
  "start": 351.0,
  "end": 360.1
 },
 {
  "input": "It's a little awkward to work with at first, because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "translatedText": "Es un poco incómodo trabajar con él al principio, porque el lado izquierdo representa la multiplicación de matriz-vector, pero el lado derecho aquí es la multiplicación de vector escalar.",
  "from_community_srt": "Es un poco incómodo trabajar con esto al principio porque el término de la izquierda representa un producto entre una matriz y un vector mientras que en el lado derecho aparece el producto de un escalar por un vector Así que vamos a comenzar reescribiendo el lado derecho",
  "n_reviews": 0,
  "start": 361.92,
  "end": 370.54
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "translatedText": "Entonces, comencemos reescribiendo ese lado derecho como una especie de multiplicación matriz-vector, usando una matriz que tiene el efecto de escalar cualquier vector por un factor lambda.",
  "from_community_srt": "como si se tratara de un producto entre una matriz y un vector usando una matriz que tiene el efecto de escalar cualquier vector por un factor λ",
  "n_reviews": 0,
  "start": 371.12,
  "end": 380.62
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "translatedText": "Las columnas de dicha matriz representarán lo que sucede con cada vector base, y cada vector base simplemente se multiplica por lambda, por lo que esta matriz tendrá el número lambda en la diagonal, con ceros en el resto.",
  "from_community_srt": "Las columnas de dicha matriz representarán lo que le ocurre a cada vector de la base y cada vector de la base es simplemente multiplicado por λ así que esta matriz tendrá el numero λ en su diagonal,",
  "n_reviews": 0,
  "start": 381.68,
  "end": 394.32
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with 1s down the diagonal.",
  "translatedText": "La forma común de escribir este tipo es factorizar esa lambda y escribirla como lambda multiplicada por i, donde i es la matriz de identidad con 1 en la diagonal.",
  "from_community_srt": "con 0s en el resto de posiciones La manera común de escribir esto es sacando factor común esa λ y escribirlo como λI",
  "n_reviews": 0,
  "start": 396.18,
  "end": 404.86
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "translatedText": "Como ambos lados parecen una multiplicación de matriz-vector, podemos restar ese lado derecho y factorizar v.",
  "from_community_srt": "donde I es la matriz identidad con 1s en la diagonal Ahora que ambos lados representan el producto de una matriz por un vector",
  "n_reviews": 0,
  "start": 405.86,
  "end": 411.86
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix times v gives the zero vector.",
  "translatedText": "Entonces, lo que ahora tenemos es una nueva matriz, A menos lambda multiplicada por la identidad, y estamos buscando un vector v tal que esta nueva matriz multiplicada por v dé el vector cero.",
  "from_community_srt": "podemos restar el término de la derecha en ambos lados y factorizar la v Y los que nos queda ahora es la nueva matriz A-λI Y estamos buscando un vector v tal que esta nueva matriz multiplicada por v nos dé el vector 0",
  "n_reviews": 0,
  "start": 414.16,
  "end": 424.92
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "translatedText": "Ahora bien, esto siempre será cierto si v mismo es el vector cero, pero eso es aburrido.",
  "from_community_srt": "Ahora bien, esto siempre sera cierto si el vector v  en sí es el vector 0.",
  "n_reviews": 0,
  "start": 426.38,
  "end": 431.1
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "translatedText": "Lo que queremos es un vector propio distinto de cero.",
  "from_community_srt": "Pero eso es aburrido Lo que queremos es un vector propio que no sea el 0 Y si miraste los capítulos 5 y 6",
  "n_reviews": 0,
  "start": 431.34,
  "end": 433.64
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "translatedText": "Y si miras los capítulos 5 y 6, sabrás que la única forma en que es posible que el producto de una matriz con un vector distinto de cero se convierta en cero es si la transformación asociada con esa matriz reduce el espacio a una dimensión inferior.",
  "from_community_srt": "sabrás que la única forma de que el producto de una matriz por un vector dé 0 es si la aplicación asociada con esa matriz encoge el espacio a una dimensión menor",
  "n_reviews": 0,
  "start": 434.42,
  "end": 448.02
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "translatedText": "Y esa compresión corresponde a un determinante cero para la matriz.",
  "from_community_srt": "y ese encogimiento se corresponde con un determinante que dé 0 para esa matriz Para poner un ejemplo,",
  "n_reviews": 0,
  "start": 449.3,
  "end": 454.22
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "translatedText": "Para ser concretos, digamos que su matriz A tiene las columnas 2, 1 y 2, 3, y piense en restar una cantidad variable, lambda, de cada entrada diagonal.",
  "from_community_srt": "digamos que tu matriz A tiene las columnas [2, 1] y [2, 3] y  piensa en restarle una cantidad λ variable a cada elemento de la diagonal Ahora imagina que modificamos λ",
  "n_reviews": 0,
  "start": 455.48,
  "end": 465.52
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "translatedText": "Ahora imagina ajustar lambda, girando una perilla para cambiar su valor.",
  "n_reviews": 0,
  "start": 466.48,
  "end": 470.28
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "translatedText": "A medida que cambia ese valor de lambda, la matriz misma cambia y, por lo tanto, cambia el determinante de la matriz.",
  "from_community_srt": "girando de una rueda para cambiar su valor a medida que el valor de λ cambia, la matriz también lo hace y por tanto el determinante de la matriz cambia El objetivo aquí es encontrar un valor de λ",
  "n_reviews": 0,
  "start": 470.94,
  "end": 477.24
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "translatedText": "El objetivo aquí es encontrar un valor de lambda que haga que este determinante sea cero, lo que significa que la transformación modificada aplasta el espacio a una dimensión inferior.",
  "from_community_srt": "que hará este determinante 0 lo cual significa que la aplicación modificada encoge el espacio a una dimensión menor",
  "n_reviews": 0,
  "start": 478.22,
  "end": 487.24
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "translatedText": "En este caso, el punto óptimo se produce cuando lambda es igual a 1.",
  "from_community_srt": "En este caso, el lugar indicado llega cuando λ=1.",
  "n_reviews": 0,
  "start": 488.16,
  "end": 491.16
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "translatedText": "Por supuesto, si hubiéramos elegido otra matriz, el valor propio no necesariamente sería 1.",
  "from_community_srt": "Por supuesto, si hemos escogido alguna otra matriz distinta el valor propio no necesariamente tendría que ser 1.",
  "n_reviews": 0,
  "start": 492.18,
  "end": 496.12
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "translatedText": "El punto óptimo podría alcanzarse con algún otro valor de lambda.",
  "from_community_srt": "El punto que buscamos podría estar para otro valor de λ Bueno,",
  "n_reviews": 0,
  "start": 496.24,
  "end": 498.6
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "translatedText": "Esto es mucho, pero analicemos lo que dice.",
  "from_community_srt": "esto es ya bastante Pero vamos a tratar de desvelar lo que esto está diciendo.",
  "n_reviews": 0,
  "start": 500.08,
  "end": 502.96
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "translatedText": "Cuando lambda es igual a 1, la matriz A menos lambda multiplicada por la identidad aplasta el espacio en una línea.",
  "from_community_srt": "Cuando λ=1, la matriz A-λI encoge el espacio en una línea.",
  "n_reviews": 0,
  "start": 502.96,
  "end": 509.56
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "translatedText": "Eso significa que hay un vector v distinto de cero tal que A menos lambda multiplicado por la identidad multiplicado por v es igual al vector cero.",
  "from_community_srt": "Esto significa que hay un vector distinto de 0 tal que (A-λI)v  es igual al vector 0.",
  "n_reviews": 0,
  "start": 510.44,
  "end": 518.56
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "translatedText": "Y recuerde, la razón por la que esto nos importa es porque significa que A multiplicado por v es igual a lambda multiplicado por v, lo que se puede interpretar como que el vector v es un vector propio de A, que permanece en su propio lapso durante la transformación A.",
  "from_community_srt": "Y recuerda, el motivo por el cuál nos importa todo esto es porque significa que Av=λv lo cuál puedes leer como si dijera que el vector v es un vector propio de A al quedarse en su propio generador durante la transformación A.",
  "n_reviews": 0,
  "start": 520.48,
  "end": 537.28
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "translatedText": "En este ejemplo, el valor propio correspondiente es 1, por lo que v en realidad permanecería fijo en su lugar.",
  "from_community_srt": "En este ejemplo, el valor propio correspondiente es 1. Así que v quedaría simplemente fijada en su lugar.",
  "n_reviews": 0,
  "start": 538.32,
  "end": 544.02
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "translatedText": "Haga una pausa y reflexione si necesita asegurarse de que esa línea de razonamiento se sienta bien.",
  "n_reviews": 0,
  "start": 546.22,
  "end": 549.5
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "translatedText": "Este es el tipo de cosas que mencioné en la introducción.",
  "from_community_srt": "Pausa y reflexiona si necesitas asegurarte que esta línea de razonamiento te cuadra Este es el tipo de problema que mencioné en la introducción",
  "n_reviews": 0,
  "start": 553.38,
  "end": 555.64
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "translatedText": "Si no tuvieras una comprensión sólida de los determinantes y de por qué se relacionan con sistemas lineales de ecuaciones que tienen soluciones distintas de cero, una expresión como esta parecería completamente inesperada.",
  "from_community_srt": "Si no tuvieras una comprensión sólida de determinantes y el porqué se relacionan con que los sistemas lineales de ecuaciones tengan soluciones distintas de 0 una expresión como ésta podría hacer parecer que sale de la nada",
  "n_reviews": 0,
  "start": 556.22,
  "end": 566.3
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "translatedText": "Para ver esto en acción, volvamos al ejemplo desde el principio, con una matriz cuyas columnas son 3, 0 y 1, 2.",
  "from_community_srt": "Para ver ésto en acción vamos a revisitar el ejemplo del principio Con la matriz cuyas columnas son [3,",
  "n_reviews": 0,
  "start": 568.32,
  "end": 574.54
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "translatedText": "Para encontrar si un valor lambda es un valor propio, réstalo de las diagonales de esta matriz y calcula el determinante.",
  "from_community_srt": "0] y [1, 2] para encontrar si un valor λ es un valor propio resta λ en la diagonal de esta matriz y calcula su determinante",
  "n_reviews": 0,
  "start": 575.35,
  "end": 583.4
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "translatedText": "Al hacer esto, obtenemos un determinado polinomio cuadrático en lambda, 3 menos lambda por 2 menos lambda.",
  "from_community_srt": "Al hacer esto,",
  "n_reviews": 0,
  "start": 590.58,
  "end": 596.72
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "translatedText": "Dado que lambda solo puede ser un valor propio si este determinante es cero, se puede concluir que los únicos valores propios posibles son lambda igual a 2 y lambda igual a 3.",
  "from_community_srt": "obtenemos un polinomio cuadrático en λ (3-λ)(2-λ) como λ solo puede ser un valor propio si el determinante resulta ser 0 puedes concluir que los únicos valores propios posibles son λ = 2 y λ = 3 Para averiguar cuáles son los vectores propios",
  "n_reviews": 0,
  "start": 597.8,
  "end": 608.84
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "translatedText": "Para descubrir cuáles son los vectores propios que realmente tienen uno de estos valores propios, digamos que lambda es igual a 2, conecte ese valor de lambda a la matriz y luego resuelva qué vectores esta matriz alterada diagonalmente envía a cero.",
  "from_community_srt": "que tienen asociados cada uno de estos valores propios Digamos λ = 2 introduce ese valor de λ en la matriz y luego resuelve para qué vectores esta nueva matriz envía al cero Si te pusieras a calcular esto",
  "n_reviews": 0,
  "start": 609.64,
  "end": 623.9
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "translatedText": "Si calculas esto de la misma manera que lo harías con cualquier otro sistema lineal, verás que las soluciones son todos los vectores en la línea diagonal atravesada por menos 1, 1.",
  "from_community_srt": "de la misma forma que hariás con cualquier otro sistema lineal verías que las soluciones son todos los vectores sobre la línia diagonal generada por [-1,",
  "n_reviews": 0,
  "start": 624.94,
  "end": 634.3
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "translatedText": "Esto corresponde al hecho de que la matriz inalterada, 3, 0, 1, 2, tiene el efecto de estirar todos esos vectores por un factor de 2.",
  "from_community_srt": "1]. Esto se corresponde con el hecho de que la matriz sin alterar 3, 0, 1, 2 tiene el efecto de alargar todos esos vectores por un factor de 2.",
  "n_reviews": 0,
  "start": 635.22,
  "end": 643.46
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "translatedText": "Ahora bien, una transformación 2D no tiene por qué tener vectores propios.",
  "from_community_srt": "Ahora bien, una aplicación lineal en 2 dimensiones no tiene por qué tener vectores propios.",
  "n_reviews": 0,
  "start": 646.32,
  "end": 650.2
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "translatedText": "Por ejemplo, considere una rotación de 90 grados.",
  "from_community_srt": "Por ejemplo,",
  "n_reviews": 0,
  "start": 650.72,
  "end": 653.4
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "translatedText": "Esto no tiene vectores propios ya que rota cada vector fuera de su propio intervalo.",
  "from_community_srt": "considera una rotación de 90 grados ésta no tiene ningún vector propio ya que rota cada uno de los vectores fuera de su sistema generador",
  "n_reviews": 0,
  "start": 653.66,
  "end": 658.2
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "translatedText": "Si realmente intentas calcular los valores propios de una rotación como esta, observa lo que sucede.",
  "from_community_srt": "Si intentaras calcular los valores propios de una rotación como esta mira qué ocurre su matriz tiene las columnas [0,",
  "n_reviews": 0,
  "start": 660.8,
  "end": 665.56
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "translatedText": "Su matriz tiene columnas 0, 1 y negativo 1, 0.",
  "from_community_srt": "1] y [-1,",
  "n_reviews": 0,
  "start": 666.3,
  "end": 670.14
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "translatedText": "Resta lambda de los elementos de la diagonal y busca cuándo el determinante es cero.",
  "from_community_srt": "0] resta λ en los elementos de la diagonal y busca cuándo el determinante es 0.",
  "n_reviews": 0,
  "start": 671.1,
  "end": 675.8
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "translatedText": "En este caso, obtienes el polinomio lambda al cuadrado más 1.",
  "from_community_srt": "En este caso,",
  "n_reviews": 0,
  "start": 678.14,
  "end": 681.94
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "translatedText": "Las únicas raíces de ese polinomio son los números imaginarios, i y i negativo.",
  "from_community_srt": "obtendrás el polinomio λ^2+1 las únicas soluciones de ese polinomio son los números imagionarios i y -i",
  "n_reviews": 0,
  "start": 682.68,
  "end": 687.92
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "translatedText": "El hecho de que no haya soluciones de números reales indica que no hay vectores propios.",
  "from_community_srt": "El hecho de que no haya soluciones reales indica que no hay vectores propios.",
  "n_reviews": 0,
  "start": 688.84,
  "end": 693.6
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "translatedText": "Otro ejemplo bastante interesante que vale la pena tener en cuenta es una cizalla.",
  "from_community_srt": "Otro ejemplo bastante interesante que merecer la pena recordar,",
  "n_reviews": 0,
  "start": 695.54,
  "end": 699.82
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "translatedText": "Esto fija i-hat en su lugar y mueve j-hat 1, por lo que su matriz tiene las columnas 1, 0 y 1, 1.",
  "from_community_srt": "es el de la \"cizalla\" que fija el vector i en su lugar y mueve j 1 unidad a la derecha De manera que su matriz tiene las columnas [1,",
  "n_reviews": 0,
  "start": 700.56,
  "end": 707.84
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "translatedText": "Todos los vectores en el eje x son vectores propios con valor propio 1 ya que permanecen fijos en su lugar.",
  "from_community_srt": "0] y [1, 1] Todos los vectores en el eje x son vectores propios con valor propio 1 puesto que se mantienen fijos en su lugar",
  "n_reviews": 0,
  "start": 708.74,
  "end": 714.54
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "translatedText": "De hecho, estos son los únicos vectores propios.",
  "from_community_srt": "De hecho,",
  "n_reviews": 0,
  "start": 715.68,
  "end": 717.82
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "translatedText": "Cuando restas lambda de las diagonales y calculas el determinante, lo que obtienes es 1 menos lambda al cuadrado.",
  "from_community_srt": "estos son los únicos vectores propios cuando restas λ en la diagonal y calculas el determinante",
  "n_reviews": 0,
  "start": 718.76,
  "end": 726.54
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "translatedText": "Y la única raíz de esta expresión es lambda igual a 1.",
  "from_community_srt": "Lo que obtienes es (1-λ)^2 Y la única solución a esa expresión es λ = 1 Esto coincide con lo que vemos geométricamente",
  "n_reviews": 0,
  "start": 729.32,
  "end": 732.86
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "translatedText": "Esto se alinea con lo que vemos geométricamente, que todos los vectores propios tienen valor propio 1.",
  "from_community_srt": "que todos los vectores propios tienen valor propio 1 Aunque,",
  "n_reviews": 0,
  "start": 734.56,
  "end": 739.72
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "translatedText": "Sin embargo, tenga en cuenta que también es posible tener un solo valor propio, pero con más que una simple línea llena de vectores propios.",
  "from_community_srt": "ten en cuenta, que también es posible tener un único valor propio con más de una línea entera de vectores propios",
  "n_reviews": 0,
  "start": 741.08,
  "end": 748.02
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "translatedText": "Un ejemplo sencillo es una matriz que escala todo en 2.",
  "n_reviews": 0,
  "start": 749.9,
  "end": 753.18
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "translatedText": "El único valor propio es 2, pero cada vector en el plano llega a ser un vector propio con ese valor propio.",
  "from_community_srt": "Un simple ejemplo es una matriz que lo escala todo por 2 El  único valor propio es 2 pero todos los vectores en el plano son vectores propios con ese valor propio",
  "n_reviews": 0,
  "start": 753.9,
  "end": 760.7
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "translatedText": "Ahora es otro buen momento para hacer una pausa y reflexionar sobre algo de esto antes de pasar al último tema.",
  "from_community_srt": "Ahora es otro buen momento para pausar y reflexionar un poco sobre esto antes de que me mueva hacia el último tema",
  "n_reviews": 0,
  "start": 762.0,
  "end": 766.96
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "translatedText": "Quiero terminar aquí con la idea de una base propia, que se basa en gran medida en las ideas del último vídeo.",
  "from_community_srt": "Quiero terminar aquí con la idea de una \"base propia\" que depende fuertemente de ideas del último vídeo.",
  "n_reviews": 0,
  "start": 783.54,
  "end": 789.88
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "translatedText": "Eche un vistazo a lo que sucede si nuestros vectores base resultan ser vectores propios.",
  "from_community_srt": "Observa qué ocurre si los vectores de nuestra base resultaran ser vectores propios Por ejemplo,",
  "n_reviews": 0,
  "start": 791.48,
  "end": 796.38
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2.",
  "translatedText": "Por ejemplo, tal vez i-hat esté escalado por 1 negativo y j-hat esté escalado por 2.",
  "from_community_srt": "tal vez el vector i es escalado por -1 y j es escalado por 2.",
  "n_reviews": 0,
  "start": 797.12,
  "end": 802.38
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "translatedText": "Al escribir sus nuevas coordenadas como las columnas de una matriz, observe que esos múltiplos escalares, negativos 1 y 2, que son los valores propios de i-hat y j-hat, se ubican en la diagonal de nuestra matriz, y todas las demás entradas son 0. .",
  "from_community_srt": "Escribiendo las nuevas coordenadas como las columnas de una matriz observa que esos escalares -1 y 2, que son los valores propios de i y j se encuentran en la diagonal de nuestra matriz y el resto de elementos son 0",
  "n_reviews": 0,
  "start": 803.42,
  "end": 817.18
 },
 {
  "input": "Any time a matrix has zeros everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix.",
  "translatedText": "Cada vez que una matriz tiene ceros en todas partes excepto en la diagonal, se llama, razonablemente, matriz diagonal.",
  "from_community_srt": "Siempre que una matriz tenga 0 en todas partes excepto en la diagonal se le llama, de forma esperada,",
  "n_reviews": 0,
  "start": 818.88,
  "end": 825.42
 },
 {
  "input": "And the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "translatedText": "Y la forma de interpretar esto es que todos los vectores base son vectores propios, siendo las entradas diagonales de esta matriz sus valores propios.",
  "from_community_srt": "una \"matriz diagonal\" y la manera de interpretar esto es que todos los vectores de la base son vectores propios",
  "n_reviews": 0,
  "start": 825.84,
  "end": 834.4
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "translatedText": "Hay muchas cosas que hacen que sea mucho más agradable trabajar con matrices diagonales.",
  "from_community_srt": "con los elementos de la diagonal de esta matriz siendo sus valores propios Hay muchas cosas que hacen que las matrices diagonales sean más cómodas para trabajar",
  "n_reviews": 0,
  "start": 837.1,
  "end": 841.06
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "translatedText": "Uno de los más importantes es que es más fácil calcular lo que sucederá si multiplicas esta matriz por sí misma muchas veces.",
  "from_community_srt": "Una importante es que es más facil calcular lo que pasará si multiplicas esta matriz por sí mismo un montón de veces",
  "n_reviews": 0,
  "start": 841.78,
  "end": 848.34
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "translatedText": "Dado que lo único que hace una de estas matrices es escalar cada vector base según algún valor propio, aplicar esa matriz muchas veces, digamos 100 veces, corresponderá a escalar cada vector base según la centésima potencia del valor propio correspondiente.",
  "from_community_srt": "puesto que todo lo que estas matrices hacen es escalar cada vector de la base por un valor propio Aplicando esta matriz muchas veces, digamos 100 veces simplemente va a equivaler a escalar cada vector de la base por la 100º potencia del valor propio correspondiente",
  "n_reviews": 0,
  "start": 849.42,
  "end": 864.6
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "translatedText": "Por el contrario, intente calcular la potencia número 100 de una matriz no diagonal.",
  "from_community_srt": "En contraste, intenta calcular la 100º potencia de una matriz no diagonal En serio,",
  "n_reviews": 0,
  "start": 865.7,
  "end": 869.68
 },
 {
  "input": "Really, try it for a moment.",
  "translatedText": "De verdad, pruébalo por un momento.",
  "n_reviews": 0,
  "start": 869.68,
  "end": 871.32
 },
 {
  "input": "It's a nightmare.",
  "translatedText": "Es una pesadilla.",
  "n_reviews": 0,
  "start": 871.74,
  "end": 872.44
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "translatedText": "Por supuesto, rara vez tendrás tanta suerte como para que tus vectores base también sean vectores propios.",
  "from_community_srt": "inténtalo ¡Es una pesadilla! Por supuesto, rara vez tendrás la suerte de que los vectores de tu base sean también vectores propios Pero si tu aplicación lineal tiene muchos vectores propios",
  "n_reviews": 0,
  "start": 876.08,
  "end": 881.26
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "translatedText": "Pero si tu transformación tiene muchos vectores propios, como el del inicio de este vídeo, suficientes para que puedas elegir un conjunto que abarque todo el espacio, entonces podrías cambiar tu sistema de coordenadas para que estos vectores propios sean tus vectores base.",
  "from_community_srt": "como aquella al comienzo del vídeo suficientes como para que puedas escoger un conjunto que genere el espacio entero entonces podrías cambiar tu sistema de coordenadas de modo que esos vectores propios fueran los vectores de tu base",
  "n_reviews": 0,
  "start": 882.04,
  "end": 896.54
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "translatedText": "Hablé sobre el cambio de base en el último video, pero aquí haré un recordatorio súper rápido de cómo expresar una transformación actualmente escrita en nuestro sistema de coordenadas en un sistema diferente.",
  "from_community_srt": "Hablé sobre los cambios de base en el anterior vídeo pero haré un recordatorio rápido en éste de como expresar la aplicación actualmente escrita en nuestro sistema de coordenadas a un sistema diferente",
  "n_reviews": 0,
  "start": 897.14,
  "end": 907.04
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "translatedText": "Tome las coordenadas de los vectores que desea usar como una nueva base, que en este caso significa nuestros dos vectores propios, luego convierta esas coordenadas en las columnas de una matriz, conocida como matriz de cambio de base.",
  "from_community_srt": "Toma las coordenadas de los vectores que quieres usar como tu nueva base la cual, en este caso, serán dos vectores propios que forman las columnas de una matriz a partir de sus coordenadas",
  "n_reviews": 0,
  "start": 908.44,
  "end": 919.44
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "translatedText": "Cuando intercala la transformación original, poniendo la matriz de cambio de base a su derecha y la inversa de la matriz de cambio de base a su izquierda, el resultado será una matriz que representa esa misma transformación, pero desde la perspectiva de las nuevas coordenadas de los vectores base. sistema.",
  "from_community_srt": "conocida como la matriz del cambio de base Cuando juntas la aplicación original poniendo la matriz del cambio de base a su derecha y la inversa de la matriz del cambio de base a su izquierda el resultado sera una matriz que representa esa misma transformación pero desde la perspectiva del sistema de coordenadas de la nueva base El objetivo de hacer esto con vectores propios",
  "n_reviews": 0,
  "start": 920.18,
  "end": 936.5
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "translatedText": "El objetivo de hacer esto con vectores propios es que se garantiza que esta nueva matriz será diagonal con sus valores propios correspondientes en esa diagonal.",
  "from_community_srt": "es que esta matriz será sí o sí diagonal con sus correspondientes valores propios en la diagonal",
  "n_reviews": 0,
  "start": 937.44,
  "end": 946.68
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "translatedText": "Esto se debe a que representa trabajar en un sistema de coordenadas donde lo que sucede con los vectores base es que se escalan durante la transformación.",
  "from_community_srt": "Esto es así porque representa que trabajas en un sistema de coordenadas donde lo que le ocurre a los vectores de la base",
  "n_reviews": 0,
  "start": 946.86,
  "end": 954.32
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "translatedText": "Un conjunto de vectores base que también son vectores propios se denomina, nuevamente, razonablemente, base propia.",
  "from_community_srt": "es que están siendo escalados durante la transformación Un conjunto de vectores que formen una base, que además sean vectores propios se le llama, como era de esperar,",
  "n_reviews": 0,
  "start": 955.8,
  "end": 961.56
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "translatedText": "Entonces, si, por ejemplo, necesitara calcular la potencia número 100 de esta matriz, sería mucho más fácil cambiar a una base propia, calcular la potencia número 100 en ese sistema y luego volver a convertir a nuestro sistema estándar.",
  "from_community_srt": "una \"base propia\" Así que si, por ejemplo, necesitaras calcular la 100º potencia de esta matriz sería mucho más sencillo cambiarla a una base propia, calcular la 100º potencia en esa base y luego convertirla de vuelta a tu base original No puedes hacer esto con todas las aplicaciones",
  "n_reviews": 0,
  "start": 962.34,
  "end": 975.68
 },
 {
  "input": "You can't do this with all transformations.",
  "translatedText": "No puedes hacer esto con todas las transformaciones.",
  "n_reviews": 0,
  "start": 976.62,
  "end": 978.32
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "translatedText": "Un corte, por ejemplo, no tiene suficientes vectores propios para abarcar todo el espacio.",
  "from_community_srt": "Una \"cizalla\", por ejemplo, no tiene suficientes vectores propios para generar el espacio entero Pero si puedes encontrar una base propia",
  "n_reviews": 0,
  "start": 978.32,
  "end": 982.98
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "translatedText": "Pero si puedes encontrar una base propia, las operaciones matriciales son realmente hermosas.",
  "n_reviews": 0,
  "start": 983.46,
  "end": 988.16
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "translatedText": "Para aquellos de ustedes que estén dispuestos a resolver un rompecabezas bastante interesante para ver cómo se ve en acción y cómo se puede usar para producir resultados sorprendentes, dejaré un mensaje aquí en la pantalla.",
  "from_community_srt": "te hace las operaciones con matrices algo realmente agradable Para aquellos de vosotros dispuestos a resolver un puzzle bastante chulo con tal de ver como se ve esto en acción y cómo puede ser usado para producir algunos resultados sorprendentes Dejaré un enunciado aquí en la pantalla.",
  "n_reviews": 0,
  "start": 989.12,
  "end": 997.32
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "translatedText": "Requiere un poco de trabajo, pero creo que lo disfrutarás.",
  "from_community_srt": "Requiere algo de trabajo pero creo que lo disfrutaréis.",
  "n_reviews": 0,
  "start": 997.6,
  "end": 1000.28
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "translatedText": "El siguiente y último vídeo de esta serie tratará sobre espacios vectoriales abstractos.",
  "from_community_srt": "El próximo y último vídeo de esta serie va a ser sobre \"espacios vectoriales abstractos\" ¡Nos vemos hasta entonces!",
  "n_reviews": 0,
  "start": 1000.84,
  "end": 1006.12
 }
]