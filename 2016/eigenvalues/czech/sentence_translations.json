[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "translatedText": "Vlastní vektory a vlastní hodnoty jsou jedním z těch témat, která jsou pro mnoho studentů obzvláště neintuitivní.",
  "model": "DeepL",
  "from_community_srt": "Minule jsem se zeptal, co pro vás znamená matematika. Někteří odvětili \"manipulaci s čísly, manipulaci se strukturami\". A kdybych se zeptal, co pro vás znamená hudba, řekli byste \"manipulaci s notami\"? -- Serge Lang Vlastní čísla a vlastní vektory jsou jedním z témat, ve kterých se studenti ztrácejí.",
  "n_reviews": 0,
  "start": 19.92,
  "end": 25.76
 },
 {
  "input": "Questions like, why are we doing this and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "translatedText": "Otázky typu, proč to děláme a co to vlastně znamená, zůstávají příliš často jen tak plout v moři výpočtů bez odpovědi.",
  "model": "DeepL",
  "from_community_srt": "Otázky jako \"Proč počítáme tohle?\" \"Co má tohle znamenat?\" se často zůstávají vznášet nad mořem nevysvětlených výpočtů.",
  "n_reviews": 0,
  "start": 25.76,
  "end": 33.26
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "translatedText": "A jak jsem zveřejňoval videa z této série, mnoho z vás se vyjádřilo, že se těšíte zejména na vizualizaci tohoto tématu.",
  "model": "DeepL",
  "from_community_srt": "Jak jsem začal vydávat tuhle sérii videí hodně z vás se těšilo zejména na tuhle látku.",
  "n_reviews": 0,
  "start": 33.92,
  "end": 40.06
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "translatedText": "Domnívám se, že důvodem není ani tak to, že by eigenthings byly obzvláště komplikované nebo špatně vysvětlené.",
  "model": "DeepL",
  "from_community_srt": "Nemyslím ale, že by to bylo kvůli tomu, že vlastní věci jsou složité nebo špatně vykládány.",
  "n_reviews": 0,
  "start": 40.68,
  "end": 46.36
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "translatedText": "Ve skutečnosti je to poměrně jednoduché a myslím, že většina knih to dobře vysvětluje.",
  "model": "DeepL",
  "from_community_srt": "Je to vlastně docela přímočaré, a řekl bych, že ve většině knížek je to vysvětlené dobře.",
  "n_reviews": 0,
  "start": 46.86,
  "end": 51.18
 },
 {
  "input": "The issue is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "translatedText": "Problémem je, že má smysl pouze tehdy, pokud máte solidní vizuální představu o mnoha tématech, která mu předcházejí.",
  "model": "DeepL",
  "from_community_srt": "Problém je, že to dává smysl teprve až když solidně vizuálně rozumíte předcházejícím tématům.",
  "n_reviews": 0,
  "start": 51.52,
  "end": 58.48
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "translatedText": "Nejdůležitější je, abyste věděli, jak uvažovat o maticích jako o lineárních transformacích, ale také abyste se dobře orientovali v takových věcech, jako jsou determinanty, lineární soustavy rovnic a změna báze.",
  "model": "DeepL",
  "from_community_srt": "Nejdůležitější tu je umět se dívat na matice jako na lineární transformace, ale taky se musíte kamarádit s tématy jako jsou determinanty, soustavy lineárních rovnic a změna báze.",
  "n_reviews": 0,
  "start": 59.06,
  "end": 69.94
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "translatedText": "Zmatek ohledně vlastních čísel obvykle souvisí spíše s nejistým základem v některém z těchto témat než se samotnými vlastními vektory a vlastními čísly.",
  "model": "DeepL",
  "from_community_srt": "Zmatení okolo vlastních věcí obvykle spíše vychází z křehkého povědomí o některém z těchto témat než ze samotných vlastních čísel a vektorů.",
  "n_reviews": 0,
  "start": 70.72,
  "end": 79.24
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "translatedText": "Pro začátek uvažujte nějakou lineární transformaci ve dvou rozměrech, jako je ta, která je zobrazena zde.",
  "model": "DeepL",
  "from_community_srt": "Začneme tím, že si vezmeme nějakou dvourozměrnou lineární transformaci, jako třeba tuhle.",
  "n_reviews": 0,
  "start": 79.98,
  "end": 84.84
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "translatedText": "Přesune bázový vektor i-hat na souřadnice 3, 0 a j-hat na 1, 2.",
  "model": "DeepL",
  "from_community_srt": "Přesouvá bázový vektor 'i' na souřadnice (3, 0) a 'j' na (1,",
  "n_reviews": 0,
  "start": 85.46,
  "end": 91.04
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "translatedText": "Je tedy reprezentován maticí, jejíž sloupce jsou 3, 0 a 1, 2.",
  "model": "DeepL",
  "from_community_srt": "2), takže jej reprezentujeme maticí se sloupečky (3, 0) a (1,",
  "n_reviews": 0,
  "start": 91.78,
  "end": 95.64
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "translatedText": "Zaměřte se na to, co to udělá s jedním konkrétním vektorem, a přemýšlejte o rozpětí tohoto vektoru, o přímce procházející jeho počátkem a vrcholem.",
  "model": "DeepL",
  "from_community_srt": "2) Zaměříme se na to, co to provádí s jedním konkrétním vektorem a podíváme se na jeho lineární obal, přímku procházející počátkem a jeho špičkou.",
  "n_reviews": 0,
  "start": 96.6,
  "end": 104.16
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "translatedText": "Většina vektorů se během transformace vyřadí ze svého rozpětí.",
  "model": "DeepL",
  "from_community_srt": "Většina vektorů během transformace vypadne ze svého obalu.",
  "n_reviews": 0,
  "start": 104.92,
  "end": 108.38
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "translatedText": "Zdálo by se, že je to docela náhoda, kdyby se místo, kam vektor dopadl, nacházelo také někde na této linii.",
  "model": "DeepL",
  "from_community_srt": "Rozumějte, byla by fakt haluz, aby výsledný vektor dopadl zase přesně na tu přímku.",
  "n_reviews": 0,
  "start": 108.78,
  "end": 115.32
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "translatedText": "Některé speciální vektory však zůstávají ve svém vlastním rozpětí, což znamená, že vliv matice na takový vektor je pouze jeho roztažení nebo zmačkání, podobně jako u skaláru.",
  "model": "DeepL",
  "from_community_srt": "V jistých speciálních případech ale vektory ve svém obalu zůstanou, což znamená, že když tento vektor vynásobíme naší maticí, tak se jen natáhne nebo zmáčkne nějakým skalárem.",
  "n_reviews": 0,
  "start": 117.4,
  "end": 127.04
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "translatedText": "Pro tento konkrétní příklad je jedním z takových speciálních vektorů bázový vektor i-hat.",
  "model": "DeepL",
  "from_community_srt": "V našem případě je jedním takovým speciálním vektorem vektor 'i', obal 'i' je x-ová osa",
  "n_reviews": 0,
  "start": 129.46,
  "end": 134.1
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "translatedText": "Rozpětí i-hat je osa x a z prvního sloupce matice vidíme, že i-hat se přesune na trojnásobek sebe sama, stále na ose x.",
  "model": "DeepL",
  "from_community_srt": "a z prvního sloupečku matice vidíme, že se 'i' přesune na svůj trojnásobek,",
  "n_reviews": 0,
  "start": 134.64,
  "end": 144.12
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "translatedText": "Navíc, vzhledem k tomu, jak fungují lineární transformace, je jakýkoli jiný vektor na ose x také pouze protažen o faktor 3, a zůstává tedy na svém vlastním rozpětí.",
  "model": "DeepL",
  "from_community_srt": "stále na ose x. Co víc, díky vlastnostem lineárních transformací se i jakýkoli jiný vektor na ose x přesune na svůj trojnásobek, a tedy zůstane ve svém obalu.",
  "n_reviews": 0,
  "start": 146.32,
  "end": 156.48
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "translatedText": "Poněkud záludnější vektor, který při této transformaci zůstává na svém vlastním rozpětí, je záporný 1, 1.",
  "model": "DeepL",
  "from_community_srt": "A pak se schovává ještě další takový vektor, který zůstává ve svém obalu: (-1,",
  "n_reviews": 0,
  "start": 158.5,
  "end": 164.04
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "translatedText": "Nakonec se protáhne na dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "1). Ten se během transformace natáhne dvakrát.",
  "n_reviews": 0,
  "start": 164.66,
  "end": 167.14
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "translatedText": "A opět, linearita bude znamenat, že jakýkoli jiný vektor na úhlopříčce, kterou tento chlapík prochází, se prostě protáhne o dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "A opět z linearity dostáváme, že i jakýkoli jiný vektor na této úhlopříčce se během transformace jenom natáhne dvakrát.",
  "n_reviews": 0,
  "start": 169.0,
  "end": 178.22
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "translatedText": "A pro tuto transformaci jsou to všechny vektory, které mají tuto zvláštní vlastnost, že zůstávají na svém rozpětí.",
  "model": "DeepL",
  "from_community_srt": "A pro tuto transformaci to už jsou všechny vektory, které zůstanou ve svém obalu, Ty na x-ové ose,",
  "n_reviews": 0,
  "start": 179.82,
  "end": 185.18
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "translatedText": "Ty na ose x se roztáhnou na trojnásobek a ty na této úhlopříčce se roztáhnou na dvojnásobek.",
  "model": "DeepL",
  "from_community_srt": "které se natáhnout koeficientem 3, a ty na zpětné úhlopříčce, které se natáhnou koeficientem 2.",
  "n_reviews": 0,
  "start": 185.62,
  "end": 191.98
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "translatedText": "Jakýkoli jiný vektor se při transformaci poněkud pootočí a vyřadí se z přímky, kterou prochází.",
  "model": "DeepL",
  "from_community_srt": "Všechny ostatní vektory se během transformace někam pootočí, a vypadnou ze svého obalu.",
  "n_reviews": 0,
  "start": 192.76,
  "end": 198.08
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "translatedText": "Jak jste již možná uhodli, tyto speciální vektory se nazývají vlastní vektory transformace a ke každému vlastnímu vektoru je přiřazena tzv. vlastní hodnota, což je právě faktor, o který se během transformace roztáhne nebo smrskne.",
  "model": "DeepL",
  "from_community_srt": "Jak byste si mohli tipnout, tyhle zvláštní vektory se nazývají \"vlastními vektory\" dané transformace a každému vlastnímu vektoru náleží jeho \"vlastní číslo\", to je ten skalár, kterým se během transformace daný vektor natáhne či smrskne.",
  "n_reviews": 0,
  "start": 202.52,
  "end": 217.38
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing, or the fact that these eigenvalues happen to be positive.",
  "translatedText": "Na roztahování a mačkání není samozřejmě nic zvláštního, stejně jako na tom, že tato vlastní čísla jsou kladná.",
  "model": "DeepL",
  "from_community_srt": "Samozřejmě není třeba rozlišovat natahování a smrskávání, ani se zaobírat jen kladnými vlastními čísly.",
  "n_reviews": 0,
  "start": 220.28,
  "end": 225.94
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "translatedText": "V jiném příkladu můžete mít vlastní vektor s vlastní hodnotou zápornou o polovinu, což znamená, že se vektor převrátí a zmenší o polovinu.",
  "model": "DeepL",
  "from_community_srt": "V jiném případě bychom mohli mít vlastní vektor s vlastním číslem -1/2, to znamená, že se vektor překlopí a dvakrát smrskne.",
  "n_reviews": 0,
  "start": 226.38,
  "end": 235.12
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "translatedText": "Důležité však je, aby zůstal na čáře, kterou se rozprostírá, aniž by se z ní otáčel.",
  "model": "DeepL",
  "from_community_srt": "Důležité je, že zůstane v přímce, kterou vytyčuje a nestočí se z ní pryč.",
  "n_reviews": 0,
  "start": 236.98,
  "end": 242.76
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "translatedText": "Pro představu, proč je užitečné o tom přemýšlet, si vezměte na pomoc trojrozměrnou rotaci.",
  "model": "DeepL",
  "from_community_srt": "Pro malý náznak, proč to může být užitečné, si představte rotaci ve 3D.",
  "n_reviews": 0,
  "start": 244.46,
  "end": 249.8
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "translatedText": "Pokud najdete vlastní vektor pro toto natočení, tedy vektor, který zůstává na svém vlastním rozpětí, nalezli jste osu natočení.",
  "model": "DeepL",
  "from_community_srt": "Když najdeme vlastní vektor této rotace, tedy vektor, který zůstane ve svém obalu, tak vlastně najdeme osu této rotace.",
  "n_reviews": 0,
  "start": 251.66,
  "end": 260.5
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3x3 matrix associated with that transformation.",
  "translatedText": "A je mnohem snazší uvažovat o 3D rotaci v podobě nějaké osy otáčení a úhlu, o který se otáčí, než přemýšlet o celé matici 3x3 spojené s touto transformací.",
  "model": "DeepL",
  "from_community_srt": "A je mnohem jednodušší se 3D rotaci dívat v pojmech jako je osa rotace a úhel, o který se otočí, než si představovat celou matici 3x3 odpovídající této rotaci.",
  "n_reviews": 0,
  "start": 262.6,
  "end": 274.74
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "translatedText": "V tomto případě by mimochodem odpovídající vlastní číslo muselo být 1, protože rotace nikdy nic neroztahuje ani nemačká, takže délka vektoru by zůstala stejná.",
  "model": "DeepL",
  "from_community_srt": "V tomhle případě by mimochodem odpovídající vlastní bylo číslo rovno 1, protože rotace nikdy nic nenatáhne ani nesmrskne, takže délka vektoru by zůstala stejná.",
  "n_reviews": 0,
  "start": 277.0,
  "end": 285.86
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "translatedText": "Tento vzorec se často objevuje v lineární algebře.",
  "model": "DeepL",
  "from_community_srt": "Tahle myšlenka se v lineární algebře vyskytuje hojně.",
  "n_reviews": 0,
  "start": 288.08,
  "end": 290.02
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "translatedText": "U jakékoli lineární transformace popsané maticí můžete pochopit, co dělá, když sloupce této matice odečtete jako místa, kde přistávají bázové vektory.",
  "model": "DeepL",
  "from_community_srt": "Když máte lineární transformaci popsanou maticí, můžete si sice představit, co dělá, tím, že si přečtete sloupce matice a",
  "n_reviews": 0,
  "start": 290.44,
  "end": 299.4
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "translatedText": "Často je však lepším způsobem, jak se dostat k jádru toho, co lineární transformace skutečně dělá, méně závislým na konkrétním souřadnicovém systému, nalezení vlastních vektorů a vlastních hodnot.",
  "model": "DeepL",
  "from_community_srt": "interpretujete je jako obrazy bázových vektorů, ale často je k pochopení, co tato transformace doopravdy dělá, lepší zvolit cestu méně závislou na konkrétním souřadnicovém systému, najít vlastní vektory a vlastní čísla.",
  "n_reviews": 0,
  "start": 300.02,
  "end": 310.82
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "translatedText": "Nebudu se zde zabývat všemi podrobnostmi o metodách výpočtu vlastních vektorů a vlastních hodnot, ale pokusím se podat přehled výpočetních myšlenek, které jsou pro koncepční pochopení nejdůležitější.",
  "model": "DeepL",
  "from_community_srt": "Nepokryji tu všechny podrobnosti metod výpočtu vlastních vektorů a vlastních čísel, ale pokusím se poskytnout přehled myšlenek výpočtu, které jsou nejdůležitější pro celkové pochopení.",
  "n_reviews": 0,
  "start": 315.46,
  "end": 326.02
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "translatedText": "Symbolicky vypadá představa vlastního vektoru takto.",
  "model": "DeepL",
  "from_community_srt": "Symbolicky vypadá představa vlastního vektoru takto.",
  "n_reviews": 0,
  "start": 327.18,
  "end": 330.48
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "translatedText": "A je matice představující nějakou transformaci, přičemž v je vlastní vektor, a lambda je číslo, konkrétně příslušná vlastní hodnota.",
  "model": "DeepL",
  "from_community_srt": "'A' je matice reprezentující jistou transformaci, 'v' je její vlastní vektor a λ (lambda) je příslušné vlastní číslo.",
  "n_reviews": 0,
  "start": 331.04,
  "end": 339.74
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "translatedText": "Tento výraz říká, že maticový vektorový součin A krát v dává stejný výsledek jako pouhé škálování vlastního vektoru v nějakou hodnotou lambda.",
  "model": "DeepL",
  "from_community_srt": "Tahle rovnice říká, že součin matice a vektoru Av vyjde stejně jako jenom vyškálování vlastního vektoru 'v' nějakým skalárem λ.",
  "n_reviews": 0,
  "start": 340.68,
  "end": 349.9
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "translatedText": "Nalezení vlastních vektorů a jejich vlastních hodnot matice A tedy spočívá v nalezení takových hodnot v a lambda, aby tento výraz platil.",
  "model": "DeepL",
  "from_community_srt": "Takže hledání vlastních čísel a vlastních vektorů matice A přejde na hledání hodnot 'v' a λ, aby byla splněna tato rovnice.",
  "n_reviews": 0,
  "start": 351.0,
  "end": 360.1
 },
 {
  "input": "It's a little awkward to work with at first, because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "translatedText": "Práce s ním je zpočátku trochu nepohodlná, protože levá strana představuje násobení matice a vektoru, ale pravá strana je skalárně-vektorové násobení.",
  "model": "DeepL",
  "from_community_srt": "Ze začátku není jasné, co s tím, protože na levé straně násobíme vektor maticí, zatímco na pravé násobíme vektor skalárem.",
  "n_reviews": 0,
  "start": 361.92,
  "end": 370.54
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "translatedText": "Začněme tedy přepisem této pravé strany jako určitého druhu maticově-vektorového násobení pomocí matice, která má za následek škálování libovolného vektoru koeficientem lambda.",
  "model": "DeepL",
  "from_community_srt": "Takže napřed přepíšeme pravou stranu, taky na nějaké násobení s maticí. Použijeme matici, která každý vektor vyškáluje skalárem λ, Sloupečky takové matice",
  "n_reviews": 0,
  "start": 371.12,
  "end": 380.62
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "translatedText": "Sloupce takové matice budou představovat to, co se děje s každým bázovým vektorem, a každý bázový vektor se jednoduše vynásobí lambdou, takže tato matice bude mít na diagonále číslo lambda a všude jinde nuly.",
  "model": "DeepL",
  "from_community_srt": "tvoří transformované bázové vektory, tedy bázové vektory vynásobené λ. Matice tak bude mít čísla λ na úhlopříčce a všude jinde nuly.",
  "n_reviews": 0,
  "start": 381.68,
  "end": 394.32
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with 1s down the diagonal.",
  "translatedText": "Běžný způsob, jak ho zapsat, je vynásobit tuto lambdu a zapsat ji jako lambda krát i, kde i je identická matice s jedničkami na diagonále.",
  "model": "DeepL",
  "from_community_srt": "Je běžné ji zapsat tak, že λ vytkneme, a píšeme λI, kde I je jednotková matice s jedničkami na úhlopříčce.",
  "n_reviews": 0,
  "start": 396.18,
  "end": 404.86
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "translatedText": "Protože obě strany vypadají jako násobení matice a vektoru, můžeme tuto pravou stranu odečíst a vynásobit v.",
  "model": "DeepL",
  "from_community_srt": "Když teď na obou stranách rovnice násobíme vektor s maticí, můžeme od sebe strany rovnice odečíst a vytknout 'v'.",
  "n_reviews": 0,
  "start": 405.86,
  "end": 411.86
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix times v gives the zero vector.",
  "translatedText": "Nyní tedy máme novou matici A minus lambda krát identita a hledáme vektor v takový, že tato nová matice krát v dává nulový vektor.",
  "model": "DeepL",
  "from_community_srt": "Takže vznikne nová matice A-λI a hledáme vektor 'v', aby když jej vynásobíme s touto maticí,",
  "n_reviews": 0,
  "start": 414.16,
  "end": 424.92
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "translatedText": "To platí vždy, pokud je v nulovým vektorem, ale to je nuda.",
  "model": "DeepL",
  "from_community_srt": "vyšla nula. To bude určitě platit, když bude nulový sám 'v', ale to je nuda.",
  "n_reviews": 0,
  "start": 426.38,
  "end": 431.1
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "translatedText": "To, co chceme, je nenulový vlastní vektor.",
  "model": "DeepL",
  "from_community_srt": "Chtěli bychom nenulový vlastní vektor.",
  "n_reviews": 0,
  "start": 431.34,
  "end": 433.64
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "translatedText": "A pokud se podíváte na kapitoly 5 a 6, dozvíte se, že jediný způsob, jak je možné, aby se součin matice s nenulovým vektorem stal nulovým, je ten, že transformace spojená s touto maticí zmačká prostor do nižší dimenze.",
  "model": "DeepL",
  "from_community_srt": "Jestli jste viděli kapitoly 5 a 6, tak víte, že aby součin matice a nenulového vektoru mohl vyjít jako nula, musí transformace odpovídající této matici splácnout prostor do nižší dimenze.",
  "n_reviews": 0,
  "start": 434.42,
  "end": 448.02
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "translatedText": "A tato squishifikace odpovídá nulovému determinantu matice.",
  "model": "DeepL",
  "from_community_srt": "Tohle splácnutí odpovídá nulovému determinantu matice.",
  "n_reviews": 0,
  "start": 449.3,
  "end": 454.22
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "translatedText": "Abychom byli konkrétní, řekněme, že vaše matice A má sloupce 2, 1 a 2, 3, a uvažujte o tom, že od každé diagonální položky odečtete proměnnou lambda.",
  "model": "DeepL",
  "from_community_srt": "Abychom byli konkrétní, dejme tomu, že A má sloupečky (2, 1) a (2, 3), a podle vzorečku odečteme proměnnou λ z každé položky na úhlopříčce.",
  "n_reviews": 0,
  "start": 455.48,
  "end": 465.52
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "translatedText": "Nyní si představte, že lambdu upravujete otáčením knoflíku a měníte její hodnotu.",
  "model": "DeepL",
  "from_community_srt": "Teď si pošolícháme λ, jako bychom točili kolečkem měnícím jeho hodnotu.",
  "n_reviews": 0,
  "start": 466.48,
  "end": 470.28
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "translatedText": "Se změnou hodnoty lambda se mění i samotná matice, a tím i její determinant.",
  "model": "DeepL",
  "from_community_srt": "Jak se λ mění, mění se samotná matice a s ní i její determinant.",
  "n_reviews": 0,
  "start": 470.94,
  "end": 477.24
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "translatedText": "Cílem je najít takovou hodnotu lambda, aby tento determinant byl nulový, což znamená, že upravená transformace zmenší prostor na nižší dimenzi.",
  "model": "DeepL",
  "from_community_srt": "Chceme najít hodnotu λ takovou, aby determinant vyšel nulový, to znamená, že takto naladěná transformace splácne prostor do nižší dimenze.",
  "n_reviews": 0,
  "start": 478.22,
  "end": 487.24
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "translatedText": "V tomto případě je nejvhodnějším bodem, když se lambda rovná 1.",
  "model": "DeepL",
  "from_community_srt": "V tomhle případě zvítězíme,",
  "n_reviews": 0,
  "start": 488.16,
  "end": 491.16
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "translatedText": "Kdybychom zvolili nějakou jinou matici, vlastní číslo by samozřejmě nemuselo být 1.",
  "model": "DeepL",
  "from_community_srt": "když λ=1. Samozřejmě, kdybychom si zvolili jinou matici, tak by jednička nejspíš nevyšla jako vlastní číslo",
  "n_reviews": 0,
  "start": 492.18,
  "end": 496.12
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "translatedText": "Sladký bod může být dosažen při jiné hodnotě lambda.",
  "model": "DeepL",
  "from_community_srt": "a správná hodnota λ by byla nějaká jiná.",
  "n_reviews": 0,
  "start": 496.24,
  "end": 498.6
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "translatedText": "Je toho trochu moc, ale pojďme si říct, co to znamená.",
  "model": "DeepL",
  "from_community_srt": "Je toho docela hodně, tak si rozklíčujme, co se teď děje.",
  "n_reviews": 0,
  "start": 500.08,
  "end": 502.96
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "translatedText": "Když je lambda rovna 1, matice A minus lambda krát identita rozmělní prostor na přímku.",
  "model": "DeepL",
  "from_community_srt": "Když je λ=1, tak matice A-λI splácne rovinu do přímky.",
  "n_reviews": 0,
  "start": 502.96,
  "end": 509.56
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "translatedText": "To znamená, že existuje nenulový vektor v takový, že A minus lambda krát identita krát v se rovná nulovému vektoru.",
  "model": "DeepL",
  "from_community_srt": "To znamená, že existuje nenulový vektor 'v', takový, že (A-λI)v vyjde jako nulový vektor.",
  "n_reviews": 0,
  "start": 510.44,
  "end": 518.56
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "translatedText": "A nezapomeňte, že nás to zajímá proto, že to znamená, že A krát v se rovná lambda krát v, což můžete vyčíst jako tvrzení, že vektor v je vlastním vektorem A, který zůstává na svém vlastním rozpětí během transformace A.",
  "model": "DeepL",
  "from_community_srt": "A to všechno nás zajímá proto, že z toho pak plyne Av=λv, což můžeme přečíst jako \"vektor 'v' je vlastní vektor matice A\", neboli vektor 'v' zůstane během transformace 'A' ve svém obalu.",
  "n_reviews": 0,
  "start": 520.48,
  "end": 537.28
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "translatedText": "V tomto příkladu je odpovídající vlastní číslo 1, takže v by vlastně zůstalo na místě.",
  "model": "DeepL",
  "from_community_srt": "V našem případě je odpovídající vlastní číslo rovno jedné, takže 'v' jenom zůstane na místě.",
  "n_reviews": 0,
  "start": 538.32,
  "end": 544.02
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "translatedText": "Zastavte se a zamyslete se, jestli se musíte ujistit, že se vám tento způsob uvažování líbí.",
  "model": "DeepL",
  "from_community_srt": "Zastavte si video, jestli si tuhle argumentaci potřebujete rozmyslet.",
  "n_reviews": 0,
  "start": 546.22,
  "end": 549.5
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "translatedText": "O tom jsem se zmínil v úvodu.",
  "model": "DeepL",
  "from_community_srt": "To je to,",
  "n_reviews": 0,
  "start": 553.38,
  "end": 555.64
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "translatedText": "Kdybyste neměli solidní znalosti o determinantech a jejich vztahu k lineárním soustavám rovnic s nenulovými řešeními, připadal by vám takový výraz úplně mimo mísu.",
  "model": "DeepL",
  "from_community_srt": "co jsem zmínil v úvodu, jestli pořádně nerozumíte determinantu, a jak souvisí se soustavami lineárních rovnic, která mají nenulová řešení, taková rovnice může vypadat jak spadlá z nebe.",
  "n_reviews": 0,
  "start": 556.22,
  "end": 566.3
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "translatedText": "Abychom to viděli v praxi, zopakujme si příklad ze začátku s maticí, jejíž sloupce jsou 3, 0 a 1, 2.",
  "model": "DeepL",
  "from_community_srt": "Abychom to viděli v praxi, podíváme se ještě na úvodní příklad s maticí se sloupečky (3,",
  "n_reviews": 0,
  "start": 568.32,
  "end": 574.54
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "translatedText": "Chcete-li zjistit, zda je hodnota lambda vlastní číslo, odečtěte ji od diagonál této matice a vypočítejte determinant.",
  "model": "DeepL",
  "from_community_srt": "0) a (1, 2). Abychom zjistili, která čísla λ jsou vlastní, odečteme λ od položek na úhlopříčce a spočteme determinant.",
  "n_reviews": 0,
  "start": 575.35,
  "end": 583.4
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "translatedText": "Tímto postupem získáme určitý kvadratický polynom v lambdě, 3 minus lambda krát 2 minus lambda.",
  "model": "DeepL",
  "from_community_srt": "Tím nám vyjde kvadratický polynom v proměnné λ: (3-λ)(2-λ)",
  "n_reviews": 0,
  "start": 590.58,
  "end": 596.72
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "translatedText": "Protože lambda může být vlastní číslo pouze tehdy, je-li tento determinant nulový, lze dojít k závěru, že jediná možná vlastní čísla jsou lambda rovna 2 a lambda rovna 3.",
  "model": "DeepL",
  "from_community_srt": "Číslo λ bude vlastní jen tehdy, když vyjde determinant nulový. Z toho můžeme usoudit, že vlastní čísla jsou jenom λ=2 a λ=3.",
  "n_reviews": 0,
  "start": 597.8,
  "end": 608.84
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "translatedText": "Chcete-li zjistit, které vlastní vektory mají vlastně jednu z těchto vlastních hodnot, řekněme lambda rovnou 2, dosaďte tuto hodnotu lambda do matice a pak vyřešte, které vektory tato diagonálně změněná matice posílá k nule.",
  "model": "DeepL",
  "from_community_srt": "Abychom určili odpovídající vlastní vektory, když už máme nějaké vlastní číslo, řekněme λ=2, dosadíme tuto hodnotu do matice a vyřešíme soustavu rovnic, abychom zjistili, které vektory se pošlou na nulu.",
  "n_reviews": 0,
  "start": 609.64,
  "end": 623.9
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "translatedText": "Kdybyste ji vypočítali stejně jako jakoukoli jinou lineární soustavu, zjistili byste, že řešením jsou všechny vektory na úhlopříčce proložené zápornými čísly 1, 1.",
  "model": "DeepL",
  "from_community_srt": "Když to spočtete, vaší oblíbenou metodou řešení soustav lineárních rovnic, zjistíte, že řešením jsou vektory v lineárním obalu (-1,",
  "n_reviews": 0,
  "start": 624.94,
  "end": 634.3
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "translatedText": "To odpovídá skutečnosti, že nezměněná matice 3, 0, 1, 2 má za následek protažení všech těchto vektorů o faktor 2.",
  "model": "DeepL",
  "from_community_srt": "1). To odpovídá tomu, že původní matice ((3,0),(1,2)) všechny tyto vektory vyškáluje dvěma.",
  "n_reviews": 0,
  "start": 635.22,
  "end": 643.46
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "translatedText": "2D transformace nemusí mít vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "Ne každá 2D transformace má vlastní vektory.",
  "n_reviews": 0,
  "start": 646.32,
  "end": 650.2
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "translatedText": "Uvažujme například otočení o 90 stupňů.",
  "model": "DeepL",
  "from_community_srt": "Příkladem může být otočení o 90°, které žádné nenulové vlastní vektory nemá,",
  "n_reviews": 0,
  "start": 650.72,
  "end": 653.4
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "translatedText": "Ten nemá žádné vlastní vektory, protože otáčí každý vektor mimo jeho vlastní rozpětí.",
  "model": "DeepL",
  "from_community_srt": "protože každý vektor stočí pryč ze svého obalu.",
  "n_reviews": 0,
  "start": 653.66,
  "end": 658.2
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "translatedText": "Pokud se skutečně pokusíte vypočítat vlastní čísla takové rotace, všimněte si, co se stane.",
  "model": "DeepL",
  "from_community_srt": "Všimněte si, co se stane,",
  "n_reviews": 0,
  "start": 660.8,
  "end": 665.56
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "translatedText": "Jeho matice má sloupce 0, 1 a záporné 1, 0.",
  "model": "DeepL",
  "from_community_srt": "když se pokusíme spočítat vlastní čísla takového otočení, Matice má sloupečky (0,1) a (-1,0),",
  "n_reviews": 0,
  "start": 666.3,
  "end": 670.14
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "translatedText": "Odečtěte lambdu od diagonálních prvků a hledejte, kdy je determinant nulový.",
  "model": "DeepL",
  "from_community_srt": "odečteme λ od hodnot na úhlopříčce a podíváme se,",
  "n_reviews": 0,
  "start": 671.1,
  "end": 675.8
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "translatedText": "V tomto případě dostanete polynom lambda na druhou plus 1.",
  "model": "DeepL",
  "from_community_srt": "kdy je determinant nulový. V tomhle případě vyjde polynom λ^2+1, jehož jediné kořeny jsou",
  "n_reviews": 0,
  "start": 678.14,
  "end": 681.94
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "translatedText": "Jedinými kořeny tohoto polynomu jsou imaginární čísla i a záporné i.",
  "model": "DeepL",
  "from_community_srt": "imaginární čísla 'i' a '-i'.",
  "n_reviews": 0,
  "start": 682.68,
  "end": 687.92
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "translatedText": "Skutečnost, že neexistují řešení v reálných číslech, znamená, že neexistují vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "Skutečnost, že tato rovnice nemá reálná řešení, značí, že tu nejsou žádné nenulové vlastní vektory.",
  "n_reviews": 0,
  "start": 688.84,
  "end": 693.6
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "translatedText": "Dalším docela zajímavým příkladem, který stojí za to mít na paměti, je střižník.",
  "model": "DeepL",
  "from_community_srt": "Jiný důležitý příklad, který je dobré mít na paměti, je zkosení.",
  "n_reviews": 0,
  "start": 695.54,
  "end": 699.82
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "translatedText": "Tím se i-hat zafixuje na místě a j-hat se posune o 1, takže jeho matice má sloupce 1, 0 a 1, 1.",
  "model": "DeepL",
  "from_community_srt": "To nechává 'i' na místě, a ''j' posune o 1 doprava. Takže jeho matice má sloupečky (1,0) a (1,1).",
  "n_reviews": 0,
  "start": 700.56,
  "end": 707.84
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "translatedText": "Všechny vektory na ose x jsou vlastní vektory s vlastní hodnotou 1, protože zůstávají na místě.",
  "model": "DeepL",
  "from_community_srt": "Všechny vektory na ose 'x' jsou vlastní příslušné vlastnímu číslu 1, jelikož zůstanou na místě.",
  "n_reviews": 0,
  "start": 708.74,
  "end": 714.54
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "translatedText": "Ve skutečnosti se jedná o jediné vlastní vektory.",
  "model": "DeepL",
  "from_community_srt": "Ale jsou to popravdě jediné vlastní vektory.",
  "n_reviews": 0,
  "start": 715.68,
  "end": 717.82
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "translatedText": "Když od úhlopříček odečtete lambdu a vypočtete determinant, dostanete 1 minus lambda na druhou.",
  "model": "DeepL",
  "from_community_srt": "Když od úhlopříčky odečtete λ a spočtete determinant, vyjde 1-λ^2.",
  "n_reviews": 0,
  "start": 718.76,
  "end": 726.54
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "translatedText": "A jediným kořenem tohoto výrazu je lambda rovná se 1.",
  "model": "DeepL",
  "from_community_srt": "Jediný kořen takové rovnice je λ=1.",
  "n_reviews": 0,
  "start": 729.32,
  "end": 732.86
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "translatedText": "To odpovídá tomu, co vidíme geometricky, že všechny vlastní vektory mají vlastní hodnotu 1.",
  "model": "DeepL",
  "from_community_srt": "To odpovídá tomu, co vidíme geometricky, že všechny vlastní vektory odpovídají vlastnímu číslu 1.",
  "n_reviews": 0,
  "start": 734.56,
  "end": 739.72
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "translatedText": "Mějte však na paměti, že je také možné mít jen jednu vlastní hodnotu, ale s více než jen řádkem plným vlastních vektorů.",
  "model": "DeepL",
  "from_community_srt": "Dále mějte na paměti, že můžeme mít jenom jedno vlastní číslo, ale víc vlastních vektorů než jen jedna přímka.",
  "n_reviews": 0,
  "start": 741.08,
  "end": 748.02
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "translatedText": "Jednoduchým příkladem je matice, která vše škáluje po 2.",
  "model": "DeepL",
  "from_community_srt": "Jednoduchým příkladem je matice, která vše zvětší dvakrát.",
  "n_reviews": 0,
  "start": 749.9,
  "end": 753.18
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "translatedText": "Jediná vlastní hodnota je 2, ale každý vektor v rovině se stane vlastním vektorem s touto vlastní hodnotou.",
  "model": "DeepL",
  "from_community_srt": "Jediná vlastní hodnota je 2, ale každý vektor v rovině je vlastním vektorem odpovídající tomuto vlastnímu číslu.",
  "n_reviews": 0,
  "start": 753.9,
  "end": 760.7
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "translatedText": "Nyní je další vhodná chvíle se zastavit a zamyslet se nad některými z nich, než přejdu k poslednímu tématu.",
  "model": "DeepL",
  "from_community_srt": "Teď je opět dobrý moment na pozastavení videa a uspořádání si toho všeho, než že přesuneme na poslední podkapitolu.",
  "n_reviews": 0,
  "start": 762.0,
  "end": 766.96
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "translatedText": "Na závěr bych rád představil myšlenku vlastní báze, která se do značné míry opírá o myšlenky z minulého videa.",
  "model": "DeepL",
  "from_community_srt": "Vlastní čísla zakončíme myšlenkou \"vlastní báze\", která se hodně opírá o minulé video.",
  "n_reviews": 0,
  "start": 783.54,
  "end": 789.88
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "translatedText": "Podívejte se, co se stane, když jsou naše základní vektory náhodou vlastními vektory.",
  "model": "DeepL",
  "from_community_srt": "Podívejme se, co se stane, když jsou všechny bázové vektory shodou okolností vlastní.",
  "n_reviews": 0,
  "start": 791.48,
  "end": 796.38
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2.",
  "translatedText": "Například i-hat je škálován zápornou hodnotou 1 a j-hat je škálován hodnotou 2.",
  "model": "DeepL",
  "from_community_srt": "Například 'i' jen vyškálujeme hodnotou -1 a 'j' vyškálujeme dvakrát.",
  "n_reviews": 0,
  "start": 797.12,
  "end": 802.38
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "translatedText": "Když zapíšeme jejich nové souřadnice jako sloupce matice, všimneme si, že tyto skalární násobky, záporné 1 a 2, což jsou vlastní čísla i-hat a j-hat, leží na diagonále naší matice a každý další zápis je 0.",
  "model": "DeepL",
  "from_community_srt": "Všimněte si, že když zapíšeme výsledné souřadnice do sloupců matice, tak tyto skaláry -1 a 2, což jsou vlastní čísla příslušející vektorům 'i' a 'j' jsou na úhlopříčce naší matice, zatímco všude jinde jsou nuly.",
  "n_reviews": 0,
  "start": 803.42,
  "end": 817.18
 },
 {
  "input": "Any time a matrix has zeros everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix.",
  "translatedText": "Vždy, když má matice nuly všude jinde než na diagonále, nazývá se vcelku rozumně diagonální maticí.",
  "model": "DeepL",
  "from_community_srt": "Kdykoli má matice nuly všude kromě úhlopříčky, nazýváme ji, nepřekvapivě, \"diagonální maticí\".",
  "n_reviews": 0,
  "start": 818.88,
  "end": 825.42
 },
 {
  "input": "And the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "translatedText": "To lze interpretovat tak, že všechny základní vektory jsou vlastními vektory, přičemž diagonální položky této matice jsou jejich vlastní hodnoty.",
  "model": "DeepL",
  "from_community_srt": "Na takovou matici se můžeme dívat tak, že všechny bázové vektory jsou vlastní, a vlastní čísla jsou napsána na úhlopříčce matice.",
  "n_reviews": 0,
  "start": 825.84,
  "end": 834.4
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "translatedText": "S diagonálními maticemi se pracuje mnohem lépe.",
  "model": "DeepL",
  "from_community_srt": "S diagonálními maticemi se zachází snáze v mnoha ohledech, zejména třeba při výpočtu transformace,",
  "n_reviews": 0,
  "start": 837.1,
  "end": 841.06
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "translatedText": "Jedním z nich je, že je snazší vypočítat, co se stane, když tuto matici vynásobíte celou řadou.",
  "model": "DeepL",
  "from_community_srt": "která vyjde z opakovaného násobení danou maticí.",
  "n_reviews": 0,
  "start": 841.78,
  "end": 848.34
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "translatedText": "Protože jediné, co jedna z těchto matic dělá, je škálování každého bázového vektoru určitou vlastní hodnotou, bude použití této matice mnohokrát, řekněme stokrát, odpovídat škálování každého bázového vektoru 100. mocninou příslušné vlastní hodnoty.",
  "model": "DeepL",
  "from_community_srt": "Protože taková matice nedělá nic jiného, než že škáluje každý bázový vektor nějakým vlastním číslem, když to provedeme dejme tomu 100krát, bude výsledek stejný jako když vyškálujeme každý bázový vektor stou mocninou příslušného vlastního čísla.",
  "n_reviews": 0,
  "start": 849.42,
  "end": 864.6
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "translatedText": "Naproti tomu zkuste vypočítat stou mocninu nediagonální matice.",
  "model": "DeepL",
  "from_community_srt": "Na druhou stranu si zkuste spočítat stou mocninu matice, která není diagonální.",
  "n_reviews": 0,
  "start": 865.7,
  "end": 869.68
 },
 {
  "input": "Really, try it for a moment.",
  "translatedText": "Opravdu, zkuste to na chvíli.",
  "model": "DeepL",
  "from_community_srt": "Vážně si to na chvíli zkuste, no,",
  "n_reviews": 0,
  "start": 869.68,
  "end": 871.32
 },
 {
  "input": "It's a nightmare.",
  "translatedText": "Je to noční můra.",
  "model": "DeepL",
  "n_reviews": 0,
  "start": 871.74,
  "end": 872.44
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "translatedText": "Samozřejmě budete mít málokdy takové štěstí, aby vaše základní vektory byly zároveň vlastními vektory.",
  "model": "DeepL",
  "from_community_srt": "je to hrůza! Samozřejmě musíte mít fakt štěstí, aby byly bázové vektory rovnou vlastní, ale za předpokladu,",
  "n_reviews": 0,
  "start": 876.08,
  "end": 881.26
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "translatedText": "Pokud však vaše transformace obsahuje mnoho vlastních vektorů, jako například transformace ze začátku tohoto videa, a to tolik, že si můžete vybrat množinu, která pokrývá celý prostor, pak můžete změnit souřadnicový systém tak, aby tyto vlastní vektory byly vašimi základními vektory.",
  "model": "DeepL",
  "from_community_srt": "že má transformace dost vlastních vektorů, jako ta z úvodu tohoto videa, dost na to, abyste z nich mohli vybrat množinu, která generuje celý prostor, tak si můžete upravit systém souřadnic, aby bázové vektory opravdu byly vlastní.",
  "n_reviews": 0,
  "start": 882.04,
  "end": 896.54
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "translatedText": "O změně základu jsem mluvil v minulém videu, ale tady si v rychlosti připomenu, jak vyjádřit transformaci zapsanou v našem souřadnicovém systému do jiného systému.",
  "model": "DeepL",
  "from_community_srt": "V minulém videu jsem vysvětloval změnu báze. Ale ještě tu stručně připomenu, jak přeložit transformaci z našeho souřadnicového systému do jiného.",
  "n_reviews": 0,
  "start": 897.14,
  "end": 907.04
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "translatedText": "Vezměte souřadnice vektorů, které chcete použít jako novou bázi, což v tomto případě znamená naše dva vlastní vektory, a pak z těchto souřadnic vytvořte sloupce matice, známé jako matice změny báze.",
  "model": "DeepL",
  "from_community_srt": "Vezmeme souřadnice vektorů, ze kterých chceme postavit novou bázi, což v našem případě znamená dva vlastní vektory, tyto souřadnice zapíšeme do sloupců matice, které se říká matice přechodu ke standardní bázi.",
  "n_reviews": 0,
  "start": 908.44,
  "end": 919.44
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "translatedText": "Když původní transformaci přepíšete a na její pravou stranu umístíte matici změny báze a na její levou stranu inverzní matici změny báze, výsledkem bude matice reprezentující stejnou transformaci, ale z pohledu souřadnicového systému nových bázových vektorů.",
  "model": "DeepL",
  "from_community_srt": "Pak sem vmáčkneme původní matici transformace nalevo od matice přechodu, a nakonec přidáme inverzní matici k matici přechodu. Výsledná matice reprezentuje tu samou transformaci, ale z pohledu nového souřadnicového systému.",
  "n_reviews": 0,
  "start": 920.18,
  "end": 936.5
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "translatedText": "Smysl tohoto postupu s vlastními vektory spočívá v tom, že tato nová matice je zaručeně diagonální s odpovídajícími vlastními hodnotami na této diagonále.",
  "model": "DeepL",
  "from_community_srt": "Tu celou záležitost jsme s vlastními vektory dělali proto, že takhle bude matice transformace zaručeně diagonální, a vlastní čísla budou ležet na úhlopříčce.",
  "n_reviews": 0,
  "start": 937.44,
  "end": 946.68
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "translatedText": "Je to proto, že se jedná o práci v souřadnicovém systému, kde se s bázovými vektory děje to, že se při transformaci škálují.",
  "model": "DeepL",
  "from_community_srt": "To proto, že pracujeme v souřadnicovém systému, kde se všechny bázové vektory během transformace jenom nějak vyškálovaly.",
  "n_reviews": 0,
  "start": 946.86,
  "end": 954.32
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "translatedText": "Soubor bázových vektorů, které jsou zároveň vlastními vektory, se nazývá, opět vcelku rozumně, vlastní báze.",
  "model": "DeepL",
  "from_community_srt": "Taková množina vlastních vektorů, která tvoří bázi se z pochopitelných důvodů nazývá \"vlastní báze\".",
  "n_reviews": 0,
  "start": 955.8,
  "end": 961.56
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "translatedText": "Pokud byste tedy například potřebovali vypočítat stou mocninu této matice, bylo by mnohem jednodušší přejít na vlastní základnu, vypočítat stou mocninu v této soustavě a pak ji převést zpět do naší standardní soustavy.",
  "model": "DeepL",
  "from_community_srt": "Takže když třeba potřebujete spočítat stou mocninu takovéhle matice, bude mnohem jednodušší přejít k vlastní bázi, spočítat stou mocninu v těchto souřadnicích, výsledek přeložit zpátky do standardního systému.",
  "n_reviews": 0,
  "start": 962.34,
  "end": 975.68
 },
 {
  "input": "You can't do this with all transformations.",
  "translatedText": "To nelze provést u všech transformací.",
  "model": "DeepL",
  "from_community_srt": "To se nedá udělat se všemi transformacemi.",
  "n_reviews": 0,
  "start": 976.62,
  "end": 978.32
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "translatedText": "Například smyk nemá dostatek vlastních vektorů, aby obsáhl celý prostor.",
  "model": "DeepL",
  "from_community_srt": "Třeba zkosení nemá dost vlastních vektorů, které by generovaly celý prostor.",
  "n_reviews": 0,
  "start": 978.32,
  "end": 982.98
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "translatedText": "Ale pokud se vám podaří najít vlastní základnu, jsou operace s maticemi opravdu krásné.",
  "model": "DeepL",
  "from_community_srt": "Ale když najdete vlastní bázi, jsou maticové operace miloučké.",
  "n_reviews": 0,
  "start": 983.46,
  "end": 988.16
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "translatedText": "Pro ty z vás, kteří jsou ochotni projít si pěknou hádanku, aby viděli, jak to vypadá v akci a jak to lze použít k dosažení překvapivých výsledků, nechám zde na obrazovce výzvu.",
  "model": "DeepL",
  "from_community_srt": "Pro ty, co jsou ochotni si promyslet pěknou úlohu, aby to všechno viděli v akci, a podívali se na netriviální výsledek, tu nechám něco na obrazovce.",
  "n_reviews": 0,
  "start": 989.12,
  "end": 997.32
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "translatedText": "Dá to trochu práce, ale myslím, že se vám to bude líbit.",
  "model": "DeepL",
  "from_community_srt": "Dá to trochu práce, ale doufám, že si to užijete.",
  "n_reviews": 0,
  "start": 997.6,
  "end": 1000.28
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "translatedText": "Další a poslední video této série se bude věnovat abstraktním vektorovým prostorům.",
  "model": "DeepL",
  "from_community_srt": "Příští a poslední video téhle série bude o \"abstraktních vektorových prostorech\".",
  "n_reviews": 0,
  "start": 1000.84,
  "end": 1006.12
 }
]