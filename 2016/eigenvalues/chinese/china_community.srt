1
00:00:19,870 --> 00:00:25,660
“特征向量与特征值”是许多学生认为非常不直观的一个话题

2
00:00:26,100 --> 00:00:29,630
“为什么要这么做”以及“它究竟意味着什么”之类的问题

3
00:00:29,630 --> 00:00:33,440
通常都淹没在计算的海洋中无人问津

4
00:00:33,950 --> 00:00:35,710
在我放出这个视频系列之后

5
00:00:35,810 --> 00:00:40,300
有很多人都在评论，说特别期待这一部分的形象解释

6
00:00:40,710 --> 00:00:41,370
我怀疑

7
00:00:41,370 --> 00:00:46,560
原因并不在于特征的东西特别复杂或是缺乏说明

8
00:00:46,890 --> 00:00:48,970
实际上，相对而言它更加直接

9
00:00:48,970 --> 00:00:51,170
而且我认为大部分的书也提供了良好的解释

10
00:00:51,720 --> 00:00:52,650
问题在于

11
00:00:52,650 --> 00:00:58,400
只有对之前讲的内容有充分的几何直观，你才能真正理解它

12
00:00:59,050 --> 00:01:04,010
这里最重要的部分是，你需要了解如何将矩阵看作线性变换

13
00:01:04,360 --> 00:01:06,110
但你也需要熟悉其他的内容

14
00:01:06,110 --> 00:01:10,160
例如行列式、线性方程组和基变换

15
00:01:10,690 --> 00:01:16,410
通常而言，对特征的东西感到疑惑，更多的是因为以上内容的薄弱基础

16
00:01:16,410 --> 00:01:19,470
而不是在于特征向量与特征值本身

17
00:01:20,370 --> 00:01:23,790
首先，考虑二维空间中的某个线性变换

18
00:01:23,790 --> 00:01:24,930
比如现在展示的这个

19
00:01:25,390 --> 00:01:31,230
它将基向量i帽变换到坐标(3, 0)，j帽变换到坐标(1, 2)

20
00:01:31,770 --> 00:01:35,760
所以如果用矩阵来表达，它的列就是(3, 0)和(1, 2)

21
00:01:36,620 --> 00:01:39,380
我们关注它对一个特定向量的作用

22
00:01:39,680 --> 00:01:44,340
并且考虑这个向量张成的空间，也就是通过原点和向量尖端的直线

23
00:01:45,010 --> 00:01:48,670
大部分向量在变换中都离开了其张成的空间

24
00:01:48,970 --> 00:01:55,390
我的意思是，如果向量正好落在这条直线上，感觉更像是巧合

25
00:01:57,410 --> 00:02:00,530
不过，某些特殊向量的确留在它们张成的空间里

26
00:02:00,920 --> 00:02:07,090
意味着矩阵对它的作用仅仅是拉伸或者压缩而已，如同一个标量

27
00:02:09,630 --> 00:02:14,280
在这个例子中，基向量i帽就是这样一个特殊向量

28
00:02:15,060 --> 00:02:17,570
i帽张成的空间是x轴

29
00:02:17,780 --> 00:02:19,630
而且从矩阵的第一列可以看出

30
00:02:19,630 --> 00:02:24,290
i帽变成了原来的3倍，仍然留在x轴上

31
00:02:26,370 --> 00:02:29,610
此外，因为线性变换的性质

32
00:02:29,880 --> 00:02:34,540
x轴上的任何其他向量都只是被拉伸为原来的3倍

33
00:02:34,540 --> 00:02:36,650
因此也就留在它们张成的空间里

34
00:02:38,600 --> 00:02:44,290
有一个略显隐蔽的向量(-1, 1)，它在变换中也留在自己张成的空间里

35
00:02:44,800 --> 00:02:47,280
最终被拉伸为原来的2倍

36
00:02:49,000 --> 00:02:51,670
同上，线性性质暗示着一点

37
00:02:51,670 --> 00:02:55,770
处在它所张成的对角线上的其他任何一个向量

38
00:02:55,770 --> 00:02:58,320
也仅仅被拉伸为原来的2倍

39
00:02:59,940 --> 00:03:01,140
对这个变换而言

40
00:03:01,370 --> 00:03:05,370
以上就是所有拥有这一特殊性质（留在它们张成的空间里）的向量

41
00:03:05,700 --> 00:03:08,500
x轴上的向量被拉伸为原来的3倍

42
00:03:08,800 --> 00:03:12,170
而这条对角线上的向量被拉伸为原来的2倍

43
00:03:12,780 --> 00:03:16,050
任何其他向量在变换中都有或多或少的旋转

44
00:03:16,240 --> 00:03:18,250
从而离开它张成的直线

45
00:03:22,610 --> 00:03:23,780
估计你现在已经猜到了

46
00:03:24,030 --> 00:03:28,360
这些特殊向量就被称为变换的“特征向量”

47
00:03:28,770 --> 00:03:33,150
每个特征向量都有一个所属的值，被称为“特征值”

48
00:03:33,340 --> 00:03:37,630
即衡量特征向量在变换中拉伸或压缩比例的因子

49
00:03:40,540 --> 00:03:46,190
当然，拉伸和压缩或者特征值恰好为正，并没有什么特殊的地方

50
00:03:46,490 --> 00:03:50,950
换个例子，你可以有一个属于特征值-1/2的特征向量

51
00:03:51,350 --> 00:03:55,170
意味着这个向量被反向，并且被压缩为原来的1/2

52
00:03:57,390 --> 00:04:02,660
但是重点在于，它停留在它张成的直线上，并未发生旋转

53
00:04:04,570 --> 00:04:07,500
若想知道为什么它有用途并且值得细究

54
00:04:07,760 --> 00:04:10,050
那就考虑一个三维空间中的旋转

55
00:04:11,880 --> 00:04:15,050
如果你能找到这个旋转的特征向量

56
00:04:15,270 --> 00:04:17,240
也就是留在它张成的空间里的向量

57
00:04:17,640 --> 00:04:20,620
那么你找到的就是旋转轴

58
00:04:22,890 --> 00:04:35,010
而且把一个三维旋转看成绕某个轴旋转一定角度，要比考虑相应的3×3矩阵直观得多

59
00:04:37,100 --> 00:04:40,880
顺便一提，在这种情况下，相应的特征值必须为1

60
00:04:41,020 --> 00:04:43,790
因为旋转并不缩放任何一个向量

61
00:04:43,950 --> 00:04:46,010
所以向量的长度保持不变

62
00:04:48,120 --> 00:04:50,220
这种规律在线性代数中经常出现

63
00:04:50,520 --> 00:04:55,500
对于任一矩阵描述的线性变换

64
00:04:55,500 --> 00:04:59,640
你可以通过将矩阵的列看作变换后的基向量来理解它

65
00:05:00,040 --> 00:05:07,710
但是，理解线性变换作用的关键往往较少依赖于你的特定坐标系

66
00:05:08,060 --> 00:05:11,070
更好的方法是求出它的特征向量和特征值

67
00:05:15,790 --> 00:05:20,240
我并不会涉及计算特征向量和特征值的具体细节

68
00:05:20,430 --> 00:05:23,440
但是我会尽量概述一下计算思想

69
00:05:23,630 --> 00:05:26,270
这对概念上的理解至关重要

70
00:05:27,140 --> 00:05:30,510
用符号表示的话，以下就是特征向量的概念

71
00:05:30,990 --> 00:05:33,810
A是代表某个变换的矩阵

72
00:05:34,010 --> 00:05:35,940
v是特征向量

73
00:05:36,290 --> 00:05:40,040
λ是一个数，也就是对应的特征值

74
00:05:40,680 --> 00:05:44,910
这个等式是说，矩阵向量乘积，也就是A乘以v

75
00:05:45,220 --> 00:05:50,140
等于特征向量v乘以某个数λ

76
00:05:51,430 --> 00:05:55,350
因此求解矩阵A的特征向量和特征值

77
00:05:55,620 --> 00:06:00,260
实际上就是求解使得这个等式成立的向量v和数λ

78
00:06:02,320 --> 00:06:03,910
乍一看，求解这个等式有些棘手

79
00:06:03,910 --> 00:06:07,460
因为等号左侧代表的是矩阵向量乘积

80
00:06:07,460 --> 00:06:10,820
但是等号右侧代表的是向量数乘

81
00:06:11,120 --> 00:06:16,160
所以我们首先将等号右侧重写为某个矩阵向量乘积

82
00:06:16,430 --> 00:06:20,840
其中，矩阵的作用效果是将任一向量乘以λ

83
00:06:21,690 --> 00:06:25,530
这个矩阵的列代表着变换后的基向量

84
00:06:25,770 --> 00:06:28,940
而每个基向量仅仅与λ相乘

85
00:06:29,320 --> 00:06:34,430
所以这个矩阵的对角元均为λ，其余位置都是0

86
00:06:36,310 --> 00:06:41,530
通常的书写方法是提出因子λ，写作λ乘以 I

87
00:06:41,530 --> 00:06:45,100
这里的 I 就是单位矩阵，对角元均为1

88
00:06:45,890 --> 00:06:48,610
现在两侧都是矩阵向量乘积的形式

89
00:06:48,880 --> 00:06:52,090
我们就能将等号右侧的东西移到左侧，然后提出因子v

90
00:06:54,250 --> 00:06:58,330
现在我们得到的是一个新的矩阵 - A减去λ乘以单位阵

91
00:06:58,760 --> 00:07:05,150
我们就寻找一个向量v，使得这个新矩阵与v相乘结果为零向量

92
00:07:06,710 --> 00:07:10,220
如果v本身就是零向量的话，这个等式恒成立

93
00:07:10,220 --> 00:07:11,330
但是这没什么意思

94
00:07:11,330 --> 00:07:13,920
我们想要的是一个非零特征向量

95
00:07:14,430 --> 00:07:16,320
如果你看过第五章和第六章视频的话

96
00:07:16,320 --> 00:07:22,290
你就知道，当且仅当矩阵代表的变换将空间压缩到更低的维度时

97
00:07:22,710 --> 00:07:28,250
才会存在一个非零向量，使得矩阵和它的乘积为零向量

98
00:07:29,840 --> 00:07:34,450
而空间压缩对应的就是矩阵的行列式为零

99
00:07:35,540 --> 00:07:40,210
举个具体的例子，假设你有一个矩阵，列为(2, 1)和(2, 3)

100
00:07:40,590 --> 00:07:45,720
考虑每个对角元都减去某个变量λ

101
00:07:46,510 --> 00:07:50,460
现在想象一下，逐渐调整λ的值

102
00:07:51,090 --> 00:07:53,080
当λ的值改变时

103
00:07:53,080 --> 00:07:57,540
矩阵本身发生改变，因此行列式也在改变

104
00:07:58,190 --> 00:08:03,140
目标在于找到一个λ使得这个行列式为零

105
00:08:03,350 --> 00:08:07,500
也就是说调整后的变换将空间压缩到一个更低的维度上

106
00:08:08,210 --> 00:08:11,370
在这个例子中，λ等于1时恰到好处

107
00:08:12,190 --> 00:08:14,140
当然，如果我选择其他的矩阵

108
00:08:14,140 --> 00:08:18,820
特征值不一定是1，λ取其他值时才能使行列式为零

109
00:08:20,190 --> 00:08:23,150
这看起来有点复杂，不过我们来解释这个过程的意思

110
00:08:23,490 --> 00:08:29,750
当λ等于1时，A减去λ乘以单位阵将空间压缩到一条直线上

111
00:08:30,380 --> 00:08:33,250
这意味着存在一个非零向量v

112
00:08:33,250 --> 00:08:38,730
使得A减去λ乘以单位阵的结果乘以v等于零向量

113
00:08:40,580 --> 00:08:46,980
记住一点，我们关注它，是因为它意味着A乘以v等于λ乘以v

114
00:08:49,490 --> 00:08:53,580
也就是说向量v是A的一个特征向量

115
00:08:53,790 --> 00:08:57,470
在变换中停留在它张成的空间里

116
00:08:58,480 --> 00:09:04,100
在这个例子中，v对应的特征值是1，所以它实际上保持不变

117
00:09:06,180 --> 00:09:09,610
如果你觉得理解还不够透彻，那就暂停思考一下

118
00:09:13,760 --> 00:09:15,890
这就是我在绪论中提到的内容

119
00:09:16,210 --> 00:09:22,960
如果你没有充分理解行列式，以及它为什么与线性方程组存在非零解有所联系

120
00:09:23,270 --> 00:09:26,400
这个等式会让你感到出乎意料

121
00:09:28,400 --> 00:09:31,320
为了了解这个过程，我们重温一下视频开头的例子

122
00:09:31,680 --> 00:09:34,730
这个矩阵的列是(3, 0)和(1, 2)

123
00:09:35,560 --> 00:09:38,610
为了求解特征值λ

124
00:09:38,910 --> 00:09:42,900
将矩阵的对角元减去λ，然后计算行列式

125
00:09:51,060 --> 00:09:56,920
这样我们就得到了一个关于λ的二次多项式(3-λ)(2-λ)

126
00:09:57,800 --> 00:10:02,440
因为只有当这个行列式为零时，λ才会是特征值

127
00:10:02,780 --> 00:10:08,980
你就能推断出，所有可能的特征值是λ等于2和λ等于3

128
00:10:10,040 --> 00:10:15,380
为了求出属于某个特征值的特征向量，比如λ等于2

129
00:10:15,900 --> 00:10:18,440
将λ的值代入矩阵当中

130
00:10:19,070 --> 00:10:24,100
然后求解出在这个对角线变化的矩阵变换后成为零的向量

131
00:10:25,180 --> 00:10:28,180
如果进行计算，如同求解其他线性方程组一样

132
00:10:28,470 --> 00:10:34,550
你会发现所有的解全部落在由向量(-1, 1)张成的对角线上

133
00:10:35,390 --> 00:10:43,610
与之对应的，就是原始的矩阵[(3, 0), (1, 2)]将这些向量拉伸为原来的2倍

134
00:10:46,600 --> 00:10:50,400
不过，二维线性变换不一定有特征向量

135
00:10:50,860 --> 00:10:53,580
举个例子，考虑这样一个90度的旋转

136
00:10:53,890 --> 00:10:58,330
它并没有特征向量，因为每一个向量都发生了旋转并离开了其张成的空间

137
00:11:01,120 --> 00:11:05,700
如果你真的尝试去计算它的特征值，注意一下会发生什么

138
00:11:06,290 --> 00:11:10,320
矩阵的列为(0, 1)和(-1, 0)

139
00:11:11,040 --> 00:11:15,970
对角元减去λ后，然后寻找行列式为0的情形

140
00:11:18,370 --> 00:11:22,130
在这个例子里，你会得到多项式λ^2+1

141
00:11:22,900 --> 00:11:28,060
这个多项式的根只能是虚数i与-i

142
00:11:28,970 --> 00:11:33,900
没有实数解表明它没有特征向量

143
00:11:35,880 --> 00:11:40,020
另一个很有意思并且值得思考的例子是剪切变换

144
00:11:40,520 --> 00:11:44,500
它保持i帽不变，将j帽向右移动一个单位

145
00:11:44,800 --> 00:11:48,040
所以矩阵的列为(1, 0)和(1, 1)

146
00:11:48,910 --> 00:11:54,730
所有x轴上的向量都是属于特征值1的特征向量，因为它们都保持不变

147
00:11:55,630 --> 00:11:58,010
实际上，这些就是所有的特征向量

148
00:11:58,780 --> 00:12:02,770
当你将对角元减去λ，然后计算行列式

149
00:12:03,450 --> 00:12:06,720
你得到的是(1-λ)^2

150
00:12:09,540 --> 00:12:13,070
这个多项式唯一的根是λ等于1

151
00:12:14,980 --> 00:12:19,890
这与几何上得到的“所有特征向量均属于特征值1”的结果一致

152
00:12:21,070 --> 00:12:21,930
不过注意一点

153
00:12:21,930 --> 00:12:28,200
可能会出现只有一个特征值，但是特征向量不止在一条直线上的情况

154
00:12:29,980 --> 00:12:33,390
一个简单的例子是将所有向量变为两倍的矩阵

155
00:12:33,970 --> 00:12:40,960
唯一的特征值是2，但是平面内每一个向量都是属于这个特征值的特征向量

156
00:12:42,230 --> 00:12:44,840
现在是暂停思考这部分的绝好时机

157
00:12:44,840 --> 00:12:46,570
因为接下来我会继续最后一个话题

158
00:13:03,900 --> 00:13:07,230
我想以特征基的概念结束这期视频

159
00:13:07,420 --> 00:13:10,040
而它在很大程度上依赖于上期视频的思想

160
00:13:11,580 --> 00:13:16,600
如果我们的基向量恰好是特征向量，来看看会发生什么

161
00:13:17,180 --> 00:13:22,480
比如说，可能i帽变为原来的(-1)倍，j帽变为原来的2倍

162
00:13:23,490 --> 00:13:26,200
将它们的新坐标作为矩阵的列

163
00:13:26,560 --> 00:13:32,480
注意，它们的倍数-1和2，也就是i帽和j帽所属的特征值

164
00:13:32,890 --> 00:13:37,340
位于矩阵的对角线上，而其他元素均为0

165
00:13:38,890 --> 00:13:45,610
除了对角元以外其他元素均为0的矩阵被称为对角矩阵，这非常合理

166
00:13:45,900 --> 00:13:50,000
解读它的方法是，所有基向量都是特征向量

167
00:13:50,210 --> 00:13:54,760
矩阵的对角元是它们所属的特征值

168
00:13:57,270 --> 00:14:01,090
对角矩阵在很多方面都更容易处理

169
00:14:01,910 --> 00:14:08,520
其中一个重要的方面是，矩阵与自己多次相乘的结果更容易计算

170
00:14:09,400 --> 00:14:14,330
因为对角矩阵仅仅让基向量与某个特征值相乘

171
00:14:14,720 --> 00:14:17,960
所以多次应用矩阵乘法，比如100次

172
00:14:18,240 --> 00:14:24,830
也只是将每个基向量与对应特征值的100次幂相乘

173
00:14:25,800 --> 00:14:29,900
相比之下，尝试计算一个非对角矩阵的100次幂

174
00:14:30,140 --> 00:14:32,650
真的去试试看，这就是场噩梦

175
00:14:36,470 --> 00:14:41,470
当然对于基向量同时也是特征向量的情况，你很可能不像它那么幸运

176
00:14:42,120 --> 00:14:46,520
但是如果你的变换有许多特征向量，就像视频开始时的例子一样

177
00:14:46,860 --> 00:14:50,620
多到你能选出一个张成全空间的集合

178
00:14:51,240 --> 00:14:56,830
那么你就能变换你的坐标系，使得这些特征向量就是基向量

179
00:14:57,560 --> 00:14:59,560
我在上期视频中已经讨论过基变换了

180
00:14:59,560 --> 00:15:01,870
不过我在这里再做一次超快的回顾

181
00:15:01,870 --> 00:15:07,180
说说如何在另一个坐标系中表达当前坐标系所描述的变换

182
00:15:08,460 --> 00:15:11,930
取出你想用作新基的向量的坐标

183
00:15:11,930 --> 00:15:14,270
在这里指的是两个特征向量

184
00:15:14,610 --> 00:15:19,640
然后将坐标作为一个矩阵的列，这个矩阵就是基变换矩阵

185
00:15:20,280 --> 00:15:22,680
在右侧写下基变换矩阵

186
00:15:22,850 --> 00:15:24,830
在左侧写下基变换矩阵的逆

187
00:15:25,150 --> 00:15:28,500
当你将原始的变换夹在两个矩阵中间时

188
00:15:28,890 --> 00:15:32,730
所得的矩阵代表的是同一个变换

189
00:15:32,940 --> 00:15:36,730
不过是从新基向量所构成的坐标系的角度来看的

190
00:15:37,620 --> 00:15:40,380
用特征向量来完成这件事的意义在于

191
00:15:40,380 --> 00:15:46,880
这个新矩阵必然是对角的，并且对角元为对应的特征值

192
00:15:47,250 --> 00:15:54,590
这是因为，它所处的坐标系的基向量在变换中只进行了缩放

193
00:15:55,770 --> 00:16:01,800
一组基向量（同样是特征向量）构成的集合被称为一组“特征基”，这也非常合理

194
00:16:02,330 --> 00:16:07,020
所以说，如果你要计算这个矩阵的100次幂

195
00:16:07,370 --> 00:16:10,550
一种更容易的做法是先变换到特征基

196
00:16:10,870 --> 00:16:13,310
在那个坐标系中计算100次幂

197
00:16:13,630 --> 00:16:15,870
然后转换回标准坐标系

198
00:16:16,720 --> 00:16:18,600
不是所有变换都能进行这一过程

199
00:16:18,780 --> 00:16:23,120
比如说剪切变换，它的特征向量不够多，并不能张成全空间

200
00:16:23,740 --> 00:16:28,380
但是如果你能找到一组特征基，矩阵运算就会变得非常轻松

201
00:16:29,160 --> 00:16:32,980
对于那些愿意动笔计算的人，我在屏幕上留了一道练习

202
00:16:32,980 --> 00:16:37,570
帮助你们理解矩阵幂次计算的实际过程，以及它所能带来的惊人结论

203
00:16:37,890 --> 00:16:40,260
这需要下一点功夫，不过我觉得你会喜欢它的

204
00:16:40,910 --> 00:16:45,610
下期，也就是最后一期视频，是关于抽象向量空间的内容

205
00:16:45,900 --> 00:16:46,520
到时候再见！

