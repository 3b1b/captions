1
00:00:19,920 --> 00:00:22,988
Собственные векторы и собственные значения — одна из тех тем, 

2
00:00:22,988 --> 00:00:25,760
которые многие студенты находят особенно неинтуитивными.

3
00:00:25,760 --> 00:00:29,982
Такие вопросы, как «почему мы это делаем и что это на самом деле означает», 

4
00:00:29,982 --> 00:00:33,260
слишком часто просто уплывают в море вычислений без ответа.

5
00:00:33,920 --> 00:00:37,121
И когда я выпустил видео из этой серии, многие из вас высказались о том, 

6
00:00:37,121 --> 00:00:40,060
что с нетерпением ждут возможности визуализировать именно эту тему.

7
00:00:40,680 --> 00:00:43,334
Я подозреваю, что причина этого не столько в том, 

8
00:00:43,334 --> 00:00:46,360
что собственные вещи особенно сложны или плохо объяснены.

9
00:00:46,860 --> 00:00:49,155
На самом деле, это сравнительно просто, и я думаю, 

10
00:00:49,155 --> 00:00:51,180
что большинство книг прекрасно объясняют это.

11
00:00:51,520 --> 00:00:54,771
Проблема в том, что это действительно имеет смысл только в том случае, 

12
00:00:54,771 --> 00:00:58,480
если у вас есть четкое визуальное понимание многих тем, которые ему предшествуют.

13
00:00:59,060 --> 00:01:03,677
Самое важное здесь то, что вы умеете воспринимать матрицы как линейные преобразования, 

14
00:01:03,677 --> 00:01:07,710
но вам также необходимо хорошо разбираться в таких вещах, как определители, 

15
00:01:07,710 --> 00:01:09,940
линейные системы уравнений и смена базиса.

16
00:01:10,720 --> 00:01:15,057
Путаница в отношении собственных веществ обычно больше связана с шатким фундаментом 

17
00:01:15,057 --> 00:01:19,240
одной из этих тем, чем с самими собственными векторами и собственными значениями.

18
00:01:19,980 --> 00:01:23,205
Для начала рассмотрим некоторое линейное преобразование в двух измерениях, 

19
00:01:23,205 --> 00:01:24,840
подобное тому, которое показано здесь.

20
00:01:25,460 --> 00:01:31,040
Он перемещает базисный вектор i-hat в координаты 3, 0 и j-hat в координаты 1, 2.

21
00:01:31,780 --> 00:01:35,640
Таким образом, он представлен матрицей, столбцы которой равны 3, 0 и 1, 2.

22
00:01:36,600 --> 00:01:40,022
Сосредоточьтесь на том, что он делает с одним конкретным вектором, 

23
00:01:40,022 --> 00:01:44,160
и подумайте о длине этого вектора, о линии, проходящей через его начало и кончик.

24
00:01:44,920 --> 00:01:48,380
Большинство векторов будут выбиты из своего диапазона во время преобразования.

25
00:01:48,780 --> 00:01:52,050
Я имею в виду, что было бы довольно случайно, если бы место, 

26
00:01:52,050 --> 00:01:55,320
где приземлился вектор, также оказалось где-то на этой линии.

27
00:01:57,400 --> 00:02:00,816
Но некоторые специальные векторы остаются в своем собственном диапазоне, 

28
00:02:00,816 --> 00:02:04,138
а это означает, что эффект, который матрица оказывает на такой вектор, 

29
00:02:04,138 --> 00:02:07,040
заключается в его простом растягивании или сжатии, как скаляр.

30
00:02:09,460 --> 00:02:11,854
В этом конкретном примере базисный вектор i-hat 

31
00:02:11,854 --> 00:02:14,100
является одним из таких специальных векторов.

32
00:02:14,640 --> 00:02:19,846
Диапазон i-hat — это ось X, и из первого столбца матрицы мы видим, 

33
00:02:19,846 --> 00:02:24,120
что i-hat перемещается в 3 раза, все еще на этой оси X.

34
00:02:26,320 --> 00:02:29,724
Более того, из-за того, как работают линейные преобразования, 

35
00:02:29,724 --> 00:02:33,459
любой другой вектор на оси X также просто растягивается в 3 раза и, 

36
00:02:33,459 --> 00:02:36,480
следовательно, остается на своем собственном интервале.

37
00:02:38,500 --> 00:02:41,377
Немного более хитрый вектор, который во время этого преобразования 

38
00:02:41,377 --> 00:02:44,040
остается в своем диапазоне, имеет отрицательное значение 1, 1.

39
00:02:44,660 --> 00:02:47,140
В итоге он растягивается в 2 раза.

40
00:02:49,000 --> 00:02:54,704
И опять же, линейность будет означать, что любой другой вектор на диагональной линии, 

41
00:02:54,704 --> 00:02:58,220
охватываемой этим парнем, просто растянется в 2 раза.

42
00:02:59,820 --> 00:03:02,579
И для этого преобразования это все векторы с особым 

43
00:03:02,579 --> 00:03:05,180
свойством оставаться в пределах своего диапазона.

44
00:03:05,620 --> 00:03:08,583
Те, что по оси X, растягиваются в 3 раза, а те, 

45
00:03:08,583 --> 00:03:11,980
что на этой диагональной линии, растягиваются в 2 раза.

46
00:03:12,760 --> 00:03:16,208
Любой другой вектор будет несколько повернут во время преобразования, 

47
00:03:16,208 --> 00:03:18,080
сбитый с линии, которую он охватывает.

48
00:03:22,520 --> 00:03:26,003
Как вы уже могли догадаться, эти специальные векторы называются 

49
00:03:26,003 --> 00:03:29,868
собственными векторами преобразования, и с каждым собственным вектором 

50
00:03:29,868 --> 00:03:33,787
связано так называемое собственное значение, которое является фактором, 

51
00:03:33,787 --> 00:03:37,380
на который он растягивается или сжимается во время преобразования.

52
00:03:40,280 --> 00:03:43,424
Конечно, нет ничего особенного в растяжении и сжатии или в том факте, 

53
00:03:43,424 --> 00:03:45,940
что эти собственные значения оказываются положительными.

54
00:03:46,380 --> 00:03:50,495
В другом примере у вас может быть собственный вектор с отрицательным собственным 

55
00:03:50,495 --> 00:03:54,662
значением в 1 половину, что означает, что вектор переворачивается и сжимается в 1 

56
00:03:54,662 --> 00:03:55,120
половину.

57
00:03:56,980 --> 00:04:00,459
Но важной частью здесь является то, что он остается на линии, 

58
00:04:00,459 --> 00:04:02,760
по которой проходит, не сворачивая с нее.

59
00:04:04,460 --> 00:04:07,588
Чтобы понять, почему об этом может быть полезно подумать, 

60
00:04:07,588 --> 00:04:09,800
рассмотрим некоторое трехмерное вращение.

61
00:04:11,660 --> 00:04:15,953
Если вы можете найти собственный вектор для этого вращения, вектор, 

62
00:04:15,953 --> 00:04:20,500
который остается на своем собственном участке, то вы нашли ось вращения.

63
00:04:22,600 --> 00:04:26,558
И гораздо проще думать о трехмерном вращении с точки зрения 

64
00:04:26,558 --> 00:04:30,319
некоторой оси вращения и угла, на который оно вращается, 

65
00:04:30,319 --> 00:04:34,740
а не думать о полной матрице 3x3, связанной с этим преобразованием.

66
00:04:37,000 --> 00:04:40,900
В этом случае, кстати, соответствующее собственное значение должно быть равно 1, 

67
00:04:40,900 --> 00:04:43,933
поскольку вращение никогда ничего не растягивает и не сжимает, 

68
00:04:43,933 --> 00:04:45,860
поэтому длина вектора останется прежней.

69
00:04:48,080 --> 00:04:50,020
Эта закономерность часто встречается в линейной алгебре.

70
00:04:50,440 --> 00:04:54,613
При любом линейном преобразовании, описываемом матрицей, вы можете понять, 

71
00:04:54,613 --> 00:04:59,400
что оно делает, прочитав столбцы этой матрицы как точки приземления базисных векторов.

72
00:05:00,020 --> 00:05:03,672
Но зачастую лучший способ понять суть того, что на самом деле делает 

73
00:05:03,672 --> 00:05:07,908
линейное преобразование, менее зависимый от вашей конкретной системы координат, 

74
00:05:07,908 --> 00:05:10,820
— это найти собственные векторы и собственные значения.

75
00:05:15,460 --> 00:05:18,962
Я не буду здесь подробно описывать методы вычисления собственных 

76
00:05:18,962 --> 00:05:23,164
векторов и собственных значений, но попытаюсь дать обзор вычислительных идей, 

77
00:05:23,164 --> 00:05:26,020
которые наиболее важны для концептуального понимания.

78
00:05:27,180 --> 00:05:30,480
Вот как символически выглядит идея собственного вектора.

79
00:05:31,040 --> 00:05:34,135
A — это матрица, представляющая некоторое преобразование, 

80
00:05:34,135 --> 00:05:37,284
с v в качестве собственного вектора, а лямбда — это число, 

81
00:05:37,284 --> 00:05:39,740
а именно соответствующее собственное значение.

82
00:05:40,680 --> 00:05:43,948
Это выражение говорит о том, что произведение матрицы на вектор A, 

83
00:05:43,948 --> 00:05:47,363
умноженное на v, дает тот же результат, что и простое масштабирование 

84
00:05:47,363 --> 00:05:49,900
собственного вектора v на некоторое значение лямбда.

85
00:05:51,000 --> 00:05:55,461
Таким образом, поиск собственных векторов и их собственных значений матрицы 

86
00:05:55,461 --> 00:06:00,100
A сводится к поиску значений v и лямбда, которые делают это выражение истинным.

87
00:06:01,920 --> 00:06:06,281
Поначалу с ним немного неудобно работать, потому что левая часть представляет собой 

88
00:06:06,281 --> 00:06:10,540
умножение матрицы на вектор, а правая часть здесь — умножение на скалярный вектор.

89
00:06:11,120 --> 00:06:14,269
Итак, давайте начнем с того, что перепишем эту правую часть 

90
00:06:14,269 --> 00:06:17,628
как своего рода умножение матрицы на вектор, используя матрицу, 

91
00:06:17,628 --> 00:06:20,620
которая масштабирует любой вектор с коэффициентом лямбда.

92
00:06:21,680 --> 00:06:26,782
Столбцы такой матрицы будут представлять то, что происходит с каждым базисным вектором, 

93
00:06:26,782 --> 00:06:29,913
и каждый базисный вектор просто умножается на лямбда, 

94
00:06:29,913 --> 00:06:34,320
поэтому эта матрица будет иметь число лямбда по диагонали, с нулями повсюду.

95
00:06:36,180 --> 00:06:40,467
Обычный способ написать этого парня — вынести эту лямбду на множитель и записать 

96
00:06:40,467 --> 00:06:44,860
ее как лямбда, умноженную на i, где i — единичная матрица с единицами по диагонали.

97
00:06:45,860 --> 00:06:49,241
Поскольку обе части выглядят как умножение матрицы на вектор, 

98
00:06:49,241 --> 00:06:51,860
мы можем вычесть эту правую часть и исключить v.

99
00:06:54,160 --> 00:06:59,155
Итак, теперь у нас есть новая матрица: A минус лямбда, умноженная на единицу, 

100
00:06:59,155 --> 00:07:04,920
и мы ищем вектор v такой, чтобы эта новая матрица, умноженная на v, давала нулевой вектор.

101
00:07:06,380 --> 00:07:11,100
Это всегда будет верно, если v само по себе является нулевым вектором, но это скучно.

102
00:07:11,340 --> 00:07:13,640
Нам нужен ненулевой собственный вектор.

103
00:07:14,420 --> 00:07:18,410
И если вы посмотрите главы 5 и 6, вы поймете, что единственный способ, 

104
00:07:18,410 --> 00:07:22,400
которым произведение матрицы с ненулевым вектором может стать нулевым, 

105
00:07:22,400 --> 00:07:25,434
— это если преобразование, связанное с этой матрицей, 

106
00:07:25,434 --> 00:07:28,020
сжимает пространство в более низкое измерение.

107
00:07:29,300 --> 00:07:34,220
И это сжатие соответствует нулевому определителю матрицы.

108
00:07:35,480 --> 00:07:40,469
Чтобы быть конкретнее, предположим, что ваша матрица A имеет столбцы 2, 1 и 2, 3, 

109
00:07:40,469 --> 00:07:45,520
и подумайте о вычитании переменной величины, лямбды, из каждой диагональной записи.

110
00:07:46,480 --> 00:07:48,420
Теперь представьте, что вы настраиваете лямбду, 

111
00:07:48,420 --> 00:07:50,280
поворачивая ручку, чтобы изменить ее значение.

112
00:07:50,940 --> 00:07:54,515
По мере изменения этого значения лямбды меняется сама матрица, 

113
00:07:54,515 --> 00:07:57,240
и, следовательно, меняется определитель матрицы.

114
00:07:58,220 --> 00:08:02,525
Цель здесь — найти значение лямбды, при котором этот определитель будет равен нулю, 

115
00:08:02,525 --> 00:08:06,727
а это означает, что измененное преобразование сжимает пространство в более низкое 

116
00:08:06,727 --> 00:08:07,240
измерение.

117
00:08:08,160 --> 00:08:11,160
В этом случае золотая середина наступает, когда лямбда равна 1.

118
00:08:12,180 --> 00:08:14,168
Конечно, если бы мы выбрали какую-то другую матрицу, 

119
00:08:14,168 --> 00:08:16,120
собственное значение не обязательно было бы равно 1.

120
00:08:16,240 --> 00:08:18,600
Золотая середина может быть достигнута при каком-то другом значении лямбды.

121
00:08:20,080 --> 00:08:22,960
Так что это довольно много, но давайте разберемся, о чем идет речь.

122
00:08:22,960 --> 00:08:27,560
Когда лямбда равна 1, матрица A минус лямбда, умноженная на единицу, 

123
00:08:27,560 --> 00:08:29,560
сжимает пространство в строке.

124
00:08:30,440 --> 00:08:34,853
Это означает, что существует ненулевой вектор v такой, что A минус лямбда, 

125
00:08:34,853 --> 00:08:38,559
умноженное на единицу, умноженное на v, равно нулевому вектору.

126
00:08:40,480 --> 00:08:44,295
И помните, причина, по которой нас это волнует, заключается в том, 

127
00:08:44,295 --> 00:08:48,509
что это означает, что A, умноженное на v, равно лямбда, умноженному на v, 

128
00:08:48,509 --> 00:08:53,464
что вы можете прочитать как утверждение, что вектор v является собственным вектором A, 

129
00:08:53,464 --> 00:08:57,280
оставаясь на своем собственном интервале во время преобразования A.

130
00:08:58,320 --> 00:09:01,539
В этом примере соответствующее собственное значение равно 1, 

131
00:09:01,539 --> 00:09:04,020
поэтому v фактически просто останется на месте.

132
00:09:06,220 --> 00:09:08,094
Сделайте паузу и подумайте, нужно ли вам убедиться, 

133
00:09:08,094 --> 00:09:09,500
что эта линия рассуждений вам нравится.

134
00:09:13,380 --> 00:09:15,640
Это то, о чем я упоминал во введении.

135
00:09:16,220 --> 00:09:19,647
Если бы вы не имели четкого представления об определителях и о том, 

136
00:09:19,647 --> 00:09:22,268
почему они связаны с линейными системами уравнений, 

137
00:09:22,268 --> 00:09:26,300
имеющими ненулевые решения, такое выражение выглядело бы совершенно неожиданным.

138
00:09:28,320 --> 00:09:32,155
Чтобы увидеть это в действии, давайте вернемся к примеру с самого начала, 

139
00:09:32,155 --> 00:09:34,540
с матрицей, столбцы которой равны 3, 0 и 1, 2.

140
00:09:35,350 --> 00:09:39,526
Чтобы определить, является ли значение лямбда собственным значением, 

141
00:09:39,526 --> 00:09:43,400
вычтите его из диагоналей этой матрицы и вычислите определитель.

142
00:09:50,580 --> 00:09:54,161
Сделав это, мы получим некий квадратичный многочлен по лямбде, 

143
00:09:54,161 --> 00:09:56,720
3 минус лямбда, умноженный на 2 минус лямбда.

144
00:09:57,800 --> 00:10:01,268
Поскольку лямбда может быть собственным значением только в том случае, 

145
00:10:01,268 --> 00:10:04,003
если этот определитель равен нулю, вы можете заключить, 

146
00:10:04,003 --> 00:10:07,423
что единственными возможными собственными значениями являются лямбда, 

147
00:10:07,423 --> 00:10:08,840
равная 2, и лямбда, равная 3.

148
00:10:09,640 --> 00:10:14,059
Чтобы выяснить, какие собственные векторы на самом деле имеют одно из этих 

149
00:10:14,059 --> 00:10:19,244
собственных значений, скажем, лямбда равна 2, подставьте это значение лямбда в матрицу, 

150
00:10:19,244 --> 00:10:23,900
а затем решите, для каких векторов эта диагонально измененная матрица обнуляет.

151
00:10:24,940 --> 00:10:29,486
Если бы вы вычислили это так же, как и любую другую линейную систему, вы бы увидели, 

152
00:10:29,486 --> 00:10:34,300
что решениями являются все векторы на диагональной линии, натянутые на отрицательные 1, 1.

153
00:10:35,220 --> 00:10:39,270
Это соответствует тому факту, что неизмененная матрица 3, 

154
00:10:39,270 --> 00:10:43,460
0, 1, 2 приводит к растягиванию всех этих векторов в 2 раза.

155
00:10:46,320 --> 00:10:50,200
Теперь двумерное преобразование не обязательно должно иметь собственные векторы.

156
00:10:50,720 --> 00:10:53,400
Например, рассмотрим поворот на 90 градусов.

157
00:10:53,660 --> 00:10:55,835
У него нет собственных векторов, поскольку он 

158
00:10:55,835 --> 00:10:58,200
вращает каждый вектор за пределы своего диапазона.

159
00:11:00,800 --> 00:11:04,244
Если вы действительно попытаетесь вычислить собственные значения вращения таким образом, 

160
00:11:04,244 --> 00:11:05,560
обратите внимание, что произойдет.

161
00:11:06,300 --> 00:11:10,140
Его матрица имеет столбцы 0, 1 и отрицательные 1, 0.

162
00:11:11,100 --> 00:11:15,800
Вычтите лямбду из диагональных элементов и найдите, когда определитель равен нулю.

163
00:11:18,140 --> 00:11:21,940
В этом случае вы получаете квадрат полинома лямбда плюс 1.

164
00:11:22,680 --> 00:11:27,920
Единственными корнями этого многочлена являются мнимые числа i и отрицательное i.

165
00:11:28,840 --> 00:11:31,368
Тот факт, что нет решений в действительных числах, 

166
00:11:31,368 --> 00:11:33,600
указывает на отсутствие собственных векторов.

167
00:11:35,540 --> 00:11:39,820
Еще один довольно интересный пример, который стоит запомнить, — это ножницы.

168
00:11:40,560 --> 00:11:44,564
Это фиксирует i-шляпу на месте и перемещает j-шляпу 1, 

169
00:11:44,564 --> 00:11:47,840
так что ее матрица имеет столбцы 1, 0 и 1, 1.

170
00:11:48,740 --> 00:11:52,393
Все векторы на оси x являются собственными векторами с собственным значением 1, 

171
00:11:52,393 --> 00:11:54,540
поскольку они остаются фиксированными на месте.

172
00:11:55,680 --> 00:11:57,820
Фактически это единственные собственные векторы.

173
00:11:58,760 --> 00:12:03,677
Когда вы вычитаете лямбду из диагоналей и вычисляете определитель, 

174
00:12:03,677 --> 00:12:06,540
вы получаете 1 минус лямбда в квадрате.

175
00:12:09,320 --> 00:12:12,860
И единственный корень этого выражения — лямбда, равная 1.

176
00:12:14,560 --> 00:12:17,090
Это согласуется с тем, что мы видим геометрически: 

177
00:12:17,090 --> 00:12:19,720
все собственные векторы имеют собственное значение 1.

178
00:12:21,080 --> 00:12:25,011
Однако имейте в виду, что также возможно иметь только одно собственное значение, 

179
00:12:25,011 --> 00:12:28,020
но с несколькими линиями, заполненными собственными векторами.

180
00:12:29,900 --> 00:12:33,180
Простой пример — матрица, которая масштабирует все на 2.

181
00:12:33,900 --> 00:12:37,509
Единственное собственное значение — 2, но каждый вектор на плоскости 

182
00:12:37,509 --> 00:12:40,700
становится собственным вектором с этим собственным значением.

183
00:12:42,000 --> 00:12:45,321
Сейчас еще один хороший момент, чтобы сделать паузу и поразмыслить над этим, 

184
00:12:45,321 --> 00:12:46,960
прежде чем я перейду к последней теме.

185
00:13:03,540 --> 00:13:06,530
Я хочу закончить здесь идеей собственного базиса, 

186
00:13:06,530 --> 00:13:09,880
которая во многом опирается на идеи из последнего видео.

187
00:13:11,480 --> 00:13:16,380
Посмотрите, что произойдет, если наши базисные векторы окажутся собственными векторами.

188
00:13:17,120 --> 00:13:22,380
Например, возможно, i-hat масштабируется на минус 1, а j-hat масштабируется на 2.

189
00:13:23,420 --> 00:13:27,444
Записывая их новые координаты в виде столбцов матрицы, обратите внимание, 

190
00:13:27,444 --> 00:13:30,055
что эти скалярные кратные, отрицательные 1 и 2, 

191
00:13:30,055 --> 00:13:33,100
которые являются собственными значениями i-hat и j-hat, 

192
00:13:33,100 --> 00:13:37,180
располагаются на диагонали нашей матрицы, а каждая вторая запись равна 0. .

193
00:13:38,880 --> 00:13:42,379
Каждый раз, когда матрица имеет нули везде, кроме диагонали, 

194
00:13:42,379 --> 00:13:45,420
ее вполне обоснованно называют диагональной матрицей.

195
00:13:45,840 --> 00:13:50,518
И это можно интерпретировать так: все базисные векторы являются собственными векторами, 

196
00:13:50,518 --> 00:13:54,400
а диагональные элементы этой матрицы являются их собственными значениями.

197
00:13:57,100 --> 00:14:01,060
Есть много вещей, которые делают работу с диагональными матрицами намного приятнее.

198
00:14:01,780 --> 00:14:04,990
Одна из самых важных проблем заключается в том, что легче вычислить, 

199
00:14:04,990 --> 00:14:08,340
что произойдет, если вы умножите эту матрицу саму на себя несколько раз.

200
00:14:09,420 --> 00:14:11,782
Поскольку все, что делает одна из этих матриц, 

201
00:14:11,782 --> 00:14:15,652
— это масштабирует каждый базисный вектор на некоторое собственное значение, 

202
00:14:15,652 --> 00:14:18,266
применение этой матрицы много раз, скажем, 100 раз, 

203
00:14:18,266 --> 00:14:21,935
будет просто соответствовать масштабированию каждого базисного вектора в 

204
00:14:21,935 --> 00:14:24,600
100-й степени соответствующего собственного значения.

205
00:14:25,700 --> 00:14:29,680
Напротив, попробуйте вычислить 100-ю степень недиагональной матрицы.

206
00:14:29,680 --> 00:14:31,320
Действительно, попробуйте на минутку.

207
00:14:31,740 --> 00:14:32,440
Это кошмар.

208
00:14:36,080 --> 00:14:41,260
Конечно, вам редко повезет, чтобы ваши базисные векторы были также собственными векторами.

209
00:14:42,040 --> 00:14:45,215
Но если у вашего преобразования много собственных векторов, 

210
00:14:45,215 --> 00:14:48,813
как в начале этого видео, достаточно, чтобы вы могли выбрать набор, 

211
00:14:48,813 --> 00:14:53,258
охватывающий все пространство, тогда вы можете изменить свою систему координат так, 

212
00:14:53,258 --> 00:14:56,540
чтобы эти собственные векторы были вашими базисными векторами.

213
00:14:57,140 --> 00:14:59,696
Я говорил об изменении основы в прошлом видео, 

214
00:14:59,696 --> 00:15:03,069
но здесь я очень быстро напомню, как выразить преобразование, 

215
00:15:03,069 --> 00:15:07,040
записанное в настоящее время в нашей системе координат, в другую систему.

216
00:15:08,440 --> 00:15:12,448
Возьмите координаты векторов, которые вы хотите использовать в качестве новой основы, 

217
00:15:12,448 --> 00:15:15,245
что в данном случае означает два наших собственных вектора, 

218
00:15:15,245 --> 00:15:19,440
затем сделайте эти координаты столбцами матрицы, что называется матрицей изменения базиса.

219
00:15:20,180 --> 00:15:25,599
Когда вы объединяете исходное преобразование, помещая изменение базовой матрицы справа 

220
00:15:25,599 --> 00:15:29,959
и обратную матрицу изменения базиса слева, результатом будет матрица, 

221
00:15:29,959 --> 00:15:35,378
представляющая то же самое преобразование, но с точки зрения координаты новых базисных 

222
00:15:35,378 --> 00:15:36,500
векторов. система.

223
00:15:37,440 --> 00:15:40,606
Весь смысл этого с собственными векторами заключается в том, 

224
00:15:40,606 --> 00:15:45,174
что эта новая матрица гарантированно будет диагональной с соответствующими собственными 

225
00:15:45,174 --> 00:15:46,680
значениями по этой диагонали.

226
00:15:46,860 --> 00:15:50,515
Это связано с тем, что это представляет собой работу в системе координат, 

227
00:15:50,515 --> 00:15:54,320
где с базисными векторами происходит масштабирование во время преобразования.

228
00:15:55,800 --> 00:15:58,918
Набор базисных векторов, которые также являются собственными векторами, 

229
00:15:58,918 --> 00:16:01,560
опять-таки достаточно разумно называется собственным базисом.

230
00:16:02,340 --> 00:16:06,706
Так что, если, например, вам нужно вычислить 100-ю степень этой матрицы, 

231
00:16:06,706 --> 00:16:09,877
было бы гораздо проще перейти к собственному базису, 

232
00:16:09,877 --> 00:16:14,184
вычислить 100-ю степень в этой системе, а затем преобразовать обратно в 

233
00:16:14,184 --> 00:16:15,680
нашу стандартную систему.

234
00:16:16,620 --> 00:16:18,320
Вы не можете сделать это со всеми преобразованиями.

235
00:16:18,320 --> 00:16:21,532
Например, сдвиг не имеет достаточного количества собственных векторов, 

236
00:16:21,532 --> 00:16:22,980
чтобы охватить все пространство.

237
00:16:23,460 --> 00:16:25,693
Но если вы сможете найти собственный базис, это 

238
00:16:25,693 --> 00:16:28,160
сделает матричные операции по-настоящему прекрасными.

239
00:16:29,120 --> 00:16:31,660
Для тех из вас, кто хочет разгадать довольно изящную головоломку, 

240
00:16:31,660 --> 00:16:34,394
чтобы увидеть, как она выглядит в действии и как ее можно использовать 

241
00:16:34,394 --> 00:16:37,320
для получения неожиданных результатов, я оставлю подсказку здесь, на экране.

242
00:16:37,600 --> 00:16:40,280
Это потребует некоторой работы, но я думаю, вам понравится.

243
00:16:40,840 --> 00:16:43,536
Следующее и последнее видео из этой серии будет 

244
00:16:43,536 --> 00:16:46,120
посвящено абстрактным векторным пространствам.

