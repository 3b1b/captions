[
 {
  "input": "Eigenvectors and eigenvalues is one of those topics that a lot of students find particularly unintuitive.",
  "translatedText": "Les vecteurs propres et les valeurs propres font partie de ces sujets que beaucoup d'étudiants trouvent particulièrement peu intuitifs.",
  "from_community_srt": "Les vecteurs propres et valeurs propres est un ces sujets que beaucoup d'étudiants trouvent particulièrement peu intuitifs.",
  "n_reviews": 0,
  "start": 19.92,
  "end": 25.76
 },
 {
  "input": "Questions like, why are we doing this and what does this actually mean, are too often left just floating away in an unanswered sea of computations.",
  "translatedText": "Des questions telles que « pourquoi faisons-nous cela et qu'est-ce que cela signifie réellement » restent trop souvent flottantes dans une mer de calculs sans réponse.",
  "from_community_srt": "Et les question comme \"Pourquoi fait-on ça?\" ou \"Qu'est-ce que ça veut vraiment dire ?\" sont bien trop souvent laissées voguer",
  "n_reviews": 0,
  "start": 25.76,
  "end": 33.26
 },
 {
  "input": "And as I've put out the videos of this series, a lot of you have commented about looking forward to visualizing this topic in particular.",
  "translatedText": "Et au fur et à mesure que j'ai publié les vidéos de cette série, beaucoup d'entre vous ont exprimé leur impatience de visualiser ce sujet en particulier.",
  "from_community_srt": "dans une mer de calculs sans réponse et alors que je postais les vidéos de cette série beaucoup d'entre vous ont commenté qu'ils attendaient avec impatience de pouvoir visualiser ce sujet en particulier.",
  "n_reviews": 0,
  "start": 33.92,
  "end": 40.06
 },
 {
  "input": "I suspect that the reason for this is not so much that eigenthings are particularly complicated or poorly explained.",
  "translatedText": "Je soupçonne que la raison en est pas tant que les choses soient particulièrement compliquées ou mal expliquées.",
  "from_community_srt": "Je soupçonne que la raison pour ceci n'est pas tant que les valeurs propres sont particulièrement compliquées ou mal expliquées.",
  "n_reviews": 0,
  "start": 40.68,
  "end": 46.36
 },
 {
  "input": "In fact, it's comparatively straightforward, and I think most books do a fine job explaining it.",
  "translatedText": "En fait, c’est relativement simple, et je pense que la plupart des livres l’expliquent très bien.",
  "from_community_srt": "A vrai dire, c'est relativement simple et je pense que la plupart des livres l'expliquent plutôt bien.",
  "n_reviews": 0,
  "start": 46.86,
  "end": 51.18
 },
 {
  "input": "The issue is that it only really makes sense if you have a solid visual understanding for many of the topics that precede it.",
  "translatedText": "Le problème est que cela n’a vraiment de sens que si vous avez une solide compréhension visuelle de la plupart des sujets qui le précèdent.",
  "from_community_srt": "Le problème vient du fait que ça n'a vraiment de sens qu'avec une bonne compréhension visuelle d'une grande partie des sujets qui le précèdent.",
  "n_reviews": 0,
  "start": 51.52,
  "end": 58.48
 },
 {
  "input": "Most important here is that you know how to think about matrices as linear transformations, but you also need to be comfortable with things like determinants, linear systems of equations, and change of basis.",
  "translatedText": "Le plus important ici est que vous sachiez considérer les matrices comme des transformations linéaires, mais vous devez également être à l'aise avec des éléments tels que les déterminants, les systèmes d'équations linéaires et le changement de base.",
  "from_community_srt": "Encore plus important ici est de savoir comment conceptualiser des matrices en tant que transformations (applications) linéaires. Mais il est aussi nécessaire d'être à l'aise avec les notions comme le déterminant, les systèmes linéaires d'équations ou le changement de base.",
  "n_reviews": 0,
  "start": 59.06,
  "end": 69.94
 },
 {
  "input": "Confusion about eigenstuffs usually has more to do with a shaky foundation in one of these topics than it does with eigenvectors and eigenvalues themselves.",
  "translatedText": "La confusion à propos des choses propres a généralement plus à voir avec des fondations fragiles dans l'un de ces sujets qu'avec les vecteurs propres et les valeurs propres elles-mêmes.",
  "from_community_srt": "La confusion autour de tout ce qui est \"propre\" vient bien plus de fondations fragiles dans un de ces domaines plutôt qu'avec les vecteurs et valeurs propres mêmes.",
  "n_reviews": 0,
  "start": 70.72,
  "end": 79.24
 },
 {
  "input": "To start, consider some linear transformation in two dimensions, like the one shown here.",
  "translatedText": "Pour commencer, considérons une transformation linéaire en deux dimensions, comme celle présentée ici.",
  "from_community_srt": "Pour débuter, considérons une transformation linéaire en deux dimensions comme celle à l'écran.",
  "n_reviews": 0,
  "start": 79.98,
  "end": 84.84
 },
 {
  "input": "It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2.",
  "translatedText": "Il déplace le vecteur de base i-hat vers les coordonnées 3, 0 et j-hat vers 1, 2.",
  "from_community_srt": "Elle déplace le vecteur de base i-chapeau aux coordonnées [3, 0] et j-chapeau en [1,",
  "n_reviews": 0,
  "start": 85.46,
  "end": 91.04
 },
 {
  "input": "So it's represented with a matrix whose columns are 3, 0, and 1, 2.",
  "translatedText": "Il est donc représenté par une matrice dont les colonnes sont 3, 0 et 1, 2.",
  "from_community_srt": "2] et est donc représentée par une matrice dont les colonnes sont [3,",
  "n_reviews": 0,
  "start": 91.78,
  "end": 95.64
 },
 {
  "input": "Focus in on what it does to one particular vector, and think about the span of that vector, the line passing through its origin and its tip.",
  "translatedText": "Concentrez-vous sur ce qu'il fait à un vecteur particulier et pensez à l'étendue de ce vecteur, à la ligne passant par son origine et sa pointe.",
  "from_community_srt": "0] et [1, 2] Concentrez vous sur ce qu'elle fait à un vecteur en particulier, et visualisez l'espace formé par ce vecteur (noté en français Vect(v)) la droite qui passe par son origine,",
  "n_reviews": 0,
  "start": 96.6,
  "end": 104.16
 },
 {
  "input": "Most vectors are going to get knocked off their span during the transformation.",
  "translatedText": "La plupart des vecteurs vont perdre leur portée pendant la transformation.",
  "from_community_srt": "et son bout. La plupart des vecteurs vont se voir déplacés de leur Vect pendant cette transformation En fait,",
  "n_reviews": 0,
  "start": 104.92,
  "end": 108.38
 },
 {
  "input": "I mean, it would seem pretty coincidental if the place where the vector landed also happened to be somewhere on that line.",
  "translatedText": "Je veux dire, cela semblerait une coïncidence si l'endroit où le vecteur a atterri se trouvait également quelque part sur cette ligne.",
  "from_community_srt": "ça ne serait qu'une coïncidence si l'endroit où le vecteur se retrouve se trouvait être quelque part sur cette droite.",
  "n_reviews": 0,
  "start": 108.78,
  "end": 115.32
 },
 {
  "input": "But some special vectors do remain on their own span, meaning the effect that the matrix has on such a vector is just to stretch it or squish it, like a scalar.",
  "translatedText": "Mais certains vecteurs spéciaux restent sur leur propre étendue, ce qui signifie que l'effet de la matrice sur un tel vecteur est simplement de l'étirer ou de l'écraser, comme un scalaire.",
  "from_community_srt": "Mais certains vecteurs spéciaux restent en effet sur leur Vect ce qui signifie que l'effet de la transformation de la matrice sur un tel vecteur n'est que de l'étirer ou compresser comme un scalaire.",
  "n_reviews": 0,
  "start": 117.4,
  "end": 127.04
 },
 {
  "input": "For this specific example, the basis vector i-hat is one such special vector.",
  "translatedText": "Pour cet exemple spécifique, le vecteur de base i-hat est l’un de ces vecteurs spéciaux.",
  "from_community_srt": "Pour cet exemple en particulier, le vecteur de la base, i-chapeau, est un de ces vecteurs spéciaux.",
  "n_reviews": 0,
  "start": 129.46,
  "end": 134.1
 },
 {
  "input": "The span of i-hat is the x-axis, and from the first column of the matrix, we can see that i-hat moves over to 3 times itself, still on that x-axis.",
  "translatedText": "L'étendue de i-hat est l'axe des x, et à partir de la première colonne de la matrice, nous pouvons voir que i-hat se déplace jusqu'à 3 fois lui-même, toujours sur cet axe des x.",
  "from_community_srt": "Le Vect de i-chapeau est l'axe x et grâce à la première colonne de la matrice nous pouvons deviner que i-chapeau se déplace à 3 fois sa valeur,",
  "n_reviews": 0,
  "start": 134.64,
  "end": 144.12
 },
 {
  "input": "What's more, because of the way linear transformations work, any other vector on the x-axis is also just stretched by a factor of 3, and hence remains on its own span.",
  "translatedText": "De plus, en raison du fonctionnement des transformations linéaires, tout autre vecteur sur l'axe des x est également simplement étiré d'un facteur 3 et reste donc sur sa propre étendue.",
  "from_community_srt": "toujours sur cet axe x. De plus, à cause du fonctionnement des transformations linéaires, n'importe quel autre vecteur de l'axe x n'est aussi qu'étiré d'un facteur 3, et, ainsi,",
  "n_reviews": 0,
  "start": 146.32,
  "end": 156.48
 },
 {
  "input": "A slightly sneakier vector that remains on its own span during this transformation is negative 1, 1.",
  "translatedText": "Un vecteur légèrement plus sournois qui reste sur sa propre étendue pendant cette transformation est moins 1, 1.",
  "from_community_srt": "reste sur son propre Vect. Un autre vecteur, légèrement plus fourbe, qui reste sur son propre Vect pendant cette transformation est [-1,",
  "n_reviews": 0,
  "start": 158.5,
  "end": 164.04
 },
 {
  "input": "It ends up getting stretched by a factor of 2.",
  "translatedText": "Il finit par être étiré d'un facteur 2.",
  "from_community_srt": "1] Il finit par être étiré d'un facteur 2.",
  "n_reviews": 0,
  "start": 164.66,
  "end": 167.14
 },
 {
  "input": "And again, linearity is going to imply that any other vector on the diagonal line spanned by this guy is just going to get stretched out by a factor of 2.",
  "translatedText": "Et encore une fois, la linéarité impliquera que tout autre vecteur sur la diagonale parcourue par ce type sera simplement étiré d'un facteur 2.",
  "from_community_srt": "Et de nouveau, la linéarité va impliquer que n'importe quel autre vecteur de cette ligne diagonale générée par ce vecteur ([-1, 1]) va simplement se voir étirer d'un facteur 2.",
  "n_reviews": 0,
  "start": 169.0,
  "end": 178.22
 },
 {
  "input": "And for this transformation, those are all the vectors with this special property of staying on their span.",
  "translatedText": "Et pour cette transformation, ce sont tous les vecteurs qui ont cette propriété particulière de rester sur leur portée.",
  "from_community_srt": "Et pour cette transformation, ce sont les seuls vecteurs avec cette propriété particulière de rester sur leur Vect.",
  "n_reviews": 0,
  "start": 179.82,
  "end": 185.18
 },
 {
  "input": "Those on the x-axis getting stretched out by a factor of 3, and those on this diagonal line getting stretched by a factor of 2.",
  "translatedText": "Ceux sur l'axe des x sont étirés d'un facteur 3, et ceux sur cette ligne diagonale sont étirés d'un facteur 2.",
  "from_community_srt": "Ceux sur l'axe x, étirés d'un facteur 3, et ceux sur cette diagonale, étirés d'un facteur 2.",
  "n_reviews": 0,
  "start": 185.62,
  "end": 191.98
 },
 {
  "input": "Any other vector is going to get rotated somewhat during the transformation, knocked off the line that it spans.",
  "translatedText": "Tout autre vecteur va subir une légère rotation pendant la transformation, et être retiré de la ligne qu'il couvre.",
  "from_community_srt": "N'importe quel autre vecteur se verra subir une rotation, d'une manière ou d'une autre, par cette transformation; dégagé de la droite qu'il a généré.",
  "n_reviews": 0,
  "start": 192.76,
  "end": 198.08
 },
 {
  "input": "As you might have guessed by now, these special vectors are called the eigenvectors of the transformation, and each eigenvector has associated with it what's called an eigenvalue, which is just the factor by which it's stretched or squished during the transformation.",
  "translatedText": "Comme vous l'avez peut-être deviné maintenant, ces vecteurs spéciaux sont appelés vecteurs propres de la transformation, et chaque vecteur propre est associé à ce qu'on appelle une valeur propre, qui est simplement le facteur par lequel il est étiré ou écrasé pendant la transformation.",
  "from_community_srt": "Comme vous avez peut-être pu le deviner, ces vecteurs spéciaux sont appelés \"vecteurs propres\" de la transformation, et chaque vecteur propre est associé à ce qu'on appelle une \"valeur propre\", qui n'est que le facteur par lequel il est étiré ou compressé pendant la transformation.",
  "n_reviews": 0,
  "start": 202.52,
  "end": 217.38
 },
 {
  "input": "Of course, there's nothing special about stretching versus squishing, or the fact that these eigenvalues happen to be positive.",
  "translatedText": "Bien sûr, il n'y a rien de spécial entre l'étirement et l'écrasement, ou le fait que ces valeurs propres se révèlent positives.",
  "from_community_srt": "Bien évidemment, il n'importe pas du tout d'étirer ou compresser; ou encore que les valeurs propres s'avèrent être positives:",
  "n_reviews": 0,
  "start": 220.28,
  "end": 225.94
 },
 {
  "input": "In another example, you could have an eigenvector with eigenvalue negative 1 half, meaning that the vector gets flipped and squished by a factor of 1 half.",
  "translatedText": "Dans un autre exemple, vous pourriez avoir un vecteur propre avec une valeur propre négative de 1 moitié, ce qui signifie que le vecteur est inversé et écrasé d'un facteur de 1 moitié.",
  "from_community_srt": "dans un autre exemple il est possible de trouver un vecteur propre avec un valeur propre associée de -1/2 ce qui signifie que le vecteur est retourné et compressé d'un facteur d'1/2 Mais l'important ici",
  "n_reviews": 0,
  "start": 226.38,
  "end": 235.12
 },
 {
  "input": "But the important part here is that it stays on the line that it spans out without getting rotated off of it.",
  "translatedText": "Mais ce qui est important ici, c'est qu'il reste sur la ligne qu'il s'étend sans en sortir.",
  "from_community_srt": "est qu'il reste sur la droite qu'il a généré sans se voir la quitter par rotation.",
  "n_reviews": 0,
  "start": 236.98,
  "end": 242.76
 },
 {
  "input": "For a glimpse of why this might be a useful thing to think about, consider some three-dimensional rotation.",
  "translatedText": "Pour avoir un aperçu de la raison pour laquelle cela pourrait être une chose utile à considérer, envisagez une rotation tridimensionnelle.",
  "from_community_srt": "Pour apercevoir pourquoi cela pourrait être une bonne chose à réaliser, visualisez une rotation tri-dimensionnelle.",
  "n_reviews": 0,
  "start": 244.46,
  "end": 249.8
 },
 {
  "input": "If you can find an eigenvector for that rotation, a vector that remains on its own span, what you have found is the axis of rotation.",
  "translatedText": "Si vous pouvez trouver un vecteur propre pour cette rotation, un vecteur qui reste sur sa propre étendue, ce que vous avez trouvé est l'axe de rotation.",
  "from_community_srt": "Si vous pouvez trouver un vecteur propre pour cette rotation, un vecteur qui reste sur son Vect (TN: rappel:",
  "n_reviews": 0,
  "start": 251.66,
  "end": 260.5
 },
 {
  "input": "And it's much easier to think about a 3D rotation in terms of some axis of rotation and an angle by which it's rotating, rather than thinking about the full 3x3 matrix associated with that transformation.",
  "translatedText": "Et il est beaucoup plus facile de penser à une rotation 3D en termes d'un axe de rotation et d'un angle de rotation, plutôt que de penser à la matrice 3x3 complète associée à cette transformation.",
  "from_community_srt": "la droite qu'il génère) ce que vous avez trouvé est l'axe de la rotation Et il est bien plus simple de visualiser une rotation en 3D via un axe de rotation et un angle qui donne la rotation plutôt que de penser à la matrice 3x3 complète associée à cette transformation.",
  "n_reviews": 0,
  "start": 262.6,
  "end": 274.74
 },
 {
  "input": "In this case, by the way, the corresponding eigenvalue would have to be 1, since rotations never stretch or squish anything, so the length of the vector would remain the same.",
  "translatedText": "Dans ce cas, d'ailleurs, la valeur propre correspondante devrait être 1, puisque les rotations ne s'étirent ni n'écrasent jamais quoi que ce soit, donc la longueur du vecteur resterait la même.",
  "from_community_srt": "Dans ce cas, d'ailleurs, la valeur propre correspondante devra être 1, puisque les rotations n'étirent ou ne compressent rien, donc la longueur (norme) du vecteur va rester la même.",
  "n_reviews": 0,
  "start": 277.0,
  "end": 285.86
 },
 {
  "input": "This pattern shows up a lot in linear algebra.",
  "translatedText": "Ce modèle apparaît souvent en algèbre linéaire.",
  "n_reviews": 0,
  "start": 288.08,
  "end": 290.02
 },
 {
  "input": "With any linear transformation described by a matrix, you could understand what it's doing by reading off the columns of this matrix as the landing spots for basis vectors.",
  "translatedText": "Avec toute transformation linéaire décrite par une matrice, vous pouvez comprendre ce qu'elle fait en lisant les colonnes de cette matrice comme points d'atterrissage pour les vecteurs de base.",
  "from_community_srt": "Ce schéma de pensée est très récurrent en algèbre linéaire: avec n'importe quelle transformation linéaire décrite par une matrice, il est possible de visualiser ce qu'elle fait en lisant les colonnes de cette matrice en tant que points d'arrivée des vecteurs de la base;",
  "n_reviews": 0,
  "start": 290.44,
  "end": 299.4
 },
 {
  "input": "But often, a better way to get at the heart of what the linear transformation actually does, less dependent on your particular coordinate system, is to find the eigenvectors and eigenvalues.",
  "translatedText": "Mais souvent, une meilleure façon d'aller au cœur de ce que fait réellement la transformation linéaire, moins dépendante de votre système de coordonnées particulier, est de trouver les vecteurs propres et les valeurs propres.",
  "from_community_srt": "mais bien souvent une meilleure manière de saisir ce que votre transformation fait réellement, indépendamment de votre système de coordonnées, est de trouver les vecteurs et valeurs propres.",
  "n_reviews": 0,
  "start": 300.02,
  "end": 310.82
 },
 {
  "input": "I won't cover the full details on methods for computing eigenvectors and eigenvalues here, but I'll try to give an overview of the computational ideas that are most important for a conceptual understanding.",
  "translatedText": "Je ne couvrirai pas ici tous les détails sur les méthodes de calcul des vecteurs propres et des valeurs propres, mais je vais essayer de donner un aperçu des idées informatiques les plus importantes pour une compréhension conceptuelle.",
  "from_community_srt": "Je ne détaillerai pas tous les détails des méthodes de calcul des vecteurs et valeurs propres ici, mais je vais essayer de donner une idée générale des principes calculatoires qui sont essentiels pour une compréhension conceptuelle.",
  "n_reviews": 0,
  "start": 315.46,
  "end": 326.02
 },
 {
  "input": "Symbolically, here's what the idea of an eigenvector looks like.",
  "translatedText": "Symboliquement, voici à quoi ressemble l'idée d'un vecteur propre.",
  "from_community_srt": "D'un point de vue symbolique, voilà ce à quoi ressemble un vecteur propre.",
  "n_reviews": 0,
  "start": 327.18,
  "end": 330.48
 },
 {
  "input": "A is the matrix representing some transformation, with v as the eigenvector, and lambda is a number, namely the corresponding eigenvalue.",
  "translatedText": "A est la matrice représentant une transformation, avec v comme vecteur propre, et lambda est un nombre, à savoir la valeur propre correspondante.",
  "from_community_srt": "A est la matrice représentant votre transformation avec v le vecteur propre et λ un nombre, par définition la valeur propre correspondante.",
  "n_reviews": 0,
  "start": 331.04,
  "end": 339.74
 },
 {
  "input": "What this expression is saying is that the matrix-vector product, A times v, gives the same result as just scaling the eigenvector v by some value lambda.",
  "translatedText": "Ce que dit cette expression, c'est que le produit matrice-vecteur, A fois v, donne le même résultat qu'une simple mise à l'échelle du vecteur propre v par une certaine valeur lambda.",
  "from_community_srt": "Ce que cette expression annonce est que le produit matrice-vecteur A.v donne le même résultat que simplement multiplier le vecteur propre v par un scalaire λ.",
  "n_reviews": 0,
  "start": 340.68,
  "end": 349.9
 },
 {
  "input": "So finding the eigenvectors and their eigenvalues of a matrix A comes down to finding the values of v and lambda that make this expression true.",
  "translatedText": "Ainsi, trouver les vecteurs propres et leurs valeurs propres d'une matrice A revient à trouver les valeurs de v et lambda qui rendent cette expression vraie.",
  "from_community_srt": "Ainsi trouve les vecteurs et valeurs propres d'un matrice A revient à trouver les valeurs de v et λ qui vérifient cette équation.",
  "n_reviews": 0,
  "start": 351.0,
  "end": 360.1
 },
 {
  "input": "It's a little awkward to work with at first, because that left-hand side represents matrix-vector multiplication, but the right-hand side here is scalar-vector multiplication.",
  "translatedText": "C'est un peu difficile à utiliser au début, car le côté gauche représente la multiplication matrice-vecteur, mais le côté droit ici est la multiplication scalaire-vecteur.",
  "from_community_srt": "C'est un assez inconfortable de travailler avec, au début, car ce membre de gauche représente une multiplication matrice-vecteur tandis que le membre de droite est une multiplication scalaire-vecteur.",
  "n_reviews": 0,
  "start": 361.92,
  "end": 370.54
 },
 {
  "input": "So let's start by rewriting that right-hand side as some kind of matrix-vector multiplication, using a matrix which has the effect of scaling any vector by a factor of lambda.",
  "translatedText": "Commençons donc par réécrire ce membre de droite comme une sorte de multiplication matrice-vecteur, en utilisant une matrice qui a pour effet de mettre à l'échelle n'importe quel vecteur par un facteur lambda.",
  "from_community_srt": "Donc, commençons par reformuler ce membre de droite en une multiplication matrice-vecteur, en utilisant une matrice qui a comme effet de multiplier n'importe quel vecteur par un facteur λ.",
  "n_reviews": 0,
  "start": 371.12,
  "end": 380.62
 },
 {
  "input": "The columns of such a matrix will represent what happens to each basis vector, and each basis vector is simply multiplied by lambda, so this matrix will have the number lambda down the diagonal, with zeros everywhere else.",
  "translatedText": "Les colonnes d'une telle matrice représenteront ce qui arrive à chaque vecteur de base, et chaque vecteur de base est simplement multiplié par lambda, donc cette matrice aura le nombre lambda sur la diagonale, avec des zéros partout ailleurs.",
  "from_community_srt": "Les colonnes d'une telle matrice vont représenter ce qui advient de chaque vecteur de la base et chaque vecteur de la base est simplement multiplié par λ donc cette matrice aura le nombre λ le long de la diagonale, et des 0s partout ailleurs.",
  "n_reviews": 0,
  "start": 381.68,
  "end": 394.32
 },
 {
  "input": "The common way to write this guy is to factor that lambda out and write it as lambda times i, where i is the identity matrix with 1s down the diagonal.",
  "translatedText": "La façon courante d'écrire ce type est de prendre en compte ce lambda et de l'écrire sous la forme lambda fois i, où i est la matrice d'identité avec des 1 sur la diagonale.",
  "from_community_srt": "La manière habituelle d'écrire ceci est de mettre ce λ en facteur et de l'écrire comme λ.I où I représente la matrice identité, avec des 1s le long de la diagonale.",
  "n_reviews": 0,
  "start": 396.18,
  "end": 404.86
 },
 {
  "input": "With both sides looking like matrix-vector multiplication, we can subtract off that right-hand side and factor out the v.",
  "translatedText": "Les deux côtés ressemblant à une multiplication matrice-vecteur, nous pouvons soustraire ce côté droit et factoriser le v.",
  "from_community_srt": "Avec chaque côté comme expression d'une multiplication matrice-vecteur, nous pouvons soustraire le membre de droite et mettre le vecteur v en facteur.",
  "n_reviews": 0,
  "start": 405.86,
  "end": 411.86
 },
 {
  "input": "So what we now have is a new matrix, A minus lambda times the identity, and we're looking for a vector v such that this new matrix times v gives the zero vector.",
  "translatedText": "Nous avons donc maintenant une nouvelle matrice, A moins lambda fois l'identité, et nous recherchons un vecteur v tel que cette nouvelle matrice multipliée par v donne le vecteur zéro.",
  "from_community_srt": "Donc ce que nous avons à présent est une nouvelle matrice, A-λ.I, Et nous cherchons un vecteur v afin que (cette nouvelle matrice).v = vecteur nul.",
  "n_reviews": 0,
  "start": 414.16,
  "end": 424.92
 },
 {
  "input": "Now, this will always be true if v itself is the zero vector, but that's boring.",
  "translatedText": "Maintenant, cela sera toujours vrai si v lui-même est le vecteur zéro, mais c'est ennuyeux.",
  "from_community_srt": "Bon, ceci sera toujours vrai si le vecteur v lui-même est le vecteur nul mais.. on s'en fout.",
  "n_reviews": 0,
  "start": 426.38,
  "end": 431.1
 },
 {
  "input": "What we want is a non-zero eigenvector.",
  "translatedText": "Ce que nous voulons, c'est un vecteur propre non nul.",
  "from_community_srt": "Ce que l'on veut est un vecteur propre,",
  "n_reviews": 0,
  "start": 431.34,
  "end": 433.64
 },
 {
  "input": "And if you watch chapter 5 and 6, you'll know that the only way it's possible for the product of a matrix with a non-zero vector to become zero is if the transformation associated with that matrix squishes space into a lower dimension.",
  "translatedText": "Et si vous regardez les chapitres 5 et 6, vous saurez que la seule façon pour le produit d'une matrice avec un vecteur non nul de devenir nul est si la transformation associée à cette matrice écrase l'espace dans une dimension inférieure.",
  "from_community_srt": "non nul. Et si vous avez regardé les chapitres 5 et 6 vous devez savoir que la seule façon envisageable, pour un produit d'un matrice avec un vecteur non nul, d'être le vecteur nul, est que la transformation associée à cette matrice compresse l'espace en une dimension inférieure.",
  "n_reviews": 0,
  "start": 434.42,
  "end": 448.02
 },
 {
  "input": "And that squishification corresponds to a zero determinant for the matrix.",
  "translatedText": "Et cette squishification correspond à un déterminant nul pour la matrice.",
  "from_community_srt": "Et cette compression correspond à un déterminant égal à 0 pour la matrice.",
  "n_reviews": 0,
  "start": 449.3,
  "end": 454.22
 },
 {
  "input": "To be concrete, let's say your matrix A has columns 2, 1 and 2, 3, and think about subtracting off a variable amount, lambda, from each diagonal entry.",
  "translatedText": "Pour être concret, disons que votre matrice A comporte les colonnes 2, 1 et 2, 3, et pensez à soustraire un montant variable, lambda, de chaque entrée diagonale.",
  "from_community_srt": "Plus concrètement, disons que la matrice A a pour colonnes [2, 1] et [2, 3] et imaginez soustraire une quantité variable λ pour chaque entrée en diagonale.",
  "n_reviews": 0,
  "start": 455.48,
  "end": 465.52
 },
 {
  "input": "Now imagine tweaking lambda, turning a knob to change its value.",
  "translatedText": "Imaginez maintenant que vous modifiez lambda, en tournant un bouton pour modifier sa valeur.",
  "from_community_srt": "A présent imaginez faire varier λ bouger légèrement pour changer sa valeur, et tandis que la valeur de λ change,",
  "n_reviews": 0,
  "start": 466.48,
  "end": 470.28
 },
 {
  "input": "As that value of lambda changes, the matrix itself changes, and so the determinant of the matrix changes.",
  "translatedText": "À mesure que cette valeur de lambda change, la matrice elle-même change, et donc le déterminant de la matrice change.",
  "from_community_srt": "la matrice elle-même est modifiée et donc le déterminant de la matrice change.",
  "n_reviews": 0,
  "start": 470.94,
  "end": 477.24
 },
 {
  "input": "The goal here is to find a value of lambda that will make this determinant zero, meaning the tweaked transformation squishes space into a lower dimension.",
  "translatedText": "Le but ici est de trouver une valeur de lambda qui rendra ce déterminant nul, ce qui signifie que la transformation modifiée écrase l'espace dans une dimension inférieure.",
  "from_community_srt": "Notre but ici sera de trouver la valeur de λ qui rendra ce déterminant nul. Ce qui signifie que la transformation, modifiée, compresse l'espace dans une dimension inférieure.",
  "n_reviews": 0,
  "start": 478.22,
  "end": 487.24
 },
 {
  "input": "In this case, the sweet spot comes when lambda equals 1.",
  "translatedText": "Dans ce cas, le point idéal survient lorsque lambda est égal à 1.",
  "from_community_srt": "Dans le cas à l'écran, le point clé est quand λ=1.",
  "n_reviews": 0,
  "start": 488.16,
  "end": 491.16
 },
 {
  "input": "Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1.",
  "translatedText": "Bien entendu, si nous avions choisi une autre matrice, la valeur propre ne serait pas nécessairement 1.",
  "from_community_srt": "Évidemment, si non avions choisi une autre matrice la valeur propre ne sera pas nécessairement 1, le point clé arrivant pour une autre valeur de λ.",
  "n_reviews": 0,
  "start": 492.18,
  "end": 496.12
 },
 {
  "input": "The sweet spot might be hit at some other value of lambda.",
  "translatedText": "Le point idéal pourrait être atteint à une autre valeur de lambda.",
  "n_reviews": 0,
  "start": 496.24,
  "end": 498.6
 },
 {
  "input": "So this is kind of a lot, but let's unravel what this is saying.",
  "translatedText": "C'est donc beaucoup, mais voyons ce que cela veut dire.",
  "from_community_srt": "Donc - ça fait beaucoup, mais déroulons ce que cela veut dire.",
  "n_reviews": 0,
  "start": 500.08,
  "end": 502.96
 },
 {
  "input": "When lambda equals 1, the matrix A minus lambda times the identity squishes space onto a line.",
  "translatedText": "Lorsque lambda est égal à 1, la matrice A moins lambda multipliée par l'identité écrase l'espace sur une ligne.",
  "from_community_srt": "Quand λ=1, la matrice A-λ.I compresse l'espace en une droite.",
  "n_reviews": 0,
  "start": 502.96,
  "end": 509.56
 },
 {
  "input": "That means there's a non-zero vector v such that A minus lambda times the identity times v equals the zero vector.",
  "translatedText": "Cela signifie qu'il existe un vecteur v non nul tel que A moins lambda fois l'identité fois v est égal au vecteur zéro.",
  "from_community_srt": "Ce qui signifie qu'il y a un vecteur v non nul tel que (A-λ.I).v est égal au vecteur nul.",
  "n_reviews": 0,
  "start": 510.44,
  "end": 518.56
 },
 {
  "input": "And remember, the reason we care about that is because it means A times v equals lambda times v, which you can read off as saying that the vector v is an eigenvector of A, staying on its own span during the transformation A.",
  "translatedText": "Et rappelez-vous, la raison pour laquelle nous nous soucions de cela est que cela signifie que A fois v est égal à lambda fois v, ce que vous pouvez lire comme disant que le vecteur v est un vecteur propre de A, restant sur sa propre étendue pendant la transformation A.",
  "from_community_srt": "Et souvenez-vous: la raison pour laquelle nous cherchions ceci était car cela signifie que A.v=λ.v Ce que vous pouvez lire comme \"le vecteur v est un vecteur propre de A.\", restant sur son propre Vect pendant la transformation A.",
  "n_reviews": 0,
  "start": 520.48,
  "end": 537.28
 },
 {
  "input": "In this example, the corresponding eigenvalue is 1, so v would actually just stay fixed in place.",
  "translatedText": "Dans cet exemple, la valeur propre correspondante est 1, donc v resterait simplement fixe en place.",
  "from_community_srt": "Sur cet exemple, la valeur propre associée est 1, donc v resterait en fait au même endroit.",
  "n_reviews": 0,
  "start": 538.32,
  "end": 544.02
 },
 {
  "input": "Pause and ponder if you need to make sure that that line of reasoning feels good.",
  "translatedText": "Faites une pause et réfléchissez si vous devez vous assurer que ce raisonnement vous convient.",
  "from_community_srt": "Faites un pause et réfléchissez-y si nécessaire pour vous assurer que ce raisonnement est bien logique.",
  "n_reviews": 0,
  "start": 546.22,
  "end": 549.5
 },
 {
  "input": "This is the kind of thing I mentioned in the introduction.",
  "translatedText": "C'est le genre de chose que j'ai mentionné dans l'introduction.",
  "n_reviews": 0,
  "start": 553.38,
  "end": 555.64
 },
 {
  "input": "If you didn't have a solid grasp of determinants and why they relate to linear systems of equations having non-zero solutions, an expression like this would feel completely out of the blue.",
  "translatedText": "Si vous n'aviez pas une solide compréhension des déterminants et de la raison pour laquelle ils se rapportent à des systèmes d'équations linéaires ayant des solutions non nulles, une expression comme celle-ci semblerait complètement inattendue.",
  "from_community_srt": "C'est ce dont j'ai parlé dans l'introduction: si vous n'avez pas une solide compréhension des déterminants et de la raison pour laquelle ils interviennent dans les système linéaires d'équations ayant des solutions non nulles, une telle expression semblerait complètement sortie de nulle part Pour visualiser tout cela en action,",
  "n_reviews": 0,
  "start": 556.22,
  "end": 566.3
 },
 {
  "input": "To see this in action, let's revisit the example from the start, with a matrix whose columns are 3, 0 and 1, 2.",
  "translatedText": "Pour voir cela en action, reprenons l'exemple du début, avec une matrice dont les colonnes sont 3, 0 et 1, 2.",
  "from_community_srt": "revoyons l'exemple depuis le début. Avec la matrice de colonnes [3,",
  "n_reviews": 0,
  "start": 568.32,
  "end": 574.54
 },
 {
  "input": "To find if a value lambda is an eigenvalue, subtract it from the diagonals of this matrix and compute the determinant.",
  "translatedText": "Pour savoir si une valeur lambda est une valeur propre, soustrayez-la des diagonales de cette matrice et calculez le déterminant.",
  "from_community_srt": "0] et [1,2], pour savoir si λ est une valeur propre soustrayez-la aux diagonales de la matrice et calculez le déterminant.",
  "n_reviews": 0,
  "start": 575.35,
  "end": 583.4
 },
 {
  "input": "Doing this, we get a certain quadratic polynomial in lambda, 3 minus lambda times 2 minus lambda.",
  "translatedText": "En faisant cela, nous obtenons un certain polynôme quadratique en lambda, 3 moins lambda fois 2 moins lambda.",
  "from_community_srt": "En faisant ceci, nous obtenons un certain polynôme quadratique en λ (3-λ).(2-λ) Puisque λ ne peut être une valeur propre",
  "n_reviews": 0,
  "start": 590.58,
  "end": 596.72
 },
 {
  "input": "Since lambda can only be an eigenvalue if this determinant happens to be zero, you can conclude that the only possible eigenvalues are lambda equals 2 and lambda equals 3.",
  "translatedText": "Puisque lambda ne peut être une valeur propre que si ce déterminant est nul, vous pouvez conclure que les seules valeurs propres possibles sont lambda égale à 2 et lambda égale à 3.",
  "from_community_srt": "que si le déterminant est nul, vous pouvez conclure que les seules valeurs propres possibles sont λ=2 et λ=3.",
  "n_reviews": 0,
  "start": 597.8,
  "end": 608.84
 },
 {
  "input": "To figure out what the eigenvectors are that actually have one of these eigenvalues, say lambda equals 2, plug in that value of lambda to the matrix and then solve for which vectors this diagonally altered matrix sends to zero.",
  "translatedText": "Pour déterminer quels sont les vecteurs propres qui ont réellement l'une de ces valeurs propres, disons que lambda est égal à 2, branchez cette valeur de lambda à la matrice, puis déterminez pour quels vecteurs cette matrice modifiée en diagonale envoie à zéro.",
  "from_community_srt": "Pour déterminer les vecteurs propres, qui sont associés à une de ces valeurs propres, disons, λ=2, entrez cette valeur de λ dans la matrice puis résolvez pour quels vecteurs cette matrice à diagonale modifiée déplace au vecteur nul.",
  "n_reviews": 0,
  "start": 609.64,
  "end": 623.9
 },
 {
  "input": "If you computed this the way you would any other linear system, you'd see that the solutions are all the vectors on the diagonal line spanned by negative 1, 1.",
  "translatedText": "Si vous calculiez cela comme vous le feriez avec n'importe quel autre système linéaire, vous verriez que les solutions sont tous les vecteurs sur la diagonale engendrée par moins 1, 1.",
  "from_community_srt": "Si vous calculiez ceci comme n'importe quel autre système linéaire, vous verriez que les solutions sont l'ensemble des vecteurs de la ligne diagonale générée par [-1,",
  "n_reviews": 0,
  "start": 624.94,
  "end": 634.3
 },
 {
  "input": "This corresponds to the fact that the unaltered matrix, 3, 0, 1, 2, has the effect of stretching all those vectors by a factor of 2.",
  "translatedText": "Cela correspond au fait que la matrice inchangée, 3, 0, 1, 2, a pour effet d'étirer tous ces vecteurs d'un facteur 2.",
  "from_community_srt": "1] {Vect([-1, 1])} Cela revient à dire que la matrice non modifiée [3, 0; 1, 2] a pour effet d'étirer tous ces vecteurs par un facteur 2.",
  "n_reviews": 0,
  "start": 635.22,
  "end": 643.46
 },
 {
  "input": "Now, a 2D transformation doesn't have to have eigenvectors.",
  "translatedText": "Désormais, une transformation 2D n'a pas besoin d'avoir de vecteurs propres.",
  "from_community_srt": "Cependant une transformation 2D n'a pas nécessairement de vecteurs propres.",
  "n_reviews": 0,
  "start": 646.32,
  "end": 650.2
 },
 {
  "input": "For example, consider a rotation by 90 degrees.",
  "translatedText": "Par exemple, considérons une rotation de 90 degrés.",
  "from_community_srt": "Par exemple,",
  "n_reviews": 0,
  "start": 650.72,
  "end": 653.4
 },
 {
  "input": "This doesn't have any eigenvectors since it rotates every vector off of its own span.",
  "translatedText": "Cela n'a pas de vecteurs propres puisqu'il fait pivoter chaque vecteur hors de sa propre étendue.",
  "from_community_srt": "visualisez une rotation de 90°: elle n'a aucun vecteur propre,",
  "n_reviews": 0,
  "start": 653.66,
  "end": 658.2
 },
 {
  "input": "If you actually try computing the eigenvalues of a rotation like this, notice what happens.",
  "translatedText": "Si vous essayez réellement de calculer les valeurs propres d’une rotation comme celle-ci, remarquez ce qui se passe.",
  "from_community_srt": "puisqu'elle fait tourner chaque vecteur en dehors de son Vect Si vous essayiez de calculer les valeurs propres d'une telle rotation,",
  "n_reviews": 0,
  "start": 660.8,
  "end": 665.56
 },
 {
  "input": "Its matrix has columns 0, 1 and negative 1, 0.",
  "translatedText": "Sa matrice comporte les colonnes 0, 1 et moins 1, 0.",
  "from_community_srt": "remarquez ce qu'il arriverait: sa matrice a pour colonnes [0, -1] et [-1,",
  "n_reviews": 0,
  "start": 666.3,
  "end": 670.14
 },
 {
  "input": "Subtract off lambda from the diagonal elements and look for when the determinant is zero.",
  "translatedText": "Soustrayez lambda des éléments diagonaux et recherchez quand le déterminant est zéro.",
  "from_community_srt": "0] soustrayez λ à la diagonale et cherchez les valeurs qui donnent un déterminant nul.",
  "n_reviews": 0,
  "start": 671.1,
  "end": 675.8
 },
 {
  "input": "In this case, you get the polynomial lambda squared plus 1.",
  "translatedText": "Dans ce cas, vous obtenez le polynôme lambda au carré plus 1.",
  "from_community_srt": "Dans ce cas,",
  "n_reviews": 0,
  "start": 678.14,
  "end": 681.94
 },
 {
  "input": "The only roots of that polynomial are the imaginary numbers, i and negative i.",
  "translatedText": "Les seules racines de ce polynôme sont les nombres imaginaires i et i négatif.",
  "from_community_srt": "vous obtenez le polynôme λ²+1 les seules racines de ce polynôme sont les nombres imaginaires i et -i",
  "n_reviews": 0,
  "start": 682.68,
  "end": 687.92
 },
 {
  "input": "The fact that there are no real number solutions indicates that there are no eigenvectors.",
  "translatedText": "Le fait qu’il n’y ait pas de solutions numériques réelles indique qu’il n’y a pas de vecteurs propres.",
  "from_community_srt": "Le fait qu'il n'y ait pas de solution réelle indique qu'il n'y a pas de vecteur propre.",
  "n_reviews": 0,
  "start": 688.84,
  "end": 693.6
 },
 {
  "input": "Another pretty interesting example worth holding in the back of your mind is a shear.",
  "translatedText": "Un autre exemple assez intéressant qui mérite d’être gardé à l’esprit est une cisaille.",
  "from_community_srt": "Un autre exemple assez intéressant qui mérite d'être retenu, est la transvection.",
  "n_reviews": 0,
  "start": 695.54,
  "end": 699.82
 },
 {
  "input": "This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1.",
  "translatedText": "Cela fixe i-hat en place et déplace j-hat 1, de sorte que sa matrice a les colonnes 1, 0 et 1, 1.",
  "from_community_srt": "Ceci conserve la position de i-chapeau et déplace j-chapeau de 1 (horizontalement) donc sa matrice a pour colonnes [1,",
  "n_reviews": 0,
  "start": 700.56,
  "end": 707.84
 },
 {
  "input": "All of the vectors on the x-axis are eigenvectors with eigenvalue 1 since they remain fixed in place.",
  "translatedText": "Tous les vecteurs sur l'axe des x sont des vecteurs propres de valeur propre 1 puisqu'ils restent fixes.",
  "from_community_srt": "0] et [1, 1] Tous les vecteurs sur l'axe x sont des vecteurs propres associés à la valeur propre 1 puisqu'ils ne changent pas de position.",
  "n_reviews": 0,
  "start": 708.74,
  "end": 714.54
 },
 {
  "input": "In fact, these are the only eigenvectors.",
  "translatedText": "En fait, ce sont les seuls vecteurs propres.",
  "from_community_srt": "A vrai dire,",
  "n_reviews": 0,
  "start": 715.68,
  "end": 717.82
 },
 {
  "input": "When you subtract off lambda from the diagonals and compute the determinant, what you get is 1 minus lambda squared.",
  "translatedText": "Lorsque vous soustrayez lambda des diagonales et calculez le déterminant, vous obtenez 1 moins lambda au carré.",
  "from_community_srt": "ceci sont les seuls vecteur propres: lorsque vous soustrayez λ de la diagonale",
  "n_reviews": 0,
  "start": 718.76,
  "end": 726.54
 },
 {
  "input": "And the only root of this expression is lambda equals 1.",
  "translatedText": "Et la seule racine de cette expression est lambda égal à 1.",
  "from_community_srt": "et que vous calculez le déterminant vous obtenez (1-λ)², et la seule racine de cette expression est λ=1",
  "n_reviews": 0,
  "start": 729.32,
  "end": 732.86
 },
 {
  "input": "This lines up with what we see geometrically, that all of the eigenvectors have eigenvalue 1.",
  "translatedText": "Cela correspond à ce que nous voyons géométriquement, à savoir que tous les vecteurs propres ont une valeur propre 1.",
  "from_community_srt": "Cela colle avec ce que l'on observe géométriquement, que tous les vecteurs propres ont une valeur propre de 1",
  "n_reviews": 0,
  "start": 734.56,
  "end": 739.72
 },
 {
  "input": "Keep in mind though, it's also possible to have just one eigenvalue, but with more than just a line full of eigenvectors.",
  "translatedText": "Gardez cependant à l’esprit qu’il est également possible d’avoir une seule valeur propre, mais avec plus qu’une simple ligne remplie de vecteurs propres.",
  "from_community_srt": "Retenez bien cependant qu'il est aussi possible de n'avoir qu'une seule valeur propre mais avec plus que simplement une droite de vecteur propres.",
  "n_reviews": 0,
  "start": 741.08,
  "end": 748.02
 },
 {
  "input": "A simple example is a matrix that scales everything by 2.",
  "translatedText": "Un exemple simple est une matrice qui met tout à l’échelle par 2.",
  "from_community_srt": "Un exemple simple est une matrice qui multiplie tout par 2.",
  "n_reviews": 0,
  "start": 749.9,
  "end": 753.18
 },
 {
  "input": "The only eigenvalue is 2, but every vector in the plane gets to be an eigenvector with that eigenvalue.",
  "translatedText": "La seule valeur propre est 2, mais chaque vecteur du plan devient un vecteur propre avec cette valeur propre.",
  "from_community_srt": "La seule valeur propre est 2 mais tous les vecteurs du plan se trouvent être vecteurs propres associés à cette valeur propre.",
  "n_reviews": 0,
  "start": 753.9,
  "end": 760.7
 },
 {
  "input": "Now is another good time to pause and ponder some of this before I move on to the last topic.",
  "translatedText": "C’est maintenant un autre bon moment pour faire une pause et réfléchir à tout cela avant de passer au dernier sujet.",
  "from_community_srt": "C'est une bonne occasion de faire une pause et réfléchir un peu à ceci avant que je passe au dernier sujet.",
  "n_reviews": 0,
  "start": 762.0,
  "end": 766.96
 },
 {
  "input": "I want to finish off here with the idea of an eigenbasis, which relies heavily on ideas from the last video.",
  "translatedText": "Je veux terminer ici avec l'idée d'une base propre, qui s'appuie fortement sur les idées de la dernière vidéo.",
  "from_community_srt": "Je veux terminer ceci avec la notion de \"base propre\" qui se base énormément sur des idées de la dernière vidéo.",
  "n_reviews": 0,
  "start": 783.54,
  "end": 789.88
 },
 {
  "input": "Take a look at what happens if our basis vectors just so happen to be eigenvectors.",
  "translatedText": "Jetez un œil à ce qui se passe si nos vecteurs de base se révèlent être des vecteurs propres.",
  "from_community_srt": "Observez ce qui arrive si nos vecteurs de la base se trouvent être des vecteurs propres.",
  "n_reviews": 0,
  "start": 791.48,
  "end": 796.38
 },
 {
  "input": "For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2.",
  "translatedText": "Par exemple, peut-être que i-hat est mis à l'échelle de moins 1 et j-hat est mis à l'échelle de 2.",
  "from_community_srt": "Par exemple, on peut avoir i-chapeau multiplié par un facteur -1 et j-chapeau multiplié par un facteur 2.",
  "n_reviews": 0,
  "start": 797.12,
  "end": 802.38
 },
 {
  "input": "Writing their new coordinates as the columns of a matrix, notice that those scalar multiples, negative 1 and 2, which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix, and every other entry is a 0.",
  "translatedText": "En écrivant leurs nouvelles coordonnées sous forme de colonnes d'une matrice, notez que ces multiples scalaires, négatifs 1 et 2, qui sont les valeurs propres de i-hat et j-hat, se trouvent sur la diagonale de notre matrice et que chaque autre entrée est un 0. .",
  "from_community_srt": "Ecrire leurs coordonnées comme colonnes d'une matrice, remarquez comme ces scalaires, -1 et 2, qui sont les valeurs propres de i-chapeau et j-chapeau, sont disposés sur les diagonales de notre matrice et toute autre entrée est nulle.",
  "n_reviews": 0,
  "start": 803.42,
  "end": 817.18
 },
 {
  "input": "Any time a matrix has zeros everywhere other than the diagonal, it's called, reasonably enough, a diagonal matrix.",
  "translatedText": "Chaque fois qu'une matrice a des zéros partout ailleurs que sur la diagonale, on l'appelle, assez raisonnablement, une matrice diagonale.",
  "from_community_srt": "Dès qu'une matrice a des 0s partout sinon sur sa diagonale, elle est appelée, assez raisonnablement,",
  "n_reviews": 0,
  "start": 818.88,
  "end": 825.42
 },
 {
  "input": "And the way to interpret this is that all the basis vectors are eigenvectors, with the diagonal entries of this matrix being their eigenvalues.",
  "translatedText": "Et la façon d'interpréter cela est que tous les vecteurs de base sont des vecteurs propres, les entrées diagonales de cette matrice étant leurs valeurs propres.",
  "from_community_srt": "une \"matrice diagonale\" et une bonne manière d'interpréter ceci est que tous les vecteurs de la base sont des vecteurs propres avec les entrée en diagonale de cette matrice comme valeurs propres.",
  "n_reviews": 0,
  "start": 825.84,
  "end": 834.4
 },
 {
  "input": "There are a lot of things that make diagonal matrices much nicer to work with.",
  "translatedText": "Il y a beaucoup de choses qui rendent les matrices diagonales beaucoup plus agréables à utiliser.",
  "from_community_srt": "Il y a beaucoup de choses qui rendent les matrices diagonales bien plus simples à étudier une des principales est qu'il est bien plus simple de calculer ce qu'il va arriver",
  "n_reviews": 0,
  "start": 837.1,
  "end": 841.06
 },
 {
  "input": "One big one is that it's easier to compute what will happen if you multiply this matrix by itself a whole bunch of times.",
  "translatedText": "Le plus important est qu'il est plus facile de calculer ce qui se passera si vous multipliez cette matrice par elle-même plusieurs fois.",
  "from_community_srt": "si vous multipliez cette matrice par elle même un grand nombre de fois, comme ce que chacune de ces matrices fait",
  "n_reviews": 0,
  "start": 841.78,
  "end": 848.34
 },
 {
  "input": "Since all one of these matrices does is scale each basis vector by some eigenvalue, applying that matrix many times, say 100 times, is just going to correspond to scaling each basis vector by the 100th power of the corresponding eigenvalue.",
  "translatedText": "Puisque toutes ces matrices ne font que mettre à l'échelle chaque vecteur de base par une valeur propre, appliquer cette matrice plusieurs fois, disons 100 fois, va simplement correspondre à la mise à l'échelle de chaque vecteur de base par la puissance 100 de la valeur propre correspondante.",
  "from_community_srt": "est de multiplier les vecteurs de la base par une valeur propre, appliquer cette matrice un grand nombre de fois, disons, 100 fois, va juste revenir à multiplier chaque vecteur de la base par la 100ème puissance de la valeur propre correspondante.",
  "n_reviews": 0,
  "start": 849.42,
  "end": 864.6
 },
 {
  "input": "In contrast, try computing the 100th power of a non-diagonal matrix.",
  "translatedText": "En revanche, essayez de calculer la puissance 100 d’une matrice non diagonale.",
  "from_community_srt": "Pour relativiser, essayez de calculer la 100ème puissance d'une matrice non diagonale: sincèrement,",
  "n_reviews": 0,
  "start": 865.7,
  "end": 869.68
 },
 {
  "input": "Really, try it for a moment.",
  "translatedText": "Vraiment, essayez-le un instant.",
  "n_reviews": 0,
  "start": 869.68,
  "end": 871.32
 },
 {
  "input": "It's a nightmare.",
  "translatedText": "C'est un cauchemar.",
  "n_reviews": 0,
  "start": 871.74,
  "end": 872.44
 },
 {
  "input": "Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors.",
  "translatedText": "Bien sûr, vous aurez rarement la chance que vos vecteurs de base soient également des vecteurs propres.",
  "from_community_srt": "essayez un instant {pas trop non plus} c'est un cauchemar ! Evidemment, vous aurez rarement la chance d'avoir vos vecteurs de base comme vecteurs propres.",
  "n_reviews": 0,
  "start": 876.08,
  "end": 881.26
 },
 {
  "input": "But if your transformation has a lot of eigenvectors, like the one from the start of this video, enough so that you can choose a set that spans the full space, then you could change your coordinate system so that these eigenvectors are your basis vectors.",
  "translatedText": "Mais si votre transformation comporte un grand nombre de vecteurs propres, comme celui du début de cette vidéo, suffisamment pour que vous puissiez choisir un ensemble qui s'étend sur tout l'espace, vous pouvez alors modifier votre système de coordonnées afin que ces vecteurs propres soient vos vecteurs de base.",
  "from_community_srt": "Mais si votre transformation a beaucoup de vecteurs propres, comme celle du début de la vidéo, suffisamment pour que vous puissiez choisir un ensemble qui génère tout l'espace alors vous pourrez changer votre système de coordonnées pour que les vecteurs propres soient vos vecteurs de base.",
  "n_reviews": 0,
  "start": 882.04,
  "end": 896.54
 },
 {
  "input": "I talked about change of basis last video, but I'll go through a super quick reminder here of how to express a transformation currently written in our coordinate system into a different system.",
  "translatedText": "J'ai parlé du changement de base dans la dernière vidéo, mais je vais faire ici un rappel très rapide de la façon d'exprimer une transformation actuellement écrite dans notre système de coordonnées dans un système différent.",
  "from_community_srt": "J'ai évoqué le changement de base dans la dernière vidéo mais je vais faire un rappel très rapide sur comment exprimer une transformation écrite dans notre système de coordonnées,",
  "n_reviews": 0,
  "start": 897.14,
  "end": 907.04
 },
 {
  "input": "Take the coordinates of the vectors that you want to use as a new basis, which in this case means our two eigenvectors, then make those coordinates the columns of a matrix, known as the change of basis matrix.",
  "translatedText": "Prenez les coordonnées des vecteurs que vous souhaitez utiliser comme nouvelle base, ce qui signifie dans ce cas nos deux vecteurs propres, puis faites de ces coordonnées les colonnes d'une matrice, connue sous le nom de matrice de changement de base.",
  "from_community_srt": "dans un système différent. Prenez les coordonnées des vecteurs que vous voulez utiliser comme nouvelle base qui, dans ce cas, veut dire qu'il faut deux vecteurs propres puis greffez ces coordonnées comme colonnes d'une matrice,",
  "n_reviews": 0,
  "start": 908.44,
  "end": 919.44
 },
 {
  "input": "When you sandwich the original transformation, putting the change of basis matrix on its right and the inverse of the change of basis matrix on its left, the result will be a matrix representing that same transformation, but from the perspective of the new basis vectors coordinate system.",
  "translatedText": "Lorsque vous prenez en sandwich la transformation d'origine, en plaçant la matrice de changement de base à sa droite et l'inverse de la matrice de changement de base à sa gauche, le résultat sera une matrice représentant cette même transformation, mais du point de vue des nouvelles coordonnées des vecteurs de base. système.",
  "from_community_srt": "appelée \"matrice de changement de base\" Quand vous prenez en sandwich la transformation originale, en mettant le changement de base sur la droite et l'inverse du changement de base sur la gauche, le résultat sera une matrice représentant la même transformation, mais du point de vue du nouveau système de coordonnées.",
  "n_reviews": 0,
  "start": 920.18,
  "end": 936.5
 },
 {
  "input": "The whole point of doing this with eigenvectors is that this new matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal.",
  "translatedText": "L’intérêt de faire cela avec les vecteurs propres est que cette nouvelle matrice est garantie d’être diagonale avec ses valeurs propres correspondantes sur cette diagonale.",
  "from_community_srt": "Tout l'intérêt de faire ceci avec des vecteurs propres est que cette nouvelle matrice est garantie d'être diagonale, avec les valeurs propres correspondantes le long de cette diagonale.",
  "n_reviews": 0,
  "start": 937.44,
  "end": 946.68
 },
 {
  "input": "This is because it represents working in a coordinate system where what happens to the basis vectors is that they get scaled during the transformation.",
  "translatedText": "En effet, cela représente un travail dans un système de coordonnées où les vecteurs de base sont mis à l'échelle lors de la transformation.",
  "from_community_srt": "C'est parce que cela représente travailler sur un système de coordonnées où les vecteurs de la base sont multipliés pendant la transformation.",
  "n_reviews": 0,
  "start": 946.86,
  "end": 954.32
 },
 {
  "input": "A set of basis vectors which are also eigenvectors is called, again, reasonably enough, an eigenbasis.",
  "translatedText": "Un ensemble de vecteurs de base qui sont également des vecteurs propres est appelé, encore une fois, assez raisonnablement, une base propre.",
  "from_community_srt": "un groupe de vecteurs de la base qui sont aussi vecteurs propres est appelé, encore assez raisonnablement,",
  "n_reviews": 0,
  "start": 955.8,
  "end": 961.56
 },
 {
  "input": "So if, for example, you needed to compute the 100th power of this matrix, it would be much easier to change to an eigenbasis, compute the 100th power in that system, then convert back to our standard system.",
  "translatedText": "Ainsi, si, par exemple, vous deviez calculer la 100e puissance de cette matrice, il serait beaucoup plus facile de passer à une base propre, de calculer la 100e puissance dans ce système, puis de revenir à notre système standard.",
  "from_community_srt": "\"base propre\" Donc si, par exemple, vous deviez calculer la 100ème puissance de cette matrice, il serait beaucoup plus simple de se placer dans une base propre, calculer la 100ème puissance dans ce système, puis retourner dans notre système de départ.",
  "n_reviews": 0,
  "start": 962.34,
  "end": 975.68
 },
 {
  "input": "You can't do this with all transformations.",
  "translatedText": "Vous ne pouvez pas faire cela avec toutes les transformations.",
  "from_community_srt": "Vous ne pouvez pas faire ceci avec toutes les transformations.",
  "n_reviews": 0,
  "start": 976.62,
  "end": 978.32
 },
 {
  "input": "A shear, for example, doesn't have enough eigenvectors to span the full space.",
  "translatedText": "Une cisaille, par exemple, n'a pas suffisamment de vecteurs propres pour couvrir tout l'espace.",
  "from_community_srt": "Une transvection, par exemple, ne possède pas assez de vecteurs propres pour générer tout l'espace.",
  "n_reviews": 0,
  "start": 978.32,
  "end": 982.98
 },
 {
  "input": "But if you can find an eigenbasis, it makes matrix operations really lovely.",
  "translatedText": "Mais si vous pouvez trouver une base propre, cela rend les opérations matricielles vraiment agréables.",
  "from_community_srt": "Mais si vous pouvez trouver une base propre, elle rendra les opérations matricielles vraiment adorables.",
  "n_reviews": 0,
  "start": 983.46,
  "end": 988.16
 },
 {
  "input": "For those of you willing to work through a pretty neat puzzle to see what this looks like in action and how it can be used to produce some surprising results, I'll leave up a prompt here on the screen.",
  "translatedText": "Pour ceux d'entre vous qui souhaitent résoudre un casse-tête assez soigné pour voir à quoi cela ressemble en action et comment il peut être utilisé pour produire des résultats surprenants, je vais laisser une invite ici à l'écran.",
  "from_community_srt": "Pour ceux d'entre vous qui auraient envie de bosser sur un puzzle assez sympa, pour voir la tête que tout ça a en action, et comment cela peut être utilisé pour obtenir des résultats intéressants; je vais laisser un petit problème à l'écran.",
  "n_reviews": 0,
  "start": 989.12,
  "end": 997.32
 },
 {
  "input": "It takes a bit of work, but I think you'll enjoy it.",
  "translatedText": "Cela demande un peu de travail, mais je pense que vous l'apprécierez.",
  "from_community_srt": "Cela demande un certain effort, mais je pense que vous allez apprécier.",
  "n_reviews": 0,
  "start": 997.6,
  "end": 1000.28
 },
 {
  "input": "The next and final video of this series is going to be on abstract vector spaces.",
  "translatedText": "La prochaine et dernière vidéo de cette série portera sur les espaces vectoriels abstraits.",
  "from_community_srt": "La prochaine, et dernière vidéo de cette série sera sur les espaces vectoriels abstraits.",
  "n_reviews": 0,
  "start": 1000.84,
  "end": 1006.12
 }
]