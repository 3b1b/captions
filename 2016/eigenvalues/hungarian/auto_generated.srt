1
00:00:19,282 --> 00:00:22,487
A sajátvektorok és a sajátértékek egyike azon

2
00:00:22,487 --> 00:00:26,460
témáknak, amelyeket sok diák különösen intuitívnak talál.

3
00:00:26,460 --> 00:00:30,165
Az olyan dolgok, mint például, hogy miért tesszük ezt, és mit is jelent ez

4
00:00:30,165 --> 00:00:34,020
valójában, túl gyakran csak lebegnek a számítások megválaszolatlan tengerében.

5
00:00:34,020 --> 00:00:37,090
És ahogy közzétettem ennek a sorozatnak a videóit, sokan

6
00:00:37,090 --> 00:00:40,700
megjegyeztétek, hogy alig várjátok, hogy megjelenítsék ezt a témát.

7
00:00:40,700 --> 00:00:43,877
Gyanítom, hogy ennek nem annyira az az oka, hogy a sajátosságok

8
00:00:43,877 --> 00:00:46,460
különösebben bonyolultak vagy rosszul magyarázhatók.

9
00:00:46,460 --> 00:00:52,020
Valójában ez viszonylag egyszerű, és szerintem a legtöbb könyv remekül elmagyarázza.

10
00:00:52,020 --> 00:00:55,677
Azt szeretném elérni, hogy ennek csak akkor van igazán értelme,

11
00:00:55,677 --> 00:00:59,220
ha szilárd vizuális megértése van az azt megelőző témák közül.

12
00:00:59,220 --> 00:01:02,845
A legfontosabb itt az, hogy tudja, hogyan kell a mátrixokat lineáris

13
00:01:02,845 --> 00:01:06,471
transzformációnak tekinteni, de olyan dolgokban is kényelmesnek kell

14
00:01:06,471 --> 00:01:10,780
lennie, mint a determinánsok, a lineáris egyenletrendszerek és az alapváltoztatás.

15
00:01:10,780 --> 00:01:15,568
A sajátanyagokkal kapcsolatos zavar általában több köze van az egyik ilyen

16
00:01:15,568 --> 00:01:20,420
téma ingatag alapjához, mint magukhoz a sajátvektorokhoz és sajátértékekhez.

17
00:01:20,420 --> 00:01:23,582
Kezdésként vegyünk fontolóra néhány lineáris transzformációt

18
00:01:23,582 --> 00:01:25,500
két dimenzióban, mint az itt látható.

19
00:01:25,500 --> 00:01:31,860
Az i-hat bázisvektort a 3, 0, a j-hat pedig 1, 2 koordinátákra mozgatja.

20
00:01:31,860 --> 00:01:36,860
Tehát egy mátrixszal ábrázoljuk, amelynek oszlopai 3, 0 és 1, 2.

21
00:01:36,860 --> 00:01:41,285
Összpontosítson arra, hogy mit csinál egy adott vektorral, és gondoljon

22
00:01:41,285 --> 00:01:45,220
a vektor fesztávjára, az origóján és csúcsán áthaladó egyenesre.

23
00:01:45,220 --> 00:01:48,500
A legtöbb vektor az átalakulás során kiesik a fesztávjából.

24
00:01:48,500 --> 00:01:52,960
Úgy értem, elég véletlennek tűnik, ha az a hely, ahol a

25
00:01:52,960 --> 00:01:57,500
vektor leszállt, véletlenül valahol ezen a vonalon lenne.

26
00:01:57,500 --> 00:02:03,650
De néhány speciális vektor a saját tartományukon marad, ami azt jelenti, hogy a mátrix

27
00:02:03,650 --> 00:02:09,660
hatása egy ilyen vektorra csak az, hogy megnyújtja vagy összenyomja, mint egy skalár.

28
00:02:09,660 --> 00:02:15,100
Ebben a konkrét példában az i-hat bázisvektor egy ilyen speciális vektor.

29
00:02:15,100 --> 00:02:20,721
Az i-hat fesztávja az x tengely, és a mátrix első oszlopából láthatjuk,

30
00:02:20,721 --> 00:02:26,500
hogy az i-hat önmaga háromszorosára mozog, még mindig azon az x tengelyen.

31
00:02:26,500 --> 00:02:32,580
Sőt, a lineáris transzformációk működése miatt az x tengelyen lévő bármely

32
00:02:32,580 --> 00:02:38,580
más vektor is csak 3-szorosára megnyúlik, és így a saját fesztávján marad.

33
00:02:38,580 --> 00:02:42,045
Egy kicsit alattomosabb vektor, amely a transzformáció

34
00:02:42,045 --> 00:02:44,880
során a saját fesztávján marad, negatív 1, 1.

35
00:02:44,880 --> 00:02:49,120
A végén 2-szeresére nyúlik.

36
00:02:49,120 --> 00:02:54,453
És ismét, a linearitás azt jelenti, hogy bármely más vektor az

37
00:02:54,453 --> 00:03:00,040
átlós vonalon, amelyet ez a fickó fed le, csak 2-szeresére nyúlik.

38
00:03:00,040 --> 00:03:03,121
És ehhez az átalakuláshoz ezek mind olyan vektorok, amelyeknek

39
00:03:03,121 --> 00:03:05,860
ez a különleges tulajdonsága, hogy a fesztávon maradnak.

40
00:03:05,860 --> 00:03:09,701
Az x tengelyen lévők 3-szorosára, az ezen az átlós

41
00:03:09,701 --> 00:03:12,940
vonalon lévők pedig 2-szeresére nyúlnak ki.

42
00:03:12,940 --> 00:03:18,081
Bármely másik vektor elfordul valamelyest a transzformáció

43
00:03:18,081 --> 00:03:22,700
során, és kikerül arról a vonalról, amelyen átnyúlik.

44
00:03:22,700 --> 00:03:28,304
Amint azt eddig sejteni lehetett, ezeket a speciális vektorokat a transzformáció

45
00:03:28,304 --> 00:03:33,631
sajátvektorainak nevezik, és minden sajátvektor hozzárendelt egy úgynevezett

46
00:03:33,631 --> 00:03:39,651
sajátértéket, amely éppen az a tényező, amellyel a transzformáció során megnyúlik vagy

47
00:03:39,651 --> 00:03:40,620
összenyomódik.

48
00:03:40,620 --> 00:03:43,814
Természetesen nincs semmi különös a nyújtásban és a squasholásban,

49
00:03:43,814 --> 00:03:46,580
vagy abban, hogy ezek a sajátértékek véletlenül pozitívak.

50
00:03:46,580 --> 00:03:52,054
Egy másik példában lehet egy sajátvektor, amelynek sajátértéke negatív 1 fele,

51
00:03:52,054 --> 00:03:57,460
ami azt jelenti, hogy a vektor megfordul és összenyomódik 1-szeres tényezővel.

52
00:03:57,460 --> 00:04:01,171
De itt az a fontos, hogy azon a vonalon maradjon,

53
00:04:01,171 --> 00:04:04,660
amelyen átnyúlik anélkül, hogy elfordulna róla.

54
00:04:04,660 --> 00:04:08,042
Ha egy pillantást szeretne látni arra, hogy ez miért lehet

55
00:04:08,042 --> 00:04:11,940
hasznos elgondolkodni, fontolja meg néhány háromdimenziós forgatást.

56
00:04:11,940 --> 00:04:17,438
Ha talál egy sajátvektort ehhez a forgáshoz, egy vektort, amely a

57
00:04:17,438 --> 00:04:23,020
saját fesztávján marad, akkor azt találta, hogy az a forgástengely.

58
00:04:23,020 --> 00:04:29,997
És sokkal könnyebb a 3D-s forgatást valamilyen forgási tengelyben és forgási szögben

59
00:04:29,997 --> 00:04:37,140
gondolkodni, mint az ehhez a transzformációhoz kapcsolódó teljes 3x3 mátrixra gondolni.

60
00:04:37,140 --> 00:04:42,074
Ebben az esetben egyébként a megfelelő sajátértéknek 1-nek kell lennie, mivel a

61
00:04:42,074 --> 00:04:46,946
forgatások soha nem nyúlnak meg vagy nem húznak ki semmit, így a vektor hossza

62
00:04:46,946 --> 00:04:48,180
változatlan maradna.

63
00:04:48,180 --> 00:04:50,580
Ez a minta gyakran megjelenik a lineáris algebrában.

64
00:04:50,580 --> 00:04:55,293
Bármilyen mátrix által leírt lineáris transzformáció esetén megértheti, mit csinál,

65
00:04:55,293 --> 00:05:00,120
ha kiolvassa ennek a mátrixnak az oszlopait, mint a bázisvektorok leszállási pontjait.

66
00:05:00,120 --> 00:05:05,198
De gyakran jobb módja annak, hogy a lineáris transzformáció

67
00:05:05,198 --> 00:05:11,293
lényegét megismerjük, ami kevésbé függ az adott koordináta-rendszertől,

68
00:05:11,293 --> 00:05:15,780
ha megtaláljuk a sajátvektorokat és a sajátértékeket.

69
00:05:15,780 --> 00:05:19,695
Itt nem térek ki a sajátvektorok és sajátértékek számítási módszereinek

70
00:05:19,695 --> 00:05:23,067
teljes részleteire, de megpróbálok áttekintést adni azokról a

71
00:05:23,067 --> 00:05:26,820
számítási ötletekről, amelyek a legfontosabbak a fogalmi megértéshez.

72
00:05:26,820 --> 00:05:30,980
Szimbolikusan így néz ki a sajátvektor ötlete.

73
00:05:30,980 --> 00:05:36,372
A valamilyen transzformációt reprezentáló mátrix, v a sajátvektor,

74
00:05:36,372 --> 00:05:40,800
a lambda pedig egy szám, vagyis a megfelelő sajátérték.

75
00:05:40,800 --> 00:05:45,908
Ez a kifejezés az, hogy a mátrix-vektor szorzat, A-szor v, ugyanazt az

76
00:05:45,908 --> 00:05:51,520
eredményt adja, mintha a v sajátvektort skáláznánk valamilyen lambda értékkel.

77
00:05:51,520 --> 00:05:57,141
Tehát az A mátrix sajátvektorainak és sajátértékeinek megtalálása a v és a lambda

78
00:05:57,141 --> 00:06:02,420
azon értékeinek megkereséséhez vezet, amelyek igazzá teszik ezt a kifejezést.

79
00:06:02,420 --> 00:06:06,373
Először kicsit kényelmetlen vele dolgozni, mert a bal oldal a

80
00:06:06,373 --> 00:06:11,220
mátrix-vektor szorzást jelenti, de a jobb oldal itt a skalárvektor szorzást.

81
00:06:11,220 --> 00:06:16,839
Tehát kezdjük azzal, hogy a jobb oldalt átírjuk valamiféle mátrix-vektor szorzásként,

82
00:06:16,839 --> 00:06:21,740
olyan mátrix használatával, amely bármely vektort lambda-tényezővel skáláz.

83
00:06:21,740 --> 00:06:27,090
Egy ilyen mátrix oszlopai azt ábrázolják, hogy mi történik az egyes bázisvektorokkal,

84
00:06:27,090 --> 00:06:31,756
és minden bázisvektort egyszerűen meg kell szorozni lambdával, így ennek a

85
00:06:31,756 --> 00:06:36,360
mátrixnak a lambda száma lesz az átlón lefelé, mindenhol máshol nullákkal.

86
00:06:36,360 --> 00:06:41,046
Ezt a típust általában úgy írják le, hogy ezt a lambdát kiszámolják, és úgy

87
00:06:41,046 --> 00:06:45,980
írják, hogy lambda szoroz i, ahol i az azonosságmátrix az átlón lefelé lévőkkel.

88
00:06:45,980 --> 00:06:50,506
Ha mindkét oldal úgy néz ki, mint a mátrix-vektor szorzás,

89
00:06:50,506 --> 00:06:54,420
levonhatjuk a jobb oldalt, és kiszámolhatjuk a v-t.

90
00:06:54,420 --> 00:06:59,997
Tehát most van egy új mátrixunk, A mínusz lambda szorozva az azonossággal, és

91
00:06:59,997 --> 00:07:05,860
keresünk egy v vektort, amelyre ez az új mátrix, szorozva v, a nulla vektort adja.

92
00:07:05,860 --> 00:07:11,420
Nos, ez mindig igaz lesz, ha maga v a nulla vektor, de ez unalmas.

93
00:07:11,420 --> 00:07:14,540
Nem nulla sajátvektort akarunk.

94
00:07:14,540 --> 00:07:19,804
És ha megnézi az 5. és 6. fejezetet, tudni fogja, hogy az egyetlen módja annak,

95
00:07:19,804 --> 00:07:24,872
hogy egy nem nulla vektorral rendelkező mátrix szorzata nullává váljon, ha a

96
00:07:24,872 --> 00:07:29,940
mátrixhoz tartozó transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

97
00:07:29,940 --> 00:07:35,560
És ez a kicsavarodás a mátrix nulla determinánsának felel meg.

98
00:07:35,560 --> 00:07:40,885
A konkrétumhoz tegyük fel, hogy az A mátrixnak 2. , 1. és 2. , 3. oszlopa van, és

99
00:07:40,885 --> 00:07:46,600
gondoljon arra, hogy minden átlós bejegyzésből kivonhat egy változó összeget, a lambdát.

100
00:07:46,600 --> 00:07:48,764
Most képzelje el, hogy beállítja a lambdát, és

101
00:07:48,764 --> 00:07:51,160
elforgatja a gombot, hogy megváltoztassa az értékét.

102
00:07:51,160 --> 00:07:54,594
A lambda értékének változásával maga a mátrix is

103
00:07:54,594 --> 00:07:58,240
változik, és így változik a mátrix meghatározója is.

104
00:07:58,240 --> 00:08:01,682
A cél itt az, hogy megtaláljuk a lambda értékét, amely nullává

105
00:08:01,682 --> 00:08:05,015
teszi ezt a determinánst, ami azt jelenti, hogy a módosított

106
00:08:05,015 --> 00:08:08,240
transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

107
00:08:08,240 --> 00:08:12,240
Ebben az esetben az édes pont akkor következik be, amikor a lambda 1.

108
00:08:12,240 --> 00:08:16,480
Természetesen, ha más mátrixot választottunk volna, a sajátérték nem feltétlenül 1.

109
00:08:16,480 --> 00:08:20,280
Az édes pontot a lambda más értéke érheti.

110
00:08:20,280 --> 00:08:23,620
Szóval ez elég sok, de fejtsük ki, mit mond ez.

111
00:08:23,620 --> 00:08:26,975
Amikor a lambda egyenlő 1-gyel, az A mátrix mínusz lambda

112
00:08:26,975 --> 00:08:30,620
szorzata az azonosság szorzatával a teret egy vonalra szorozza.

113
00:08:30,620 --> 00:08:35,721
Ez azt jelenti, hogy létezik egy nem nulla v vektor, amelyben A mínusz

114
00:08:35,721 --> 00:08:40,680
lambda szorozva az azonosság szorzatával v egyenlő a nulla vektorral.

115
00:08:40,680 --> 00:08:46,618
És ne feledjük, azért törődünk ezzel, mert ez azt jelenti, hogy A-szor

116
00:08:46,618 --> 00:08:52,473
v egyenlő lambda-szor v-vel, amit úgy olvashatunk le, hogy a v vektor

117
00:08:52,473 --> 00:08:58,580
A sajátvektora, amely az A transzformáció során a saját fesztávján marad.

118
00:08:58,580 --> 00:09:06,240
Ebben a példában a megfelelő sajátérték 1, tehát v valójában csak a helyén marad.

119
00:09:06,240 --> 00:09:10,831
Álljon meg, és gondolkodjon el, ha meg kell bizonyosodnia

120
00:09:10,831 --> 00:09:13,840
arról, hogy ez az érvelés jónak tűnik.

121
00:09:13,840 --> 00:09:16,280
Ez az, amit a bevezetőben említettem.

122
00:09:16,280 --> 00:09:20,319
Ha nem lenne szilárd felfogása a determinánsokról, és arról, hogy

123
00:09:20,319 --> 00:09:24,236
ezek miért vonatkoznak a nem nullától eltérő megoldású lineáris

124
00:09:24,236 --> 00:09:28,460
egyenletrendszerekre, egy ilyen kifejezés teljesen váratlannak tűnik.

125
00:09:28,460 --> 00:09:31,867
Hogy ezt működés közben lássuk, nézzük újra a példát az

126
00:09:31,867 --> 00:09:35,640
elejétől egy olyan mátrixszal, amelynek oszlopai 3, 0 és 1, 2.

127
00:09:35,640 --> 00:09:43,572
Annak megállapításához, hogy egy lambda érték sajátérték-e,

128
00:09:43,572 --> 00:09:51,240
vonja ki a mátrix átlóiból, és számítsa ki a determinánst.

129
00:09:51,240 --> 00:09:54,508
Ezzel egy bizonyos másodfokú polinomot kapunk

130
00:09:54,508 --> 00:09:57,920
lambdában, 3 mínusz lambda szor 2 mínusz lambda.

131
00:09:57,920 --> 00:10:01,785
Mivel a lambda csak akkor lehet sajátérték, ha ez a determináns

132
00:10:01,785 --> 00:10:05,771
véletlenül nulla, ezért arra a következtetésre juthatunk, hogy az

133
00:10:05,771 --> 00:10:10,120
egyetlen lehetséges sajátérték a lambda egyenlő 2 és a lambda egyenlő 3.

134
00:10:10,120 --> 00:10:14,106
Ahhoz, hogy kitaláljuk, melyek azok a sajátvektorok, amelyek ténylegesen

135
00:10:14,106 --> 00:10:17,764
rendelkeznek ezen sajátértékek egyikével, mondjuk a lambda egyenlő

136
00:10:17,764 --> 00:10:21,423
2-vel, csatlakoztassa ezt a lambda-értéket a mátrixhoz, majd oldja

137
00:10:21,423 --> 00:10:25,300
meg, hogy ez az átlósan módosított mátrix mely vektorokra küld nullára.

138
00:10:25,300 --> 00:10:30,359
Ha ezt úgy számolná ki, mint bármely más lineáris rendszert, akkor azt látná, hogy

139
00:10:30,359 --> 00:10:35,480
a megoldások az átlós egyenesen lévő összes vektorok, amelyeket negatív 1, 1 fed le.

140
00:10:35,480 --> 00:10:40,340
Ez megfelel annak a ténynek, hogy a változatlan mátrix,

141
00:10:40,340 --> 00:10:44,680
3, 0, 1, 2, az összes vektort 2-szeresére nyújtja.

142
00:10:44,680 --> 00:10:50,880
Nos, egy 2D-s transzformációnak nem kell sajátvektorokkal rendelkeznie.

143
00:10:50,880 --> 00:10:53,960
Vegyünk például egy 90 fokkal való elforgatást.

144
00:10:53,960 --> 00:11:01,200
Ennek nincsenek sajátvektorai, mivel minden vektort elforgat a saját tartományából.

145
00:11:01,200 --> 00:11:04,155
Ha valóban megpróbálja kiszámítani egy ilyen forgatás

146
00:11:04,155 --> 00:11:06,400
sajátértékeit, figyelje meg, mi történik.

147
00:11:06,400 --> 00:11:11,120
Mátrixának 0, 1 oszlopa és negatív 1, 0 oszlopa van.

148
00:11:11,120 --> 00:11:18,440
Vonjuk le a lambdát az átlós elemekből, és nézzük meg, hogy a determináns mikor nulla.

149
00:11:18,440 --> 00:11:22,960
Ebben az esetben megkapja a lambda polinom négyzetét plusz 1-gyel.

150
00:11:22,960 --> 00:11:29,000
Ennek a polinomnak az egyetlen gyöke az imaginárius számok, az i és a negatív i.

151
00:11:29,000 --> 00:11:36,120
Az a tény, hogy nincsenek valós számmegoldások, azt jelzi, hogy nincsenek sajátvektorok.

152
00:11:36,120 --> 00:11:40,640
Egy másik nagyon érdekes példa, amelyet érdemes a fejedben tartani, a nyíró.

153
00:11:40,640 --> 00:11:44,636
Ez a helyére rögzíti az i-hat-ot, és áthelyezi a

154
00:11:44,636 --> 00:11:49,040
j-hat 1-et, így a mátrixának 1, 0 és 1, 1 oszlopa van.

155
00:11:49,040 --> 00:11:52,141
Az x-tengelyen lévő összes vektor 1-es sajátértékű

156
00:11:52,141 --> 00:11:55,060
sajátvektor, mivel a helyükön rögzítve maradnak.

157
00:11:55,060 --> 00:11:58,880
Valójában ezek az egyetlen sajátvektorok.

158
00:11:58,880 --> 00:12:04,260
Ha kivonja a lambdát az átlókból, és kiszámítja a

159
00:12:04,260 --> 00:12:09,640
determinánst, akkor 1 mínusz lambda négyzetet kap.

160
00:12:09,640 --> 00:12:15,080
Ennek a kifejezésnek az egyetlen gyöke a lambda egyenlő 1-gyel.

161
00:12:15,080 --> 00:12:18,083
Ez összhangban van azzal, amit geometrikusan látunk,

162
00:12:18,083 --> 00:12:21,200
hogy minden sajátvektor 1-es sajátértékkel rendelkezik.

163
00:12:21,200 --> 00:12:25,345
Ne feledje azonban, hogy az is lehetséges, hogy csak egy

164
00:12:25,345 --> 00:12:30,000
sajátértéke legyen, de több, mint egy sajátvektorokkal teli sor.

165
00:12:30,000 --> 00:12:34,040
Egy egyszerű példa egy mátrix, amely mindent 2-vel skáláz.

166
00:12:34,040 --> 00:12:38,605
Az egyetlen sajátérték 2, de a síkban minden vektor

167
00:12:38,605 --> 00:12:42,380
egy sajátvektor lesz ezzel a sajátértékkel.

168
00:12:42,380 --> 00:12:53,140
Most újabb jó alkalom arra, hogy szünetet tartsunk és

169
00:12:53,140 --> 00:13:03,900
elgondolkozzunk ezen, mielőtt az utolsó témára térnék.

170
00:13:03,900 --> 00:13:07,608
Itt szeretném befejezni a sajátbázis ötletét,

171
00:13:07,608 --> 00:13:11,720
amely erősen támaszkodik az utolsó videó ötleteire.

172
00:13:11,720 --> 00:13:17,220
Nézze meg, mi történik, ha bázisvektoraink véletlenül sajátvektorok.

173
00:13:17,220 --> 00:13:23,760
Például lehet, hogy az i-hat negatív 1-gyel, a j-hat pedig 2-vel van méretezve.

174
00:13:23,760 --> 00:13:28,788
Az új koordinátáikat egy mátrix oszlopaiként írva figyeljük meg, hogy

175
00:13:28,788 --> 00:13:33,816
azok a skaláris többszörösek, a negatív 1 és 2, amelyek az i-hat és a

176
00:13:33,816 --> 00:13:39,060
j-hat sajátértékei, a mátrixunk átlóján ülnek, és minden más bejegyzés 0.

177
00:13:39,060 --> 00:13:44,916
Bármikor, amikor egy mátrixban az átlón kívül mindenhol 0-k vannak, ésszerűen

178
00:13:44,916 --> 00:13:50,847
átlós mátrixnak nevezzük, és ennek az értelmezése úgy történik, hogy az összes

179
00:13:50,847 --> 00:13:57,380
bázisvektor sajátvektor, és ennek a mátrixnak a diagonális bejegyzései a sajátértékeik.

180
00:13:57,380 --> 00:14:02,060
Sok olyan dolog van, ami sokkal szebbé teszi az átlós mátrixokkal való munkát.

181
00:14:02,060 --> 00:14:05,597
Az egyik nagy dolog az, hogy könnyebb kiszámítani, mi fog

182
00:14:05,597 --> 00:14:09,500
történni, ha ezt a mátrixot többszörösen megszorozzuk önmagával.

183
00:14:09,500 --> 00:14:14,867
Mivel ezek a mátrixok mindegyike minden bázisvektort valamilyen sajátértékre

184
00:14:14,867 --> 00:14:20,443
skáláz, ezért a mátrix sokszori, mondjuk 100-szori alkalmazása csak akkor felel

185
00:14:20,443 --> 00:14:25,880
meg, ha minden bázisvektort a megfelelő sajátérték 100. hatványával skálázunk.

186
00:14:25,880 --> 00:14:29,940
Ezzel szemben próbálja meg kiszámítani egy nem átlós mátrix 100. hatványát.

187
00:14:29,940 --> 00:14:31,940
Tényleg, próbáld ki egy pillanatra.

188
00:14:31,940 --> 00:14:36,500
Ez egy rémálom.

189
00:14:36,500 --> 00:14:39,360
Természetesen ritkán lesz olyan szerencsés, hogy

190
00:14:39,360 --> 00:14:42,220
az alapvektorai egyben sajátvektorok is legyenek.

191
00:14:42,220 --> 00:14:46,736
De ha a transzformációnak sok sajátvektora van, mint például ennek a videónak az

192
00:14:46,736 --> 00:14:51,475
elejétől, ami elég ahhoz, hogy olyan halmazt válasszon, amely átfedi a teljes teret,

193
00:14:51,475 --> 00:14:56,215
akkor módosíthatja a koordináta-rendszert úgy, hogy ezek a sajátvektorok legyenek az

194
00:14:56,215 --> 00:14:56,940
alapvektorok.

195
00:14:56,940 --> 00:15:00,504
Az előző videóban beszéltem az alap megváltoztatásáról, de itt

196
00:15:00,504 --> 00:15:04,296
végigmegyek egy szupergyors emlékeztetőn, hogyan lehet kifejezni a

197
00:15:04,296 --> 00:15:08,540
koordinátarendszerünkben jelenleg írt transzformációt egy másik rendszerbe.

198
00:15:08,540 --> 00:15:12,312
Vegyük új bázisnak a használni kívánt vektorok koordinátáit, ami

199
00:15:12,312 --> 00:15:15,910
jelen esetben a mi két sajátvektorunkat, majd tegyük ezeket a

200
00:15:15,910 --> 00:15:20,380
koordinátákat egy mátrix oszlopaivá, amelyet bázisváltási mátrixnak nevezünk.

201
00:15:20,380 --> 00:15:24,474
Ha az eredeti transzformációt szendvicsbe tesszük, jobbra téve a

202
00:15:24,474 --> 00:15:28,506
bázismátrix változását, balra pedig a bázis mátrix változásának

203
00:15:28,506 --> 00:15:33,041
inverzét, akkor az eredmény egy ugyanazt a transzformációt reprezentáló

204
00:15:33,041 --> 00:15:37,640
mátrix lesz, de az új bázisvektorok koordinátája szempontjából. rendszer.

205
00:15:37,640 --> 00:15:42,539
Ennek a sajátvektorokkal való megtételének az a lényege, hogy ez az új

206
00:15:42,539 --> 00:15:47,300
mátrix garantáltan átlós a megfelelő sajátértékeivel az átlón lefelé.

207
00:15:47,300 --> 00:15:51,460
Ez azért van így, mert egy olyan koordinátarendszerben dolgozik, ahol

208
00:15:51,460 --> 00:15:55,740
az történik a bázisvektorokkal, hogy a transzformáció során skálázódnak.

209
00:15:55,740 --> 00:15:58,714
A bázisvektorok azon halmazát, amelyek egyben

210
00:15:58,714 --> 00:16:02,400
sajátvektorok is, ismét ésszerűen sajátbázisnak nevezzük.

211
00:16:02,400 --> 00:16:07,365
Tehát, ha például ennek a mátrixnak a 100. hatványát kellene kiszámítani,

212
00:16:07,365 --> 00:16:12,129
sokkal könnyebb lenne sajátbázisra váltani, kiszámolni a 100. hatványt

213
00:16:12,129 --> 00:16:16,760
abban a rendszerben, majd visszakonvertálni a standard rendszerünkre.

214
00:16:16,760 --> 00:16:18,460
Ezt nem lehet minden átalakítással megtenni.

215
00:16:18,460 --> 00:16:23,800
Például egy nyírásnak nincs elég sajátvektora a teljes tér áthidalásához.

216
00:16:23,800 --> 00:16:29,180
De ha talál egy sajátbázist, az igazán széppé teszi a mátrixműveleteket.

217
00:16:29,180 --> 00:16:31,937
Azok számára, akik hajlandóak egy szép rejtvényen dolgozni, hogy

218
00:16:31,937 --> 00:16:34,906
meglássák, hogyan néz ki ez működés közben, és hogyan használható fel

219
00:16:34,906 --> 00:16:37,960
néhány meglepő eredmény eléréséhez, itt hagyok egy üzenetet a képernyőn.

220
00:16:37,960 --> 00:16:40,960
Egy kis munkát igényel, de azt hiszem, élvezni fogja.

221
00:16:40,960 --> 00:16:46,000
A sorozat következő és egyben utolsó videója absztrakt vektortereken fog szerepelni.

222
00:16:46,000 --> 00:16:46,000
Majd találkozunk!

