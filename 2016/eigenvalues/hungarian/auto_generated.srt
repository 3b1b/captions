1
00:00:19,920 --> 00:00:23,095
A sajátvektorok és a sajátértékek egyike azon témáknak, 

2
00:00:23,095 --> 00:00:25,760
amelyeket sok diák különösen intuitívnak talál.

3
00:00:25,760 --> 00:00:29,975
Az olyan dolgok, mint például, hogy miért tesszük ezt, és mit is jelent ez valójában, 

4
00:00:29,975 --> 00:00:33,260
túl gyakran csak lebegnek a számítások megválaszolatlan tengerében.

5
00:00:33,920 --> 00:00:36,445
És ahogy közzétettem ennek a sorozatnak a videóit, 

6
00:00:36,445 --> 00:00:40,060
sokan megjegyeztétek, hogy alig várjátok, hogy megjelenítsék ezt a témát.

7
00:00:40,680 --> 00:00:43,813
Gyanítom, hogy ennek nem annyira az az oka, hogy a sajátosságok 

8
00:00:43,813 --> 00:00:46,360
különösebben bonyolultak vagy rosszul magyarázhatók.

9
00:00:46,860 --> 00:00:50,840
Valójában ez viszonylag egyszerű, és szerintem a legtöbb könyv remekül elmagyarázza.

10
00:00:50,840 --> 00:00:54,720
Azt szeretném elérni, hogy ennek csak akkor van igazán értelme, 

11
00:00:54,720 --> 00:00:58,480
ha szilárd vizuális megértése van az azt megelőző témák közül.

12
00:00:59,060 --> 00:01:02,472
A legfontosabb itt az, hogy tudja, hogyan kell a mátrixokat lineáris 

13
00:01:02,472 --> 00:01:06,280
transzformációnak tekinteni, de olyan dolgokban is kényelmesnek kell lennie, 

14
00:01:06,280 --> 00:01:09,940
mint a determinánsok, a lineáris egyenletrendszerek és az alapváltoztatás.

15
00:01:10,720 --> 00:01:14,951
A sajátanyagokkal kapcsolatos zavar általában több köze van az egyik ilyen 

16
00:01:14,951 --> 00:01:19,240
téma ingatag alapjához, mint magukhoz a sajátvektorokhoz és sajátértékekhez.

17
00:01:19,979 --> 00:01:23,848
Kezdésként vegyünk fontolóra néhány lineáris transzformációt két dimenzióban, 

18
00:01:23,848 --> 00:01:24,840
mint az itt látható.

19
00:01:25,460 --> 00:01:31,040
Az i-hat bázisvektort a 3, 0, a j-hat pedig 1, 2 koordinátákra mozgatja.

20
00:01:31,780 --> 00:01:35,640
Tehát egy mátrixszal ábrázoljuk, amelynek oszlopai 3, 0 és 1, 2.

21
00:01:36,600 --> 00:01:39,879
Összpontosítson arra, hogy mit csinál egy adott vektorral, 

22
00:01:39,879 --> 00:01:44,160
és gondoljon a vektor fesztávjára, az origóján és csúcsán áthaladó egyenesre.

23
00:01:44,920 --> 00:01:48,380
A legtöbb vektor az átalakulás során kiesik a fesztávjából.

24
00:01:48,780 --> 00:01:51,615
Úgy értem, elég véletlennek tűnik, ha az a hely, 

25
00:01:51,615 --> 00:01:55,320
ahol a vektor leszállt, véletlenül valahol ezen a vonalon lenne.

26
00:01:57,400 --> 00:02:01,491
De néhány speciális vektor a saját tartományukon marad, ami azt jelenti, 

27
00:02:01,491 --> 00:02:06,143
hogy a mátrix hatása egy ilyen vektorra csak az, hogy megnyújtja vagy összenyomja, 

28
00:02:06,143 --> 00:02:07,040
mint egy skalár.

29
00:02:09,460 --> 00:02:14,100
Ebben a konkrét példában az i-hat bázisvektor egy ilyen speciális vektor.

30
00:02:14,640 --> 00:02:19,315
Az i-hat fesztávja az x tengely, és a mátrix első oszlopából láthatjuk, 

31
00:02:19,315 --> 00:02:24,120
hogy az i-hat önmaga háromszorosára mozog, még mindig azon az x tengelyen.

32
00:02:26,320 --> 00:02:31,434
Sőt, a lineáris transzformációk működése miatt az x tengelyen lévő bármely 

33
00:02:31,434 --> 00:02:36,480
más vektor is csak 3-szorosára megnyúlik, és így a saját fesztávján marad.

34
00:02:38,500 --> 00:02:43,319
Egy kicsit alattomosabb vektor, amely a transzformáció során a saját fesztávján marad, 

35
00:02:43,319 --> 00:02:44,040
negatív 1, 1.

36
00:02:44,660 --> 00:02:47,140
A végén 2-szeresére nyúlik.

37
00:02:49,000 --> 00:02:54,574
És ismét, a linearitás azt jelenti, hogy bármely más vektor az átlós vonalon, 

38
00:02:54,574 --> 00:02:58,220
amelyet ez a fickó fed le, csak 2-szeresére nyúlik.

39
00:02:59,820 --> 00:03:02,162
És ehhez az átalakuláshoz ezek mind olyan vektorok, 

40
00:03:02,162 --> 00:03:05,180
amelyeknek ez a különleges tulajdonsága, hogy a fesztávon maradnak.

41
00:03:05,620 --> 00:03:09,070
Az x tengelyen lévők 3-szorosára, az ezen az átlós 

42
00:03:09,070 --> 00:03:11,980
vonalon lévők pedig 2-szeresére nyúlnak ki.

43
00:03:12,760 --> 00:03:15,894
Bármely másik vektor elfordul valamelyest a transzformáció során, 

44
00:03:15,894 --> 00:03:18,080
és kikerül arról a vonalról, amelyen átnyúlik.

45
00:03:22,520 --> 00:03:27,167
Amint azt eddig sejteni lehetett, ezeket a speciális vektorokat a transzformáció 

46
00:03:27,167 --> 00:03:31,585
sajátvektorainak nevezik, és minden sajátvektor hozzárendelt egy úgynevezett 

47
00:03:31,585 --> 00:03:36,576
sajátértéket, amely éppen az a tényező, amellyel a transzformáció során megnyúlik vagy 

48
00:03:36,576 --> 00:03:37,380
összenyomódik.

49
00:03:40,280 --> 00:03:43,313
Természetesen nincs semmi különös a nyújtásban és a squasholásban, 

50
00:03:43,313 --> 00:03:45,940
vagy abban, hogy ezek a sajátértékek véletlenül pozitívak.

51
00:03:46,380 --> 00:03:50,777
Egy másik példában lehet egy sajátvektor, amelynek sajátértéke negatív 1 fele, 

52
00:03:50,777 --> 00:03:55,120
ami azt jelenti, hogy a vektor megfordul és összenyomódik 1-szeres tényezővel.

53
00:03:56,980 --> 00:03:59,959
De itt az a fontos, hogy azon a vonalon maradjon, 

54
00:03:59,959 --> 00:04:02,760
amelyen átnyúlik anélkül, hogy elfordulna róla.

55
00:04:04,460 --> 00:04:07,907
Ha egy pillantást szeretne látni arra, hogy ez miért lehet hasznos elgondolkodni, 

56
00:04:07,907 --> 00:04:09,800
fontolja meg néhány háromdimenziós forgatást.

57
00:04:11,660 --> 00:04:15,515
Ha talál egy sajátvektort ehhez a forgáshoz, egy vektort, 

58
00:04:15,515 --> 00:04:20,500
amely a saját fesztávján marad, akkor azt találta, hogy az a forgástengely.

59
00:04:22,600 --> 00:04:28,599
És sokkal könnyebb a 3D-s forgatást valamilyen forgási tengelyben és forgási szögben 

60
00:04:28,599 --> 00:04:34,740
gondolkodni, mint az ehhez a transzformációhoz kapcsolódó teljes 3x3 mátrixra gondolni.

61
00:04:37,000 --> 00:04:40,563
Ebben az esetben egyébként a megfelelő sajátértéknek 1-nek kell lennie, 

62
00:04:40,563 --> 00:04:43,880
mivel a forgatások soha nem nyúlnak meg vagy nem húznak ki semmit, 

63
00:04:43,880 --> 00:04:45,860
így a vektor hossza változatlan maradna.

64
00:04:48,080 --> 00:04:50,020
Ez a minta gyakran megjelenik a lineáris algebrában.

65
00:04:50,440 --> 00:04:54,867
Bármilyen mátrix által leírt lineáris transzformáció esetén megértheti, mit csinál, 

66
00:04:54,867 --> 00:04:59,400
ha kiolvassa ennek a mátrixnak az oszlopait, mint a bázisvektorok leszállási pontjait.

67
00:05:00,020 --> 00:05:04,807
De gyakran jobb módja annak, hogy a lineáris transzformáció lényegét megismerjük, 

68
00:05:04,807 --> 00:05:07,725
ami kevésbé függ az adott koordináta-rendszertől, 

69
00:05:07,725 --> 00:05:10,820
ha megtaláljuk a sajátvektorokat és a sajátértékeket.

70
00:05:15,460 --> 00:05:19,205
Itt nem térek ki a sajátvektorok és sajátértékek számítási módszereinek 

71
00:05:19,205 --> 00:05:23,575
teljes részleteire, de megpróbálok áttekintést adni azokról a számítási ötletekről, 

72
00:05:23,575 --> 00:05:26,020
amelyek a legfontosabbak a fogalmi megértéshez.

73
00:05:27,180 --> 00:05:30,480
Szimbolikusan így néz ki a sajátvektor ötlete.

74
00:05:31,040 --> 00:05:35,817
A valamilyen transzformációt reprezentáló mátrix, v a sajátvektor, 

75
00:05:35,817 --> 00:05:39,740
a lambda pedig egy szám, vagyis a megfelelő sajátérték.

76
00:05:40,680 --> 00:05:46,063
Ez a kifejezés az, hogy a mátrix-vektor szorzat, A-szor v, ugyanazt az eredményt adja, 

77
00:05:46,063 --> 00:05:49,900
mintha a v sajátvektort skáláznánk valamilyen lambda értékkel.

78
00:05:51,000 --> 00:05:55,693
Tehát az A mátrix sajátvektorainak és sajátértékeinek megtalálása a v és a lambda 

79
00:05:55,693 --> 00:06:00,100
azon értékeinek megkereséséhez vezet, amelyek igazzá teszik ezt a kifejezést.

80
00:06:01,920 --> 00:06:05,792
Először kicsit kényelmetlen vele dolgozni, mert a bal oldal a 

81
00:06:05,792 --> 00:06:10,540
mátrix-vektor szorzást jelenti, de a jobb oldal itt a skalárvektor szorzást.

82
00:06:11,120 --> 00:06:16,194
Tehát kezdjük azzal, hogy a jobb oldalt átírjuk valamiféle mátrix-vektor szorzásként, 

83
00:06:16,194 --> 00:06:20,620
olyan mátrix használatával, amely bármely vektort lambda-tényezővel skáláz.

84
00:06:21,680 --> 00:06:26,305
Egy ilyen mátrix oszlopai azt ábrázolják, hogy mi történik az egyes bázisvektorokkal, 

85
00:06:26,305 --> 00:06:29,694
és minden bázisvektort egyszerűen meg kell szorozni lambdával, 

86
00:06:29,694 --> 00:06:34,320
így ennek a mátrixnak a lambda száma lesz az átlón lefelé, mindenhol máshol nullákkal.

87
00:06:36,180 --> 00:06:40,798
Ezt a típust általában úgy írják le, hogy ezt a lambdát kiszámolják, és úgy írják, 

88
00:06:40,798 --> 00:06:44,860
hogy lambda szoroz i, ahol i az azonosságmátrix az átlón lefelé lévőkkel.

89
00:06:45,860 --> 00:06:49,078
Ha mindkét oldal úgy néz ki, mint a mátrix-vektor szorzás, 

90
00:06:49,078 --> 00:06:51,860
levonhatjuk a jobb oldalt, és kiszámolhatjuk a v-t.

91
00:06:54,160 --> 00:06:59,203
Tehát most van egy új mátrixunk, A mínusz lambda szorozva az azonossággal, 

92
00:06:59,203 --> 00:07:04,920
és keresünk egy v vektort, amelyre ez az új mátrix, szorozva v, a nulla vektort adja.

93
00:07:06,380 --> 00:07:11,100
Nos, ez mindig igaz lesz, ha maga v a nulla vektor, de ez unalmas.

94
00:07:11,340 --> 00:07:13,640
Nem nulla sajátvektort akarunk.

95
00:07:14,420 --> 00:07:19,069
És ha megnézi az 5. és 6. fejezetet, tudni fogja, hogy az egyetlen módja annak, 

96
00:07:19,069 --> 00:07:23,254
hogy egy nem nulla vektorral rendelkező mátrix szorzata nullává váljon, 

97
00:07:23,254 --> 00:07:28,020
ha a mátrixhoz tartozó transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

98
00:07:29,300 --> 00:07:34,220
És ez a kicsavarodás a mátrix nulla determinánsának felel meg.

99
00:07:35,480 --> 00:07:40,145
A konkrétumhoz tegyük fel, hogy az A mátrixnak 2. , 1. és 2. , 3. oszlopa van, 

100
00:07:40,145 --> 00:07:44,929
és gondoljon arra, hogy minden átlós bejegyzésből kivonhat egy változó összeget, 

101
00:07:44,929 --> 00:07:45,520
a lambdát.

102
00:07:46,480 --> 00:07:49,090
Most képzelje el, hogy beállítja a lambdát, és elforgatja a gombot, 

103
00:07:49,090 --> 00:07:50,280
hogy megváltoztassa az értékét.

104
00:07:50,940 --> 00:07:54,620
A lambda értékének változásával maga a mátrix is változik, 

105
00:07:54,620 --> 00:07:57,240
és így változik a mátrix meghatározója is.

106
00:07:58,220 --> 00:08:00,635
A cél itt az, hogy megtaláljuk a lambda értékét, 

107
00:08:00,635 --> 00:08:03,444
amely nullává teszi ezt a determinánst, ami azt jelenti, 

108
00:08:03,444 --> 00:08:07,240
hogy a módosított transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

109
00:08:08,160 --> 00:08:11,160
Ebben az esetben az édes pont akkor következik be, amikor a lambda 1.

110
00:08:12,180 --> 00:08:16,120
Természetesen, ha más mátrixot választottunk volna, a sajátérték nem feltétlenül 1.

111
00:08:16,240 --> 00:08:18,600
Az édes pontot a lambda más értéke érheti.

112
00:08:20,080 --> 00:08:22,960
Szóval ez elég sok, de fejtsük ki, mit mond ez.

113
00:08:22,960 --> 00:08:26,123
Amikor a lambda egyenlő 1-gyel, az A mátrix mínusz lambda 

114
00:08:26,123 --> 00:08:29,560
szorzata az azonosság szorzatával a teret egy vonalra szorozza.

115
00:08:30,440 --> 00:08:33,514
Ez azt jelenti, hogy létezik egy nem nulla v vektor, 

116
00:08:33,514 --> 00:08:38,559
amelyben A mínusz lambda szorozva az azonosság szorzatával v egyenlő a nulla vektorral.

117
00:08:40,480 --> 00:08:45,111
És ne feledjük, azért törődünk ezzel, mert ez azt jelenti, 

118
00:08:45,111 --> 00:08:50,293
hogy A-szor v egyenlő lambda-szor v-vel, amit úgy olvashatunk le, 

119
00:08:50,293 --> 00:08:57,280
hogy a v vektor A sajátvektora, amely az A transzformáció során a saját fesztávján marad.

120
00:08:58,320 --> 00:09:04,020
Ebben a példában a megfelelő sajátérték 1, tehát v valójában csak a helyén marad.

121
00:09:06,220 --> 00:09:08,440
Álljon meg, és gondolkodjon el, ha meg kell bizonyosodnia arról, 

122
00:09:08,440 --> 00:09:09,500
hogy ez az érvelés jónak tűnik.

123
00:09:13,380 --> 00:09:15,640
Ez az, amit a bevezetőben említettem.

124
00:09:16,220 --> 00:09:19,309
Ha nem lenne szilárd felfogása a determinánsokról, és arról, 

125
00:09:19,309 --> 00:09:22,804
hogy ezek miért vonatkoznak a nem nullától eltérő megoldású lineáris 

126
00:09:22,804 --> 00:09:26,300
egyenletrendszerekre, egy ilyen kifejezés teljesen váratlannak tűnik.

127
00:09:28,320 --> 00:09:32,905
Hogy ezt működés közben lássuk, nézzük újra a példát az elejétől egy olyan mátrixszal, 

128
00:09:32,905 --> 00:09:34,540
amelynek oszlopai 3, 0 és 1, 2.

129
00:09:35,350 --> 00:09:39,443
Annak megállapításához, hogy egy lambda érték sajátérték-e, 

130
00:09:39,443 --> 00:09:43,400
vonja ki a mátrix átlóiból, és számítsa ki a determinánst.

131
00:09:50,580 --> 00:09:54,303
Ezzel egy bizonyos másodfokú polinomot kapunk lambdában, 

132
00:09:54,303 --> 00:09:56,720
3 mínusz lambda szor 2 mínusz lambda.

133
00:09:57,800 --> 00:10:02,281
Mivel a lambda csak akkor lehet sajátérték, ha ez a determináns véletlenül nulla, 

134
00:10:02,281 --> 00:10:05,998
ezért arra a következtetésre juthatunk, hogy az egyetlen lehetséges 

135
00:10:05,998 --> 00:10:08,840
sajátérték a lambda egyenlő 2 és a lambda egyenlő 3.

136
00:10:09,640 --> 00:10:12,358
Ahhoz, hogy kitaláljuk, melyek azok a sajátvektorok, 

137
00:10:12,358 --> 00:10:15,538
amelyek ténylegesen rendelkeznek ezen sajátértékek egyikével, 

138
00:10:15,538 --> 00:10:19,693
mondjuk a lambda egyenlő 2-vel, csatlakoztassa ezt a lambda-értéket a mátrixhoz, 

139
00:10:19,693 --> 00:10:23,900
majd oldja meg, hogy ez az átlósan módosított mátrix mely vektorokra küld nullára.

140
00:10:24,940 --> 00:10:29,311
Ha ezt úgy számolná ki, mint bármely más lineáris rendszert, akkor azt látná, 

141
00:10:29,311 --> 00:10:34,300
hogy a megoldások az átlós egyenesen lévő összes vektorok, amelyeket negatív 1, 1 fed le.

142
00:10:35,220 --> 00:10:39,573
Ez megfelel annak a ténynek, hogy a változatlan mátrix, 

143
00:10:39,573 --> 00:10:43,460
3, 0, 1, 2, az összes vektort 2-szeresére nyújtja.

144
00:10:46,320 --> 00:10:50,200
Nos, egy 2D-s transzformációnak nem kell sajátvektorokkal rendelkeznie.

145
00:10:50,720 --> 00:10:53,400
Vegyünk például egy 90 fokkal való elforgatást.

146
00:10:53,660 --> 00:10:58,200
Ennek nincsenek sajátvektorai, mivel minden vektort elforgat a saját tartományából.

147
00:11:00,800 --> 00:11:04,257
Ha valóban megpróbálja kiszámítani egy ilyen forgatás sajátértékeit, 

148
00:11:04,257 --> 00:11:05,560
figyelje meg, mi történik.

149
00:11:06,300 --> 00:11:10,140
Mátrixának 0, 1 oszlopa és negatív 1, 0 oszlopa van.

150
00:11:11,100 --> 00:11:15,800
Vonjuk le a lambdát az átlós elemekből, és nézzük meg, hogy a determináns mikor nulla.

151
00:11:18,140 --> 00:11:21,940
Ebben az esetben megkapja a lambda polinom négyzetét plusz 1-gyel.

152
00:11:22,680 --> 00:11:27,920
Ennek a polinomnak az egyetlen gyöke az imaginárius számok, az i és a negatív i.

153
00:11:28,840 --> 00:11:33,600
Az a tény, hogy nincsenek valós számmegoldások, azt jelzi, hogy nincsenek sajátvektorok.

154
00:11:35,540 --> 00:11:39,820
Egy másik nagyon érdekes példa, amelyet érdemes a fejedben tartani, a nyíró.

155
00:11:40,560 --> 00:11:44,871
Ez a helyére rögzíti az i-hat-ot, és áthelyezi a j-hat 1-et, 

156
00:11:44,871 --> 00:11:47,840
így a mátrixának 1, 0 és 1, 1 oszlopa van.

157
00:11:48,739 --> 00:11:52,489
Az x-tengelyen lévő összes vektor 1-es sajátértékű sajátvektor, 

158
00:11:52,489 --> 00:11:54,540
mivel a helyükön rögzítve maradnak.

159
00:11:55,680 --> 00:11:57,820
Valójában ezek az egyetlen sajátvektorok.

160
00:11:58,760 --> 00:12:03,739
Ha kivonja a lambdát az átlókból, és kiszámítja a determinánst, 

161
00:12:03,739 --> 00:12:06,540
akkor 1 mínusz lambda négyzetet kap.

162
00:12:09,319 --> 00:12:12,860
Ennek a kifejezésnek az egyetlen gyöke a lambda egyenlő 1-gyel.

163
00:12:14,560 --> 00:12:17,092
Ez összhangban van azzal, amit geometrikusan látunk, 

164
00:12:17,092 --> 00:12:19,720
hogy minden sajátvektor 1-es sajátértékkel rendelkezik.

165
00:12:21,080 --> 00:12:25,496
Ne feledje azonban, hogy az is lehetséges, hogy csak egy sajátértéke legyen, 

166
00:12:25,496 --> 00:12:28,020
de több, mint egy sajátvektorokkal teli sor.

167
00:12:29,900 --> 00:12:33,180
Egy egyszerű példa egy mátrix, amely mindent 2-vel skáláz.

168
00:12:33,900 --> 00:12:37,622
Az egyetlen sajátérték 2, de a síkban minden vektor 

169
00:12:37,622 --> 00:12:40,700
egy sajátvektor lesz ezzel a sajátértékkel.

170
00:12:42,000 --> 00:12:45,490
Most újabb jó alkalom arra, hogy szünetet tartsunk és elgondolkozzunk ezen, 

171
00:12:45,490 --> 00:12:46,960
mielőtt az utolsó témára térnék.

172
00:13:03,540 --> 00:13:06,546
Itt szeretném befejezni a sajátbázis ötletét, 

173
00:13:06,546 --> 00:13:09,880
amely erősen támaszkodik az utolsó videó ötleteire.

174
00:13:11,480 --> 00:13:16,380
Nézze meg, mi történik, ha bázisvektoraink véletlenül sajátvektorok.

175
00:13:17,120 --> 00:13:22,380
Például lehet, hogy az i-hat negatív 1-gyel, a j-hat pedig 2-vel van méretezve.

176
00:13:23,420 --> 00:13:27,619
Az új koordinátáikat egy mátrix oszlopaiként írva figyeljük meg, 

177
00:13:27,619 --> 00:13:31,042
hogy azok a skaláris többszörösek, a negatív 1 és 2, 

178
00:13:31,042 --> 00:13:35,500
amelyek az i-hat és a j-hat sajátértékei, a mátrixunk átlóján ülnek, 

179
00:13:35,500 --> 00:13:37,180
és minden más bejegyzés 0.

180
00:13:38,880 --> 00:13:43,205
Bármikor, amikor egy mátrixban az átlón kívül mindenhol 0-k vannak, 

181
00:13:43,205 --> 00:13:47,912
ésszerűen átlós mátrixnak nevezzük, és ennek az értelmezése úgy történik, 

182
00:13:47,912 --> 00:13:53,382
hogy az összes bázisvektor sajátvektor, és ennek a mátrixnak a diagonális bejegyzései 

183
00:13:53,382 --> 00:13:54,400
a sajátértékeik.

184
00:13:57,100 --> 00:14:01,060
Sok olyan dolog van, ami sokkal szebbé teszi az átlós mátrixokkal való munkát.

185
00:14:01,780 --> 00:14:05,436
Az egyik nagy dolog az, hogy könnyebb kiszámítani, mi fog történni, 

186
00:14:05,436 --> 00:14:08,340
ha ezt a mátrixot többszörösen megszorozzuk önmagával.

187
00:14:09,420 --> 00:14:14,910
Mivel ezek a mátrixok mindegyike minden bázisvektort valamilyen sajátértékre skáláz, 

188
00:14:14,910 --> 00:14:19,884
ezért a mátrix sokszori, mondjuk 100-szori alkalmazása csak akkor felel meg, 

189
00:14:19,884 --> 00:14:24,600
ha minden bázisvektort a megfelelő sajátérték 100. hatványával skálázunk.

190
00:14:25,700 --> 00:14:29,680
Ezzel szemben próbálja meg kiszámítani egy nem átlós mátrix 100. hatványát.

191
00:14:29,680 --> 00:14:31,320
Tényleg, próbáld ki egy pillanatra.

192
00:14:31,740 --> 00:14:32,440
Ez egy rémálom.

193
00:14:36,080 --> 00:14:38,670
Természetesen ritkán lesz olyan szerencsés, hogy 

194
00:14:38,670 --> 00:14:41,260
az alapvektorai egyben sajátvektorok is legyenek.

195
00:14:42,040 --> 00:14:44,676
De ha a transzformációnak sok sajátvektora van, 

196
00:14:44,676 --> 00:14:49,564
mint például ennek a videónak az elejétől, ami elég ahhoz, hogy olyan halmazt válasszon, 

197
00:14:49,564 --> 00:14:53,738
amely átfedi a teljes teret, akkor módosíthatja a koordináta-rendszert úgy, 

198
00:14:53,738 --> 00:14:56,540
hogy ezek a sajátvektorok legyenek az alapvektorok.

199
00:14:57,140 --> 00:14:59,844
Az előző videóban beszéltem az alap megváltoztatásáról, 

200
00:14:59,844 --> 00:15:02,210
de itt végigmegyek egy szupergyors emlékeztetőn, 

201
00:15:02,210 --> 00:15:05,253
hogyan lehet kifejezni a koordinátarendszerünkben jelenleg írt 

202
00:15:05,253 --> 00:15:07,040
transzformációt egy másik rendszerbe.

203
00:15:08,440 --> 00:15:11,729
Vegyük új bázisnak a használni kívánt vektorok koordinátáit, 

204
00:15:11,729 --> 00:15:15,288
ami jelen esetben a mi két sajátvektorunkat, majd tegyük ezeket a 

205
00:15:15,288 --> 00:15:19,440
koordinátákat egy mátrix oszlopaivá, amelyet bázisváltási mátrixnak nevezünk.

206
00:15:20,180 --> 00:15:23,217
Ha az eredeti transzformációt szendvicsbe tesszük, 

207
00:15:23,217 --> 00:15:28,459
jobbra téve a bázismátrix változását, balra pedig a bázis mátrix változásának inverzét, 

208
00:15:28,459 --> 00:15:32,926
akkor az eredmény egy ugyanazt a transzformációt reprezentáló mátrix lesz, 

209
00:15:32,926 --> 00:15:36,500
de az új bázisvektorok koordinátája szempontjából. rendszer.

210
00:15:37,440 --> 00:15:41,202
Ennek a sajátvektorokkal való megtételének az a lényege, 

211
00:15:41,202 --> 00:15:46,680
hogy ez az új mátrix garantáltan átlós a megfelelő sajátértékeivel az átlón lefelé.

212
00:15:46,860 --> 00:15:50,274
Ez azért van így, mert egy olyan koordinátarendszerben dolgozik, 

213
00:15:50,274 --> 00:15:54,320
ahol az történik a bázisvektorokkal, hogy a transzformáció során skálázódnak.

214
00:15:55,800 --> 00:15:59,379
A bázisvektorok azon halmazát, amelyek egyben sajátvektorok is, 

215
00:15:59,379 --> 00:16:01,560
ismét ésszerűen sajátbázisnak nevezzük.

216
00:16:02,340 --> 00:16:06,952
Tehát, ha például ennek a mátrixnak a 100. hatványát kellene kiszámítani, 

217
00:16:06,952 --> 00:16:10,817
sokkal könnyebb lenne sajátbázisra váltani, kiszámolni a 100. 

218
00:16:10,817 --> 00:16:15,680
hatványt abban a rendszerben, majd visszakonvertálni a standard rendszerünkre.

219
00:16:16,620 --> 00:16:18,320
Ezt nem lehet minden átalakítással megtenni.

220
00:16:18,320 --> 00:16:22,980
Például egy nyírásnak nincs elég sajátvektora a teljes tér áthidalásához.

221
00:16:23,460 --> 00:16:28,160
De ha talál egy sajátbázist, az igazán széppé teszi a mátrixműveleteket.

222
00:16:29,120 --> 00:16:32,130
Azok számára, akik hajlandóak egy szép rejtvényen dolgozni, hogy meglássák, 

223
00:16:32,130 --> 00:16:34,745
hogyan néz ki ez működés közben, és hogyan használható fel néhány 

224
00:16:34,745 --> 00:16:37,320
meglepő eredmény eléréséhez, itt hagyok egy üzenetet a képernyőn.

225
00:16:37,600 --> 00:16:40,280
Egy kis munkát igényel, de azt hiszem, élvezni fogja.

226
00:16:40,840 --> 00:16:45,380
A sorozat következő és egyben utolsó videója absztrakt vektortereken fog szerepelni.

227
00:16:45,900 --> 00:16:46,120
Majd találkozunk!

