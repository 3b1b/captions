1
00:00:19,282 --> 00:00:23,184
A sajátvektorok és a sajátértékek egyike azon témáknak,

2
00:00:23,184 --> 00:00:26,460
amelyeket sok diák különösen intuitívnak talál.

3
00:00:26,460 --> 00:00:30,709
Az olyan dolgok, mint például, hogy miért tesszük ezt, és mit is jelent ez valójában,

4
00:00:30,709 --> 00:00:34,020
túl gyakran csak lebegnek a számítások megválaszolatlan tengerében.

5
00:00:34,020 --> 00:00:36,767
És ahogy közzétettem ennek a sorozatnak a videóit,

6
00:00:36,767 --> 00:00:40,700
sokan megjegyeztétek, hogy alig várjátok, hogy megjelenítsék ezt a témát.

7
00:00:40,700 --> 00:00:43,877
Gyanítom, hogy ennek nem annyira az az oka, hogy a sajátosságok

8
00:00:43,877 --> 00:00:46,460
különösebben bonyolultak vagy rosszul magyarázhatók.

9
00:00:46,460 --> 00:00:52,020
Valójában ez viszonylag egyszerű, és szerintem a legtöbb könyv remekül elmagyarázza.

10
00:00:52,020 --> 00:00:55,677
Azt szeretném elérni, hogy ennek csak akkor van igazán értelme,

11
00:00:55,677 --> 00:00:59,220
ha szilárd vizuális megértése van az azt megelőző témák közül.

12
00:00:59,220 --> 00:01:02,845
A legfontosabb itt az, hogy tudja, hogyan kell a mátrixokat lineáris

13
00:01:02,845 --> 00:01:06,891
transzformációnak tekinteni, de olyan dolgokban is kényelmesnek kell lennie,

14
00:01:06,891 --> 00:01:10,780
mint a determinánsok, a lineáris egyenletrendszerek és az alapváltoztatás.

15
00:01:10,780 --> 00:01:15,568
A sajátanyagokkal kapcsolatos zavar általában több köze van az egyik ilyen

16
00:01:15,568 --> 00:01:20,420
téma ingatag alapjához, mint magukhoz a sajátvektorokhoz és sajátértékekhez.

17
00:01:20,420 --> 00:01:24,463
Kezdésként vegyünk fontolóra néhány lineáris transzformációt két dimenzióban,

18
00:01:24,463 --> 00:01:25,500
mint az itt látható.

19
00:01:25,500 --> 00:01:31,860
Az i-hat bázisvektort a 3, 0, a j-hat pedig 1, 2 koordinátákra mozgatja.

20
00:01:31,860 --> 00:01:36,860
Tehát egy mátrixszal ábrázoljuk, amelynek oszlopai 3, 0 és 1, 2.

21
00:01:36,860 --> 00:01:40,486
Összpontosítson arra, hogy mit csinál egy adott vektorral,

22
00:01:40,486 --> 00:01:45,220
és gondoljon a vektor fesztávjára, az origóján és csúcsán áthaladó egyenesre.

23
00:01:45,220 --> 00:01:48,500
A legtöbb vektor az átalakulás során kiesik a fesztávjából.

24
00:01:48,500 --> 00:01:52,402
Úgy értem, elég véletlennek tűnik, ha az a hely,

25
00:01:52,402 --> 00:01:57,500
ahol a vektor leszállt, véletlenül valahol ezen a vonalon lenne.

26
00:01:57,500 --> 00:02:02,660
De néhány speciális vektor a saját tartományukon marad, ami azt jelenti,

27
00:02:02,660 --> 00:02:08,528
hogy a mátrix hatása egy ilyen vektorra csak az, hogy megnyújtja vagy összenyomja,

28
00:02:08,528 --> 00:02:09,660
mint egy skalár.

29
00:02:09,660 --> 00:02:15,100
Ebben a konkrét példában az i-hat bázisvektor egy ilyen speciális vektor.

30
00:02:15,100 --> 00:02:20,721
Az i-hat fesztávja az x tengely, és a mátrix első oszlopából láthatjuk,

31
00:02:20,721 --> 00:02:26,500
hogy az i-hat önmaga háromszorosára mozog, még mindig azon az x tengelyen.

32
00:02:26,500 --> 00:02:32,580
Sőt, a lineáris transzformációk működése miatt az x tengelyen lévő bármely

33
00:02:32,580 --> 00:02:38,580
más vektor is csak 3-szorosára megnyúlik, és így a saját fesztávján marad.

34
00:02:38,580 --> 00:02:44,061
Egy kicsit alattomosabb vektor, amely a transzformáció során a saját fesztávján marad,

35
00:02:44,061 --> 00:02:44,880
negatív 1, 1.

36
00:02:44,880 --> 00:02:49,120
A végén 2-szeresére nyúlik.

37
00:02:49,120 --> 00:02:55,722
És ismét, a linearitás azt jelenti, hogy bármely más vektor az átlós vonalon,

38
00:02:55,722 --> 00:03:00,040
amelyet ez a fickó fed le, csak 2-szeresére nyúlik.

39
00:03:00,040 --> 00:03:02,583
És ehhez az átalakuláshoz ezek mind olyan vektorok,

40
00:03:02,583 --> 00:03:05,860
amelyeknek ez a különleges tulajdonsága, hogy a fesztávon maradnak.

41
00:03:05,860 --> 00:03:09,701
Az x tengelyen lévők 3-szorosára, az ezen az átlós

42
00:03:09,701 --> 00:03:12,940
vonalon lévők pedig 2-szeresére nyúlnak ki.

43
00:03:12,940 --> 00:03:18,691
Bármely másik vektor elfordul valamelyest a transzformáció során,

44
00:03:18,691 --> 00:03:22,700
és kikerül arról a vonalról, amelyen átnyúlik.

45
00:03:22,700 --> 00:03:28,304
Amint azt eddig sejteni lehetett, ezeket a speciális vektorokat a transzformáció

46
00:03:28,304 --> 00:03:33,631
sajátvektorainak nevezik, és minden sajátvektor hozzárendelt egy úgynevezett

47
00:03:33,631 --> 00:03:39,651
sajátértéket, amely éppen az a tényező, amellyel a transzformáció során megnyúlik vagy

48
00:03:39,651 --> 00:03:40,620
összenyomódik.

49
00:03:40,620 --> 00:03:43,814
Természetesen nincs semmi különös a nyújtásban és a squasholásban,

50
00:03:43,814 --> 00:03:46,580
vagy abban, hogy ezek a sajátértékek véletlenül pozitívak.

51
00:03:46,580 --> 00:03:52,054
Egy másik példában lehet egy sajátvektor, amelynek sajátértéke negatív 1 fele,

52
00:03:52,054 --> 00:03:57,460
ami azt jelenti, hogy a vektor megfordul és összenyomódik 1-szeres tényezővel.

53
00:03:57,460 --> 00:04:01,171
De itt az a fontos, hogy azon a vonalon maradjon,

54
00:04:01,171 --> 00:04:04,660
amelyen átnyúlik anélkül, hogy elfordulna róla.

55
00:04:04,660 --> 00:04:09,360
Ha egy pillantást szeretne látni arra, hogy ez miért lehet hasznos elgondolkodni,

56
00:04:09,360 --> 00:04:11,940
fontolja meg néhány háromdimenziós forgatást.

57
00:04:11,940 --> 00:04:16,771
Ha talál egy sajátvektort ehhez a forgáshoz, egy vektort,

58
00:04:16,771 --> 00:04:23,020
amely a saját fesztávján marad, akkor azt találta, hogy az a forgástengely.

59
00:04:23,020 --> 00:04:29,997
És sokkal könnyebb a 3D-s forgatást valamilyen forgási tengelyben és forgási szögben

60
00:04:29,997 --> 00:04:37,140
gondolkodni, mint az ehhez a transzformációhoz kapcsolódó teljes 3x3 mátrixra gondolni.

61
00:04:37,140 --> 00:04:41,580
Ebben az esetben egyébként a megfelelő sajátértéknek 1-nek kell lennie,

62
00:04:41,580 --> 00:04:45,712
mivel a forgatások soha nem nyúlnak meg vagy nem húznak ki semmit,

63
00:04:45,712 --> 00:04:48,180
így a vektor hossza változatlan maradna.

64
00:04:48,180 --> 00:04:50,580
Ez a minta gyakran megjelenik a lineáris algebrában.

65
00:04:50,580 --> 00:04:55,293
Bármilyen mátrix által leírt lineáris transzformáció esetén megértheti, mit csinál,

66
00:04:55,293 --> 00:05:00,120
ha kiolvassa ennek a mátrixnak az oszlopait, mint a bázisvektorok leszállási pontjait.

67
00:05:00,120 --> 00:05:07,061
De gyakran jobb módja annak, hogy a lineáris transzformáció lényegét megismerjük,

68
00:05:07,061 --> 00:05:11,293
ami kevésbé függ az adott koordináta-rendszertől,

69
00:05:11,293 --> 00:05:15,780
ha megtaláljuk a sajátvektorokat és a sajátértékeket.

70
00:05:15,780 --> 00:05:19,695
Itt nem térek ki a sajátvektorok és sajátértékek számítási módszereinek

71
00:05:19,695 --> 00:05:24,263
teljes részleteire, de megpróbálok áttekintést adni azokról a számítási ötletekről,

72
00:05:24,263 --> 00:05:26,820
amelyek a legfontosabbak a fogalmi megértéshez.

73
00:05:26,820 --> 00:05:30,980
Szimbolikusan így néz ki a sajátvektor ötlete.

74
00:05:30,980 --> 00:05:36,372
A valamilyen transzformációt reprezentáló mátrix, v a sajátvektor,

75
00:05:36,372 --> 00:05:40,800
a lambda pedig egy szám, vagyis a megfelelő sajátérték.

76
00:05:40,800 --> 00:05:47,059
Ez a kifejezés az, hogy a mátrix-vektor szorzat, A-szor v, ugyanazt az eredményt adja,

77
00:05:47,059 --> 00:05:51,520
mintha a v sajátvektort skáláznánk valamilyen lambda értékkel.

78
00:05:51,520 --> 00:05:57,141
Tehát az A mátrix sajátvektorainak és sajátértékeinek megtalálása a v és a lambda

79
00:05:57,141 --> 00:06:02,420
azon értékeinek megkereséséhez vezet, amelyek igazzá teszik ezt a kifejezést.

80
00:06:02,420 --> 00:06:06,373
Először kicsit kényelmetlen vele dolgozni, mert a bal oldal a

81
00:06:06,373 --> 00:06:11,220
mátrix-vektor szorzást jelenti, de a jobb oldal itt a skalárvektor szorzást.

82
00:06:11,220 --> 00:06:16,839
Tehát kezdjük azzal, hogy a jobb oldalt átírjuk valamiféle mátrix-vektor szorzásként,

83
00:06:16,839 --> 00:06:21,740
olyan mátrix használatával, amely bármely vektort lambda-tényezővel skáláz.

84
00:06:21,740 --> 00:06:27,090
Egy ilyen mátrix oszlopai azt ábrázolják, hogy mi történik az egyes bázisvektorokkal,

85
00:06:27,090 --> 00:06:31,009
és minden bázisvektort egyszerűen meg kell szorozni lambdával,

86
00:06:31,009 --> 00:06:36,360
így ennek a mátrixnak a lambda száma lesz az átlón lefelé, mindenhol máshol nullákkal.

87
00:06:36,360 --> 00:06:41,478
Ezt a típust általában úgy írják le, hogy ezt a lambdát kiszámolják, és úgy írják,

88
00:06:41,478 --> 00:06:45,980
hogy lambda szoroz i, ahol i az azonosságmátrix az átlón lefelé lévőkkel.

89
00:06:45,980 --> 00:06:50,506
Ha mindkét oldal úgy néz ki, mint a mátrix-vektor szorzás,

90
00:06:50,506 --> 00:06:54,420
levonhatjuk a jobb oldalt, és kiszámolhatjuk a v-t.

91
00:06:54,420 --> 00:06:59,782
Tehát most van egy új mátrixunk, A mínusz lambda szorozva az azonossággal,

92
00:06:59,782 --> 00:07:05,860
és keresünk egy v vektort, amelyre ez az új mátrix, szorozva v, a nulla vektort adja.

93
00:07:05,860 --> 00:07:11,420
Nos, ez mindig igaz lesz, ha maga v a nulla vektor, de ez unalmas.

94
00:07:11,420 --> 00:07:14,540
Nem nulla sajátvektort akarunk.

95
00:07:14,540 --> 00:07:19,804
És ha megnézi az 5. és 6. fejezetet, tudni fogja, hogy az egyetlen módja annak,

96
00:07:19,804 --> 00:07:24,543
hogy egy nem nulla vektorral rendelkező mátrix szorzata nullává váljon,

97
00:07:24,543 --> 00:07:29,940
ha a mátrixhoz tartozó transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

98
00:07:29,940 --> 00:07:35,560
És ez a kicsavarodás a mátrix nulla determinánsának felel meg.

99
00:07:35,560 --> 00:07:40,690
A konkrétumhoz tegyük fel, hogy az A mátrixnak 2. , 1. és 2. , 3. oszlopa van,

100
00:07:40,690 --> 00:07:45,950
és gondoljon arra, hogy minden átlós bejegyzésből kivonhat egy változó összeget,

101
00:07:45,950 --> 00:07:46,600
a lambdát.

102
00:07:46,600 --> 00:07:49,732
Most képzelje el, hogy beállítja a lambdát, és elforgatja a gombot,

103
00:07:49,732 --> 00:07:51,160
hogy megváltoztassa az értékét.

104
00:07:51,160 --> 00:07:55,295
A lambda értékének változásával maga a mátrix is változik,

105
00:07:55,295 --> 00:07:58,240
és így változik a mátrix meghatározója is.

106
00:07:58,240 --> 00:08:00,917
A cél itt az, hogy megtaláljuk a lambda értékét,

107
00:08:00,917 --> 00:08:04,032
amely nullává teszi ezt a determinánst, ami azt jelenti,

108
00:08:04,032 --> 00:08:08,240
hogy a módosított transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

109
00:08:08,240 --> 00:08:12,240
Ebben az esetben az édes pont akkor következik be, amikor a lambda 1.

110
00:08:12,240 --> 00:08:16,480
Természetesen, ha más mátrixot választottunk volna, a sajátérték nem feltétlenül 1.

111
00:08:16,480 --> 00:08:20,280
Az édes pontot a lambda más értéke érheti.

112
00:08:20,280 --> 00:08:23,620
Szóval ez elég sok, de fejtsük ki, mit mond ez.

113
00:08:23,620 --> 00:08:26,975
Amikor a lambda egyenlő 1-gyel, az A mátrix mínusz lambda

114
00:08:26,975 --> 00:08:30,620
szorzata az azonosság szorzatával a teret egy vonalra szorozza.

115
00:08:30,620 --> 00:08:34,428
Ez azt jelenti, hogy létezik egy nem nulla v vektor,

116
00:08:34,428 --> 00:08:40,680
amelyben A mínusz lambda szorozva az azonosság szorzatával v egyenlő a nulla vektorral.

117
00:08:40,680 --> 00:08:45,615
És ne feledjük, azért törődünk ezzel, mert ez azt jelenti,

118
00:08:45,615 --> 00:08:51,135
hogy A-szor v egyenlő lambda-szor v-vel, amit úgy olvashatunk le,

119
00:08:51,135 --> 00:08:58,580
hogy a v vektor A sajátvektora, amely az A transzformáció során a saját fesztávján marad.

120
00:08:58,580 --> 00:09:06,240
Ebben a példában a megfelelő sajátérték 1, tehát v valójában csak a helyén marad.

121
00:09:06,240 --> 00:09:11,385
Álljon meg, és gondolkodjon el, ha meg kell bizonyosodnia arról,

122
00:09:11,385 --> 00:09:13,840
hogy ez az érvelés jónak tűnik.

123
00:09:13,840 --> 00:09:16,280
Ez az, amit a bevezetőben említettem.

124
00:09:16,280 --> 00:09:20,013
Ha nem lenne szilárd felfogása a determinánsokról, és arról,

125
00:09:20,013 --> 00:09:24,236
hogy ezek miért vonatkoznak a nem nullától eltérő megoldású lineáris

126
00:09:24,236 --> 00:09:28,460
egyenletrendszerekre, egy ilyen kifejezés teljesen váratlannak tűnik.

127
00:09:28,460 --> 00:09:33,753
Hogy ezt működés közben lássuk, nézzük újra a példát az elejétől egy olyan mátrixszal,

128
00:09:33,753 --> 00:09:35,640
amelynek oszlopai 3, 0 és 1, 2.

129
00:09:35,640 --> 00:09:43,572
Annak megállapításához, hogy egy lambda érték sajátérték-e,

130
00:09:43,572 --> 00:09:51,240
vonja ki a mátrix átlóiból, és számítsa ki a determinánst.

131
00:09:51,240 --> 00:09:55,290
Ezzel egy bizonyos másodfokú polinomot kapunk lambdában,

132
00:09:55,290 --> 00:09:57,920
3 mínusz lambda szor 2 mínusz lambda.

133
00:09:57,920 --> 00:10:02,872
Mivel a lambda csak akkor lehet sajátérték, ha ez a determináns véletlenül nulla,

134
00:10:02,872 --> 00:10:06,979
ezért arra a következtetésre juthatunk, hogy az egyetlen lehetséges

135
00:10:06,979 --> 00:10:10,120
sajátérték a lambda egyenlő 2 és a lambda egyenlő 3.

136
00:10:10,120 --> 00:10:13,014
Ahhoz, hogy kitaláljuk, melyek azok a sajátvektorok,

137
00:10:13,014 --> 00:10:16,399
amelyek ténylegesen rendelkeznek ezen sajátértékek egyikével,

138
00:10:16,399 --> 00:10:20,822
mondjuk a lambda egyenlő 2-vel, csatlakoztassa ezt a lambda-értéket a mátrixhoz,

139
00:10:20,822 --> 00:10:25,300
majd oldja meg, hogy ez az átlósan módosított mátrix mely vektorokra küld nullára.

140
00:10:25,300 --> 00:10:30,054
Ha ezt úgy számolná ki, mint bármely más lineáris rendszert, akkor azt látná,

141
00:10:30,054 --> 00:10:35,480
hogy a megoldások az átlós egyenesen lévő összes vektorok, amelyeket negatív 1, 1 fed le.

142
00:10:35,480 --> 00:10:40,340
Ez megfelel annak a ténynek, hogy a változatlan mátrix,

143
00:10:40,340 --> 00:10:44,680
3, 0, 1, 2, az összes vektort 2-szeresére nyújtja.

144
00:10:44,680 --> 00:10:50,880
Nos, egy 2D-s transzformációnak nem kell sajátvektorokkal rendelkeznie.

145
00:10:50,880 --> 00:10:53,960
Vegyünk például egy 90 fokkal való elforgatást.

146
00:10:53,960 --> 00:11:01,200
Ennek nincsenek sajátvektorai, mivel minden vektort elforgat a saját tartományából.

147
00:11:01,200 --> 00:11:04,976
Ha valóban megpróbálja kiszámítani egy ilyen forgatás sajátértékeit,

148
00:11:04,976 --> 00:11:06,400
figyelje meg, mi történik.

149
00:11:06,400 --> 00:11:11,120
Mátrixának 0, 1 oszlopa és negatív 1, 0 oszlopa van.

150
00:11:11,120 --> 00:11:18,440
Vonjuk le a lambdát az átlós elemekből, és nézzük meg, hogy a determináns mikor nulla.

151
00:11:18,440 --> 00:11:22,960
Ebben az esetben megkapja a lambda polinom négyzetét plusz 1-gyel.

152
00:11:22,960 --> 00:11:29,000
Ennek a polinomnak az egyetlen gyöke az imaginárius számok, az i és a negatív i.

153
00:11:29,000 --> 00:11:36,120
Az a tény, hogy nincsenek valós számmegoldások, azt jelzi, hogy nincsenek sajátvektorok.

154
00:11:36,120 --> 00:11:40,640
Egy másik nagyon érdekes példa, amelyet érdemes a fejedben tartani, a nyíró.

155
00:11:40,640 --> 00:11:45,614
Ez a helyére rögzíti az i-hat-ot, és áthelyezi a j-hat 1-et,

156
00:11:45,614 --> 00:11:49,040
így a mátrixának 1, 0 és 1, 1 oszlopa van.

157
00:11:49,040 --> 00:11:52,931
Az x-tengelyen lévő összes vektor 1-es sajátértékű sajátvektor,

158
00:11:52,931 --> 00:11:55,060
mivel a helyükön rögzítve maradnak.

159
00:11:55,060 --> 00:11:58,880
Valójában ezek az egyetlen sajátvektorok.

160
00:11:58,880 --> 00:12:05,766
Ha kivonja a lambdát az átlókból, és kiszámítja a determinánst,

161
00:12:05,766 --> 00:12:09,640
akkor 1 mínusz lambda négyzetet kap.

162
00:12:09,640 --> 00:12:15,080
Ennek a kifejezésnek az egyetlen gyöke a lambda egyenlő 1-gyel.

163
00:12:15,080 --> 00:12:18,083
Ez összhangban van azzal, amit geometrikusan látunk,

164
00:12:18,083 --> 00:12:21,200
hogy minden sajátvektor 1-es sajátértékkel rendelkezik.

165
00:12:21,200 --> 00:12:26,800
Ne feledje azonban, hogy az is lehetséges, hogy csak egy sajátértéke legyen,

166
00:12:26,800 --> 00:12:30,000
de több, mint egy sajátvektorokkal teli sor.

167
00:12:30,000 --> 00:12:34,040
Egy egyszerű példa egy mátrix, amely mindent 2-vel skáláz.

168
00:12:34,040 --> 00:12:38,605
Az egyetlen sajátérték 2, de a síkban minden vektor

169
00:12:38,605 --> 00:12:42,380
egy sajátvektor lesz ezzel a sajátértékkel.

170
00:12:42,380 --> 00:12:57,523
Most újabb jó alkalom arra, hogy szünetet tartsunk és elgondolkozzunk ezen,

171
00:12:57,523 --> 00:13:03,900
mielőtt az utolsó témára térnék.

172
00:13:03,900 --> 00:13:07,608
Itt szeretném befejezni a sajátbázis ötletét,

173
00:13:07,608 --> 00:13:11,720
amely erősen támaszkodik az utolsó videó ötleteire.

174
00:13:11,720 --> 00:13:17,220
Nézze meg, mi történik, ha bázisvektoraink véletlenül sajátvektorok.

175
00:13:17,220 --> 00:13:23,760
Például lehet, hogy az i-hat negatív 1-gyel, a j-hat pedig 2-vel van méretezve.

176
00:13:23,760 --> 00:13:28,429
Az új koordinátáikat egy mátrix oszlopaiként írva figyeljük meg,

177
00:13:28,429 --> 00:13:32,236
hogy azok a skaláris többszörösek, a negatív 1 és 2,

178
00:13:32,236 --> 00:13:37,192
amelyek az i-hat és a j-hat sajátértékei, a mátrixunk átlóján ülnek,

179
00:13:37,192 --> 00:13:39,060
és minden más bejegyzés 0.

180
00:13:39,060 --> 00:13:44,165
Bármikor, amikor egy mátrixban az átlón kívül mindenhol 0-k vannak,

181
00:13:44,165 --> 00:13:49,721
ésszerűen átlós mátrixnak nevezzük, és ennek az értelmezése úgy történik,

182
00:13:49,721 --> 00:13:56,178
hogy az összes bázisvektor sajátvektor, és ennek a mátrixnak a diagonális bejegyzései

183
00:13:56,178 --> 00:13:57,380
a sajátértékeik.

184
00:13:57,380 --> 00:14:02,060
Sok olyan dolog van, ami sokkal szebbé teszi az átlós mátrixokkal való munkát.

185
00:14:02,060 --> 00:14:06,206
Az egyik nagy dolog az, hogy könnyebb kiszámítani, mi fog történni,

186
00:14:06,206 --> 00:14:09,500
ha ezt a mátrixot többszörösen megszorozzuk önmagával.

187
00:14:09,500 --> 00:14:15,424
Mivel ezek a mátrixok mindegyike minden bázisvektort valamilyen sajátértékre skáláz,

188
00:14:15,424 --> 00:14:20,791
ezért a mátrix sokszori, mondjuk 100-szori alkalmazása csak akkor felel meg,

189
00:14:20,791 --> 00:14:25,880
ha minden bázisvektort a megfelelő sajátérték 100. hatványával skálázunk.

190
00:14:25,880 --> 00:14:29,940
Ezzel szemben próbálja meg kiszámítani egy nem átlós mátrix 100. hatványát.

191
00:14:29,940 --> 00:14:31,940
Tényleg, próbáld ki egy pillanatra.

192
00:14:31,940 --> 00:14:36,500
Ez egy rémálom.

193
00:14:36,500 --> 00:14:39,360
Természetesen ritkán lesz olyan szerencsés, hogy

194
00:14:39,360 --> 00:14:42,220
az alapvektorai egyben sajátvektorok is legyenek.

195
00:14:42,220 --> 00:14:44,896
De ha a transzformációnak sok sajátvektora van,

196
00:14:44,896 --> 00:14:49,858
mint például ennek a videónak az elejétől, ami elég ahhoz, hogy olyan halmazt válasszon,

197
00:14:49,858 --> 00:14:54,096
amely átfedi a teljes teret, akkor módosíthatja a koordináta-rendszert úgy,

198
00:14:54,096 --> 00:14:56,940
hogy ezek a sajátvektorok legyenek az alapvektorok.

199
00:14:56,940 --> 00:15:00,108
Az előző videóban beszéltem az alap megváltoztatásáról,

200
00:15:00,108 --> 00:15:02,881
de itt végigmegyek egy szupergyors emlékeztetőn,

201
00:15:02,881 --> 00:15:06,446
hogyan lehet kifejezni a koordinátarendszerünkben jelenleg írt

202
00:15:06,446 --> 00:15:08,540
transzformációt egy másik rendszerbe.

203
00:15:08,540 --> 00:15:12,080
Vegyük új bázisnak a használni kívánt vektorok koordinátáit,

204
00:15:12,080 --> 00:15:15,910
ami jelen esetben a mi két sajátvektorunkat, majd tegyük ezeket a

205
00:15:15,910 --> 00:15:20,380
koordinátákat egy mátrix oszlopaivá, amelyet bázisváltási mátrixnak nevezünk.

206
00:15:20,380 --> 00:15:23,592
Ha az eredeti transzformációt szendvicsbe tesszük,

207
00:15:23,592 --> 00:15:29,135
jobbra téve a bázismátrix változását, balra pedig a bázis mátrix változásának inverzét,

208
00:15:29,135 --> 00:15:33,860
akkor az eredmény egy ugyanazt a transzformációt reprezentáló mátrix lesz,

209
00:15:33,860 --> 00:15:37,640
de az új bázisvektorok koordinátája szempontjából. rendszer.

210
00:15:37,640 --> 00:15:41,573
Ennek a sajátvektorokkal való megtételének az a lényege,

211
00:15:41,573 --> 00:15:47,300
hogy ez az új mátrix garantáltan átlós a megfelelő sajátértékeivel az átlón lefelé.

212
00:15:47,300 --> 00:15:51,163
Ez azért van így, mert egy olyan koordinátarendszerben dolgozik,

213
00:15:51,163 --> 00:15:55,740
ahol az történik a bázisvektorokkal, hogy a transzformáció során skálázódnak.

214
00:15:55,740 --> 00:15:59,878
A bázisvektorok azon halmazát, amelyek egyben sajátvektorok is,

215
00:15:59,878 --> 00:16:02,400
ismét ésszerűen sajátbázisnak nevezzük.

216
00:16:02,400 --> 00:16:07,365
Tehát, ha például ennek a mátrixnak a 100. hatványát kellene kiszámítani,

217
00:16:07,365 --> 00:16:11,525
sokkal könnyebb lenne sajátbázisra váltani, kiszámolni a 100.

218
00:16:11,525 --> 00:16:16,760
hatványt abban a rendszerben, majd visszakonvertálni a standard rendszerünkre.

219
00:16:16,760 --> 00:16:18,460
Ezt nem lehet minden átalakítással megtenni.

220
00:16:18,460 --> 00:16:23,800
Például egy nyírásnak nincs elég sajátvektora a teljes tér áthidalásához.

221
00:16:23,800 --> 00:16:29,180
De ha talál egy sajátbázist, az igazán széppé teszi a mátrixműveleteket.

222
00:16:29,180 --> 00:16:32,403
Azok számára, akik hajlandóak egy szép rejtvényen dolgozni, hogy meglássák,

223
00:16:32,403 --> 00:16:35,202
hogyan néz ki ez működés közben, és hogyan használható fel néhány

224
00:16:35,202 --> 00:16:37,960
meglepő eredmény eléréséhez, itt hagyok egy üzenetet a képernyőn.

225
00:16:37,960 --> 00:16:40,960
Egy kis munkát igényel, de azt hiszem, élvezni fogja.

226
00:16:40,960 --> 00:16:46,000
A sorozat következő és egyben utolsó videója absztrakt vektortereken fog szerepelni.

227
00:16:46,000 --> 00:16:46,000
Majd találkozunk!

