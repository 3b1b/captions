1
00:00:19,282 --> 00:00:24,760
A sajátvektorok és a sajátértékek egyike azon

2
00:00:24,760 --> 00:00:26,460
témáknak, amelyeket sok diák különösen intuitívnak talál.

3
00:00:26,460 --> 00:00:30,320
Az olyan dolgok, mint például, hogy miért tesszük ezt, és mit is

4
00:00:30,320 --> 00:00:34,020
jelent ez valójában, túl gyakran csak lebegnek a számítások megválaszolatlan tengerében.

5
00:00:34,020 --> 00:00:37,340
És ahogy közzétettem ennek a sorozatnak a videóit, sokan

6
00:00:37,340 --> 00:00:40,700
megjegyeztétek, hogy alig várjátok, hogy megjelenítsék ezt a témát.

7
00:00:40,700 --> 00:00:44,700
Gyanítom, hogy ennek nem annyira az az oka,

8
00:00:44,700 --> 00:00:46,460
hogy a sajátosságok különösebben bonyolultak vagy rosszul magyarázhatók.

9
00:00:46,460 --> 00:00:51,020
Valójában ez viszonylag egyszerű, és szerintem

10
00:00:51,020 --> 00:00:52,020
a legtöbb könyv remekül elmagyarázza.

11
00:00:52,020 --> 00:00:56,500
Azt szeretném elérni, hogy ennek csak akkor van igazán értelme,

12
00:00:56,500 --> 00:00:59,220
ha szilárd vizuális megértése van az azt megelőző témák közül.

13
00:00:59,220 --> 00:01:04,460
A legfontosabb itt az, hogy tudja, hogyan kell a mátrixokat

14
00:01:04,460 --> 00:01:09,140
lineáris transzformációnak tekinteni, de olyan dolgokban is kényelmesnek kell lennie,

15
00:01:09,140 --> 00:01:10,780
mint a determinánsok, a lineáris egyenletrendszerek és az alapváltoztatás.

16
00:01:10,780 --> 00:01:15,580
A sajátanyagokkal kapcsolatos zavar általában több köze van az egyik

17
00:01:15,580 --> 00:01:20,420
ilyen téma ingatag alapjához, mint magukhoz a sajátvektorokhoz és sajátértékekhez.

18
00:01:20,420 --> 00:01:25,500
Kezdésként vegyünk fontolóra néhány lineáris transzformációt két dimenzióban, mint az itt látható.

19
00:01:25,500 --> 00:01:31,860
Az i-hat bázisvektort a 3, 0, a j-hat pedig 1, 2 koordinátákra mozgatja.

20
00:01:31,860 --> 00:01:36,860
Tehát egy mátrixszal ábrázoljuk, amelynek oszlopai 3, 0 és 1, 2.

21
00:01:36,860 --> 00:01:42,020
Összpontosítson arra, hogy mit csinál egy adott vektorral, és gondoljon

22
00:01:42,020 --> 00:01:45,220
a vektor fesztávjára, az origóján és csúcsán áthaladó egyenesre.

23
00:01:45,220 --> 00:01:48,460
A legtöbb vektor az átalakulás során kiesik a fesztávjából.

24
00:01:48,500 --> 00:01:53,140
Úgy értem, elég véletlennek tűnik, ha az a hely, ahol

25
00:01:53,140 --> 00:01:57,500
a vektor leszállt, véletlenül valahol ezen a vonalon lenne.

26
00:01:57,500 --> 00:02:02,380
De néhány speciális vektor a saját tartományukon marad, ami azt jelenti, hogy a mátrix

27
00:02:02,380 --> 00:02:09,660
hatása egy ilyen vektorra csak az, hogy megnyújtja vagy összenyomja, mint egy skalár.

28
00:02:09,660 --> 00:02:15,100
Ebben a konkrét példában az i-hat bázisvektor egy ilyen speciális vektor.

29
00:02:15,100 --> 00:02:19,940
Az i-hat fesztávja az x tengely, és a mátrix első oszlopából láthatjuk,

30
00:02:19,940 --> 00:02:26,500
hogy az i-hat önmaga háromszorosára mozog, még mindig azon az x tengelyen.

31
00:02:26,500 --> 00:02:32,540
Sőt, a lineáris transzformációk működése miatt az x tengelyen lévő bármely más

32
00:02:32,540 --> 00:02:38,580
vektor is csak 3-szorosára megnyúlik, és így a saját fesztávján marad.

33
00:02:38,580 --> 00:02:42,760
Egy kicsit alattomosabb vektor, amely a transzformáció során

34
00:02:42,760 --> 00:02:44,880
a saját fesztávján marad, negatív 1, 1.

35
00:02:44,880 --> 00:02:49,120
A végén 2-szeresére nyúlik.

36
00:02:49,120 --> 00:02:54,760
És ismét, a linearitás azt jelenti, hogy bármely más vektor az

37
00:02:54,760 --> 00:03:00,040
átlós vonalon, amelyet ez a fickó fed le, csak 2-szeresére nyúlik.

38
00:03:00,040 --> 00:03:04,200
És ehhez az átalakuláshoz ezek mind olyan vektorok, amelyeknek

39
00:03:04,200 --> 00:03:05,860
ez a különleges tulajdonsága, hogy a fesztávon maradnak.

40
00:03:05,860 --> 00:03:10,000
Az x tengelyen lévők 3-szorosára, az ezen az

41
00:03:10,000 --> 00:03:12,940
átlós vonalon lévők pedig 2-szeresére nyúlnak ki.

42
00:03:12,940 --> 00:03:16,600
Bármely másik vektor elfordul valamelyest a transzformáció során,

43
00:03:16,600 --> 00:03:22,700
és kikerül arról a vonalról, amelyen átnyúlik.

44
00:03:22,700 --> 00:03:28,140
Amint azt eddig sejteni lehetett, ezeket a speciális vektorokat a transzformáció

45
00:03:28,140 --> 00:03:33,460
sajátvektorainak nevezik, és minden sajátvektor hozzárendelt egy úgynevezett sajátértéket, amely éppen

46
00:03:33,460 --> 00:03:40,620
az a tényező, amellyel a transzformáció során megnyúlik vagy összenyomódik.

47
00:03:40,620 --> 00:03:44,220
Természetesen nincs semmi különös a nyújtásban és a squasholásban,

48
00:03:44,220 --> 00:03:46,580
vagy abban, hogy ezek a sajátértékek véletlenül pozitívak.

49
00:03:46,580 --> 00:03:51,820
Egy másik példában lehet egy sajátvektor, amelynek sajátértéke negatív 1 fele,

50
00:03:51,820 --> 00:03:57,460
ami azt jelenti, hogy a vektor megfordul és összenyomódik 1-szeres tényezővel.

51
00:03:57,460 --> 00:04:01,580
De itt az a fontos, hogy azon a

52
00:04:01,580 --> 00:04:04,660
vonalon maradjon, amelyen átnyúlik anélkül, hogy elfordulna róla.

53
00:04:04,660 --> 00:04:09,780
Ha egy pillantást szeretne látni arra, hogy ez miért

54
00:04:09,780 --> 00:04:11,940
lehet hasznos elgondolkodni, fontolja meg néhány háromdimenziós forgatást.

55
00:04:11,940 --> 00:04:17,780
Ha talál egy sajátvektort ehhez a forgáshoz, egy vektort, amely a

56
00:04:17,780 --> 00:04:23,020
saját fesztávján marad, akkor azt találta, hogy az a forgástengely.

57
00:04:23,020 --> 00:04:28,540
És sokkal könnyebb a 3D-s forgatást valamilyen forgási

58
00:04:28,540 --> 00:04:33,880
tengelyben és forgási szögben gondolkodni, mint az ehhez

59
00:04:33,880 --> 00:04:37,140
a transzformációhoz kapcsolódó teljes 3x3 mátrixra gondolni.

60
00:04:37,140 --> 00:04:42,080
Ebben az esetben egyébként a megfelelő sajátértéknek 1-nek kell lennie, mivel a forgatások soha

61
00:04:42,080 --> 00:04:48,180
nem nyúlnak meg vagy nem húznak ki semmit, így a vektor hossza változatlan maradna.

62
00:04:48,180 --> 00:04:50,580
Ez a minta gyakran megjelenik a lineáris algebrában.

63
00:04:50,580 --> 00:04:55,420
Bármilyen mátrix által leírt lineáris transzformáció esetén megértheti, mit csinál, ha

64
00:04:55,420 --> 00:05:00,120
kiolvassa ennek a mátrixnak az oszlopait, mint a bázisvektorok leszállási pontjait.

65
00:05:00,120 --> 00:05:04,180
De gyakran jobb módja annak, hogy a lineáris transzformáció lényegét megismerjük, ami

66
00:05:04,220 --> 00:05:15,780
kevésbé függ az adott koordináta-rendszertől, ha megtaláljuk a sajátvektorokat és a sajátértékeket.

67
00:05:15,780 --> 00:05:19,980
Itt nem térek ki a sajátvektorok és sajátértékek számítási

68
00:05:19,980 --> 00:05:24,600
módszereinek teljes részleteire, de megpróbálok áttekintést adni azokról a

69
00:05:24,600 --> 00:05:26,820
számítási ötletekről, amelyek a legfontosabbak a fogalmi megértéshez.

70
00:05:26,820 --> 00:05:30,980
Szimbolikusan így néz ki a sajátvektor ötlete.

71
00:05:30,980 --> 00:05:37,220
A valamilyen transzformációt reprezentáló mátrix, v a sajátvektor, a

72
00:05:37,220 --> 00:05:40,800
lambda pedig egy szám, vagyis a megfelelő sajátérték.

73
00:05:40,800 --> 00:05:45,500
Ez a kifejezés az, hogy a mátrix-vektor szorzat, A-szor v, ugyanazt

74
00:05:45,500 --> 00:05:51,520
az eredményt adja, mintha a v sajátvektort skáláznánk valamilyen lambda értékkel.

75
00:05:51,520 --> 00:05:56,900
Tehát az A mátrix sajátvektorainak és sajátértékeinek megtalálása a v és a

76
00:05:56,900 --> 00:06:02,420
lambda azon értékeinek megkereséséhez vezet, amelyek igazzá teszik ezt a kifejezést.

77
00:06:02,420 --> 00:06:06,340
Először kicsit kényelmetlen vele dolgozni, mert a bal oldal a mátrix-vektor

78
00:06:06,340 --> 00:06:11,220
szorzást jelenti, de a jobb oldal itt a skalárvektor szorzást.

79
00:06:11,220 --> 00:06:16,540
Tehát kezdjük azzal, hogy a jobb oldalt átírjuk valamiféle mátrix-vektor

80
00:06:16,540 --> 00:06:21,740
szorzásként, olyan mátrix használatával, amely bármely vektort lambda-tényezővel skáláz.

81
00:06:21,740 --> 00:06:26,260
Egy ilyen mátrix oszlopai azt ábrázolják, hogy mi történik az egyes bázisvektorokkal,

82
00:06:26,260 --> 00:06:31,580
és minden bázisvektort egyszerűen meg kell szorozni lambdával, így ennek a

83
00:06:31,580 --> 00:06:36,360
mátrixnak a lambda száma lesz az átlón lefelé, mindenhol máshol nullákkal.

84
00:06:36,360 --> 00:06:40,980
Ezt a típust általában úgy írják le, hogy ezt a lambdát kiszámolják, és úgy

85
00:06:40,980 --> 00:06:45,980
írják, hogy lambda szoroz i, ahol i az azonosságmátrix az átlón lefelé lévőkkel.

86
00:06:45,980 --> 00:06:50,260
Ha mindkét oldal úgy néz ki, mint a mátrix-vektor

87
00:06:50,260 --> 00:06:54,340
szorzás, levonhatjuk a jobb oldalt, és kiszámolhatjuk a v-t.

88
00:06:54,420 --> 00:06:59,340
Tehát most van egy új mátrixunk, A mínusz lambda szorozva az azonossággal, és keresünk

89
00:06:59,340 --> 00:07:05,860
egy v vektort, amelyre ez az új mátrix, szorozva v, a nulla vektort adja.

90
00:07:05,860 --> 00:07:11,420
Nos, ez mindig igaz lesz, ha maga v a nulla vektor, de ez unalmas.

91
00:07:11,420 --> 00:07:14,540
Nem nulla sajátvektort akarunk.

92
00:07:14,540 --> 00:07:18,900
És ha megnézi az 5. és 6. fejezetet, tudni fogja, hogy az

93
00:07:18,900 --> 00:07:24,940
egyetlen módja annak, hogy egy nem nulla vektorral rendelkező mátrix szorzata nullává

94
00:07:24,940 --> 00:07:29,940
váljon, ha a mátrixhoz tartozó transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

95
00:07:29,940 --> 00:07:35,560
És ez a kicsavarodás a mátrix nulla determinánsának felel meg.

96
00:07:35,560 --> 00:07:41,700
A konkrétumhoz tegyük fel, hogy az A mátrixnak 2., 1. és 2., 3. oszlopa

97
00:07:41,700 --> 00:07:46,600
van, és gondoljon arra, hogy minden átlós bejegyzésből kivonhat egy változó összeget, a lambdát.

98
00:07:46,600 --> 00:07:51,160
Most képzelje el, hogy beállítja a lambdát, és elforgatja a gombot, hogy megváltoztassa az értékét.

99
00:07:51,160 --> 00:07:56,320
A lambda értékének változásával maga a mátrix is

100
00:07:56,320 --> 00:07:58,240
változik, és így változik a mátrix meghatározója is.

101
00:07:58,240 --> 00:08:03,720
A cél itt az, hogy megtaláljuk a lambda értékét, amely nullává teszi ezt a

102
00:08:03,720 --> 00:08:08,240
determinánst, ami azt jelenti, hogy a módosított transzformáció a teret egy alacsonyabb dimenzióba tömöríti.

103
00:08:08,240 --> 00:08:12,240
Ebben az esetben az édes pont akkor következik be, amikor a lambda 1.

104
00:08:12,240 --> 00:08:16,480
Természetesen, ha más mátrixot választottunk volna, a sajátérték nem feltétlenül 1.

105
00:08:16,480 --> 00:08:20,280
Az édes pontot a lambda más értéke érheti.

106
00:08:20,280 --> 00:08:23,620
Szóval ez elég sok, de fejtsük ki, mit mond ez.

107
00:08:23,620 --> 00:08:30,620
Amikor a lambda egyenlő 1-gyel, az A mátrix mínusz lambda szorzata az azonosság szorzatával a teret egy vonalra szorozza.

108
00:08:30,620 --> 00:08:36,440
Ez azt jelenti, hogy létezik egy nem nulla v vektor, amelyben A

109
00:08:36,440 --> 00:08:40,680
mínusz lambda szorozva az azonosság szorzatával v egyenlő a nulla vektorral.

110
00:08:40,680 --> 00:08:46,180
És ne feledjük, azért törődünk ezzel, mert ez azt jelenti, hogy A-szor

111
00:08:46,180 --> 00:08:54,040
v egyenlő lambda-szor v-vel, amit úgy olvashatunk le, hogy a v vektor

112
00:08:54,040 --> 00:08:58,580
A sajátvektora, amely az A transzformáció során a saját fesztávján marad.

113
00:08:58,580 --> 00:09:03,440
Ebben a példában a megfelelő sajátérték 1,

114
00:09:03,440 --> 00:09:06,200
tehát v valójában csak a helyén marad.

115
00:09:06,240 --> 00:09:13,840
Álljon meg, és gondolkodjon el, ha meg kell bizonyosodnia arról, hogy ez az érvelés jónak tűnik.

116
00:09:13,840 --> 00:09:16,280
Ez az, amit a bevezetőben említettem.

117
00:09:16,280 --> 00:09:21,320
Ha nem lenne szilárd felfogása a determinánsokról, és arról, hogy ezek miért vonatkoznak

118
00:09:21,320 --> 00:09:28,460
a nem nullától eltérő megoldású lineáris egyenletrendszerekre, egy ilyen kifejezés teljesen váratlannak tűnik.

119
00:09:28,460 --> 00:09:32,400
Hogy ezt működés közben lássuk, nézzük újra a példát az elejétől

120
00:09:32,400 --> 00:09:35,640
egy olyan mátrixszal, amelynek oszlopai 3, 0 és 1, 2.

121
00:09:35,640 --> 00:09:41,600
Annak megállapításához, hogy egy lambda érték sajátérték-e, vonja ki

122
00:09:41,600 --> 00:09:51,240
a mátrix átlóiból, és számítsa ki a determinánst.

123
00:09:51,240 --> 00:09:57,920
Ezzel egy bizonyos másodfokú polinomot kapunk lambdában, 3 mínusz lambda szor 2 mínusz lambda.

124
00:09:57,920 --> 00:10:03,000
Mivel a lambda csak akkor lehet sajátérték, ha ez a determináns véletlenül nulla, ezért arra a

125
00:10:03,000 --> 00:10:10,120
következtetésre juthatunk, hogy az egyetlen lehetséges sajátérték a lambda egyenlő 2 és a lambda egyenlő 3.

126
00:10:10,120 --> 00:10:14,340
Ahhoz, hogy kitaláljuk, melyek azok a sajátvektorok, amelyek ténylegesen rendelkeznek ezen sajátértékek egyikével,

127
00:10:14,340 --> 00:10:20,840
mondjuk a lambda egyenlő 2-vel, csatlakoztassa ezt a lambda-értéket a mátrixhoz, majd

128
00:10:20,840 --> 00:10:25,300
oldja meg, hogy ez az átlósan módosított mátrix mely vektorokra küld nullára.

129
00:10:25,300 --> 00:10:29,800
Ha ezt úgy számolná ki, mint bármely más lineáris rendszert, akkor azt látná, hogy

130
00:10:29,800 --> 00:10:35,480
a megoldások az átlós egyenesen lévő összes vektorok, amelyeket negatív 1, 1 fed le.

131
00:10:35,480 --> 00:10:41,200
Ez megfelel annak a ténynek, hogy a változatlan mátrix,

132
00:10:41,200 --> 00:10:44,680
3, 0, 1, 2, az összes vektort 2-szeresére nyújtja.

133
00:10:44,680 --> 00:10:50,880
Nos, egy 2D-s transzformációnak nem kell sajátvektorokkal rendelkeznie.

134
00:10:50,880 --> 00:10:53,960
Vegyünk például egy 90 fokkal való elforgatást.

135
00:10:53,960 --> 00:11:01,200
Ennek nincsenek sajátvektorai, mivel minden vektort elforgat a saját tartományából.

136
00:11:01,200 --> 00:11:06,400
Ha valóban megpróbálja kiszámítani egy ilyen forgatás sajátértékeit, figyelje meg, mi történik.

137
00:11:06,400 --> 00:11:11,120
Mátrixának 0, 1 oszlopa és negatív 1, 0 oszlopa van.

138
00:11:11,120 --> 00:11:18,440
Vonjuk le a lambdát az átlós elemekből, és nézzük meg, hogy a determináns mikor nulla.

139
00:11:18,440 --> 00:11:22,960
Ebben az esetben megkapja a lambda polinom négyzetét plusz 1-gyel.

140
00:11:22,960 --> 00:11:29,000
Ennek a polinomnak az egyetlen gyöke az imaginárius számok, az i és a negatív i.

141
00:11:29,000 --> 00:11:36,120
Az a tény, hogy nincsenek valós számmegoldások, azt jelzi, hogy nincsenek sajátvektorok.

142
00:11:36,120 --> 00:11:40,640
Egy másik nagyon érdekes példa, amelyet érdemes a fejedben tartani, a nyíró.

143
00:11:40,640 --> 00:11:47,460
Ez a helyére rögzíti az i-hat-ot, és áthelyezi a j-hat 1-et,

144
00:11:47,460 --> 00:11:49,000
így a mátrixának 1, 0 és 1, 1 oszlopa van.

145
00:11:49,040 --> 00:11:54,060
Az x-tengelyen lévő összes vektor 1-es sajátértékű

146
00:11:54,060 --> 00:11:55,060
sajátvektor, mivel a helyükön rögzítve maradnak.

147
00:11:55,060 --> 00:11:58,880
Valójában ezek az egyetlen sajátvektorok.

148
00:11:58,880 --> 00:12:04,400
Ha kivonja a lambdát az átlókból, és kiszámítja

149
00:12:04,400 --> 00:12:09,640
a determinánst, akkor 1 mínusz lambda négyzetet kap.

150
00:12:09,640 --> 00:12:15,080
Ennek a kifejezésnek az egyetlen gyöke a lambda egyenlő 1-gyel.

151
00:12:15,080 --> 00:12:19,640
Ez összhangban van azzal, amit geometrikusan látunk,

152
00:12:19,640 --> 00:12:21,200
hogy minden sajátvektor 1-es sajátértékkel rendelkezik.

153
00:12:21,200 --> 00:12:26,280
Ne feledje azonban, hogy az is lehetséges, hogy csak egy

154
00:12:26,280 --> 00:12:30,000
sajátértéke legyen, de több, mint egy sajátvektorokkal teli sor.

155
00:12:30,000 --> 00:12:34,040
Egy egyszerű példa egy mátrix, amely mindent 2-vel skáláz.

156
00:12:34,040 --> 00:12:39,680
Az egyetlen sajátérték 2, de a síkban minden

157
00:12:39,680 --> 00:12:42,380
vektor egy sajátvektor lesz ezzel a sajátértékkel.

158
00:12:42,380 --> 00:12:46,020
Most újabb jó alkalom arra, hogy szünetet tartsunk

159
00:12:46,020 --> 00:12:46,900
és elgondolkozzunk ezen, mielőtt az utolsó témára térnék.

160
00:13:03,900 --> 00:13:08,940
Itt szeretném befejezni a sajátbázis ötletét, amely

161
00:13:08,940 --> 00:13:11,720
erősen támaszkodik az utolsó videó ötleteire.

162
00:13:11,720 --> 00:13:17,220
Nézze meg, mi történik, ha bázisvektoraink véletlenül sajátvektorok.

163
00:13:17,220 --> 00:13:23,760
Például lehet, hogy az i-hat negatív 1-gyel, a j-hat pedig 2-vel van méretezve.

164
00:13:23,760 --> 00:13:28,800
Az új koordinátáikat egy mátrix oszlopaiként írva figyeljük meg, hogy azok a

165
00:13:28,800 --> 00:13:34,500
skaláris többszörösek, a negatív 1 és 2, amelyek az i-hat és a

166
00:13:34,500 --> 00:13:39,060
j-hat sajátértékei, a mátrixunk átlóján ülnek, és minden más bejegyzés 0 .

167
00:13:39,060 --> 00:13:43,940
Bármikor, amikor egy mátrixban az átlón kívül mindenhol 0-k vannak, ésszerűen átlós

168
00:13:43,940 --> 00:13:48,940
mátrixnak nevezzük, és ennek az értelmezése úgy történik, hogy az összes

169
00:13:48,940 --> 00:13:57,380
bázisvektor sajátvektor, és ennek a mátrixnak a diagonális bejegyzései a sajátértékeik.

170
00:13:57,380 --> 00:14:02,060
Sok olyan dolog van, ami sokkal szebbé teszi az átlós mátrixokkal való munkát.

171
00:14:02,060 --> 00:14:06,380
Az egyik nagy dolog az, hogy könnyebb kiszámítani, mi

172
00:14:06,380 --> 00:14:09,500
fog történni, ha ezt a mátrixot többszörösen megszorozzuk önmagával.

173
00:14:09,500 --> 00:14:15,140
Mivel ezek a mátrixok mindegyike minden bázisvektort valamilyen sajátértékre skáláz,

174
00:14:15,140 --> 00:14:20,900
ezért a mátrix sokszori, mondjuk 100-szori alkalmazása csak akkor felel

175
00:14:20,900 --> 00:14:25,880
meg, ha minden bázisvektort a megfelelő sajátérték 100. hatványával skálázunk.

176
00:14:25,880 --> 00:14:29,940
Ezzel szemben próbálja meg kiszámítani egy nem átlós mátrix 100. hatványát.

177
00:14:29,940 --> 00:14:31,940
Tényleg, próbáld ki egy pillanatra.

178
00:14:31,940 --> 00:14:32,580
Ez egy rémálom.

179
00:14:36,500 --> 00:14:42,220
Természetesen ritkán lesz olyan szerencsés, hogy az alapvektorai egyben sajátvektorok is legyenek.

180
00:14:42,220 --> 00:14:46,900
De ha a transzformációnak sok sajátvektora van, mint például ennek a videónak az

181
00:14:46,900 --> 00:14:52,160
elejétől, ami elég ahhoz, hogy olyan halmazt válasszon, amely átfedi a teljes teret,

182
00:14:52,160 --> 00:14:56,940
akkor módosíthatja a koordináta-rendszert úgy, hogy ezek a sajátvektorok legyenek az alapvektorok.

183
00:14:56,940 --> 00:15:01,140
Az előző videóban beszéltem az alap megváltoztatásáról, de

184
00:15:01,140 --> 00:15:06,180
itt végigmegyek egy szupergyors emlékeztetőn, hogyan lehet kifejezni

185
00:15:06,180 --> 00:15:08,540
a koordinátarendszerünkben jelenleg írt transzformációt egy másik rendszerbe.

186
00:15:08,540 --> 00:15:12,420
Vegyük új bázisnak a használni kívánt vektorok koordinátáit, ami

187
00:15:12,420 --> 00:15:17,540
jelen esetben a mi két sajátvektorunkat, majd tegyük ezeket

188
00:15:17,540 --> 00:15:20,380
a koordinátákat egy mátrix oszlopaivá, amelyet bázisváltási mátrixnak nevezünk.

189
00:15:20,380 --> 00:15:24,460
Ha az eredeti transzformációt szendvicsbe tesszük, jobbra téve a

190
00:15:24,460 --> 00:15:30,560
bázismátrix változását, balra pedig a bázis mátrix változásának inverzét,

191
00:15:30,560 --> 00:15:35,520
akkor az eredmény egy ugyanazt a transzformációt reprezentáló mátrix

192
00:15:35,520 --> 00:15:37,640
lesz, de az új bázisvektorok koordinátája szempontjából. rendszer.

193
00:15:37,640 --> 00:15:42,640
Ennek a sajátvektorokkal való megtételének az a lényege, hogy ez az

194
00:15:42,640 --> 00:15:47,300
új mátrix garantáltan átlós a megfelelő sajátértékeivel az átlón lefelé.

195
00:15:47,300 --> 00:15:51,080
Ez azért van így, mert egy olyan koordinátarendszerben dolgozik, ahol

196
00:15:51,080 --> 00:15:55,740
az történik a bázisvektorokkal, hogy a transzformáció során skálázódnak.

197
00:15:55,740 --> 00:16:02,400
A bázisvektorok azon halmazát, amelyek egyben sajátvektorok is, ismét ésszerűen sajátbázisnak nevezzük.

198
00:16:02,400 --> 00:16:07,620
Tehát, ha például ennek a mátrixnak a 100. hatványát kellene

199
00:16:07,620 --> 00:16:14,060
kiszámítani, sokkal könnyebb lenne sajátbázisra váltani, kiszámolni a 100.

200
00:16:14,060 --> 00:16:16,760
hatványt abban a rendszerben, majd visszakonvertálni a standard rendszerünkre.

201
00:16:16,760 --> 00:16:18,460
Ezt nem lehet minden átalakítással megtenni.

202
00:16:18,460 --> 00:16:23,800
Például egy nyírásnak nincs elég sajátvektora a teljes tér áthidalásához.

203
00:16:23,800 --> 00:16:29,180
De ha talál egy sajátbázist, az igazán széppé teszi a mátrixműveleteket.

204
00:16:29,180 --> 00:16:32,060
Azok számára, akik hajlandóak egy szép rejtvényen dolgozni, hogy meglássák,

205
00:16:32,060 --> 00:16:35,880
hogyan néz ki ez működés közben, és hogyan használható fel

206
00:16:35,880 --> 00:16:37,960
néhány meglepő eredmény eléréséhez, itt hagyok egy üzenetet a képernyőn.

207
00:16:37,960 --> 00:16:40,960
Egy kis munkát igényel, de azt hiszem, élvezni fogja.

208
00:16:40,960 --> 00:16:46,000
A sorozat következő és egyben utolsó videója absztrakt vektortereken fog szerepelni.

209
00:16:46,000 --> 00:16:46,500
Majd találkozunk!

